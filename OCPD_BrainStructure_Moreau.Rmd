---
title: "OCPD and Brain Structure"
author: "Allison L. Moreau, Ph.D."
date: "Published 1/20/2024"
output:
  html_document: default
  pdf_document: default
---

SEE ALSO "ML.script.R" for OCPD Aim 1 ML analyses and 
"Dougs.Datasets.Rmd" for OCPD Aim 1 ML external validation analyses

```{r setup,  include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(eval = FALSE)
library(psych) # various useful functions
library(haven) # loads SPSS .sav files
library(labelled) # work w/ labelled data imported from SPSS or Stata 
library(readxl) # loads .xls files
library(writexl)
library(reshape) # reshapes data frames
library(schoolmath) # contains is.decimal function
library(rlist) # Data manipulation for list objects
library(ggpubr) # Publication-ready ggplots 
library(ggseg) # Brain figures
library(ggsegExtra) #additional stuff for ggseg package (including other atlases)
library(ggsegDKT) # DKT atlas for ggseg

library(sjPlot) # to get result tables
library(sjmisc)
library(sjlabelled)
library(lm.beta) # get standardized coefficients

library(lavaan) # runs latent variable analyses (i.e., SEM,  CFA)
library(lme4) # runs HLM/Linear Mixed Effects models
library(lmerTest) # more HLM tools
library(nlme) # need lme (instead of lmer) for Aim 2 residualizing
#library(semPlot)
#library(semTable)

library(caret) # runs machine learning algorithms
library(caretEnsemble) # allows you to run multiple models at once (could also ensemble if wanted)
library(gbm) # runs gbm ML analyses
library(nnet) # runs neural network models

library(tictoc) # timer to tell how long code runs
library(validate) # checks input data to make sure no problems w/it
library(tidyverse)
library(doParallel) # Enables parallel processing

dns.data.dir <- "/Users/Shared/SharedDocs/from.Box/research/datasets/DNS/"
span.data.dir <- "/Users/Shared/SharedDocs/from.Box/research/datasets/SPAN/"
project.dir <- "/Users/Shared/SharedDocs/from.Box/research/projects/dissertation/"
```

# Load Data

## NEO Data

```{r load-NEO-data,  include=FALSE}
#############################################
#### DUKE NEUROGENETICS STUDY (DNS) DATA ####
#############################################
DNS.NEO.raw.data <- read_sav(paste(dns.data.dir, "neopirscor.sav", sep = ""))
# DNS.NEO.raw.data.SPSS <- read_spss("~/Library/CloudStorage/Box-Box/research/datasets/DNS/neopirscor.sav")

# Delete fake subjs DNS9999 and DNS9998
DNS.NEO.raw.data <- filter(DNS.NEO.raw.data, DNSID != c("DNS9999", "DNS9998")) 

# Create dataframe of NEO summary scores (SPAN data has separate input file for summary scores)
DNS.NEO.scored.data <- select(DNS.NEO.raw.data, c("ID",  "NEON1":"neocp"))

# Remove NEO summary scores from raw data dataframe + rename "DNSID" to "ID"
DNS.NEO.raw.data <- select(DNS.NEO.raw.data, c(1:244)) %>%
                      rename("ID" = "DNSID")

# Fix NEO variable labels to show correct values (0-4 instead of 1-5)
## the data are already 0-4 but the label seems like 1-5. could cause confusion
DNS.NEO.raw.data <- DNS.NEO.raw.data %>% mutate_at(vars(starts_with("NEO")), 
                    ~labelled_spss(., labels = c("Strongly Disagree"=0, "Disagree"=1, "Neutral"=2, "Agree"=3, "Strongly Agree"=4)))

# Create raw dataframe of only subjects w/ NEO data
### DNS0007 is missing NEO data - Q97-120 missing (240 Q's total)
### for SPAN ML, removing subjs w/ >25% missing NEO items, so probably won't remove DNS0007
### Warning: some subjects not listed in this file and missing NEO data
DNS.NEO.raw.data_not.NAs <- DNS.NEO.raw.data[rowSums(is.na(select(DNS.NEO.raw.data, -c(1:4)))) 
                                                != ncol(select(DNS.NEO.raw.data, -c(1:4))), ]
# Create list of DNS subjects w/ NEO data
DNS.subjs.w.NEO <- DNS.NEO.raw.data_not.NAs[["ID"]]

# Create scored dataframe of only subjects w/ NEO data
DNS.NEO.scored.data_not.NAs <- filter(DNS.NEO.scored.data, ID %in% DNS.subjs.w.NEO)

#############################################################
#### ST. LOUIS PERSONALITY AND AGING NETWORK (SPAN) DATA ####
#############################################################

##############
## Baseline ##
##############
SPAN.NEO.raw.data <- read_excel(paste(span.data.dir, "Baseline/Participant/Raw/SPAN_baseline_NEO-PI-R.xlsx", sep = ""),
                                 na = ".")
SPAN.NEO.scored.data <- read_excel(paste(span.data.dir, "Baseline/Participant/Cooked/SPAN_baseline_NEO-PI-R_summary_scores.xlsx", sep = ""),  
                                  na = ".")
# Remove "P" from beginning of each variable name
names(SPAN.NEO.raw.data) <- substring(names(SPAN.NEO.raw.data), 2) # 2 tells it to start string at 2nd character
names(SPAN.NEO.scored.data) <- substring(names(SPAN.NEO.scored.data), 2)

# Fix "PARTID" variable so P added back in (b/c couldn't figure out how to ignore first column 
#                                           when removing first character from var name)
SPAN.NEO.raw.data <- rename(SPAN.NEO.raw.data,  "PARTID" = "ARTID")
SPAN.NEO.scored.data <- rename(SPAN.NEO.scored.data, "PARTID" = "ARTID")

# Create raw dataframe of only subjects w/ NEO data
SPAN.NEO.raw.data_not.NAs <- SPAN.NEO.raw.data[rowSums(is.na(select(SPAN.NEO.raw.data, -1))) 
                                                != ncol(select(SPAN.NEO.raw.data, -1)), ]

# Create list of SPAN subjects w/ baseline NEO data
SPAN.subjs.w.NEO <- SPAN.NEO.raw.data_not.NAs[["PARTID"]]

# Create scored dataframe of only subjects w/ NEO data
SPAN.NEO.scored.data_not.NAs <- filter(SPAN.NEO.scored.data, PARTID %in% SPAN.subjs.w.NEO)

##########
## FU10 ##
##########
SPAN.FU10.NEO.raw.data <- read.csv(paste(span.data.dir, "FU10/Participant/Raw/PFU10NEO.csv", sep = ""), 
                                   na.strings = ".")
SPAN.FU10.NEO.scored.data  <- read.csv(paste(span.data.dir, "FU10/Participant/Cooked/PFU10NEO.csv", sep = ""),  
                                   na.strings = ".")

# CURRENTLY COMMENTED OUT B/C MIGHT WANT TO INCLUDE NEO DATA FROM MULTIPLE TPS IN ONE MODEL
# Remove "PFU10" from beginning of each variable name
# names(SPAN.FU10.NEO.raw.data) <- substring(names(SPAN.FU10.NEO.raw.data), 6) # 6 tells it to start string at 6th character
# names(SPAN.FU10.NEO.scored.data) <- substring(names(SPAN.FU10.NEO.scored.data), 6)

# Fix "PARTID" variable name (NOT NEEDED IF HAVEN'T RUN CODE ABOVE)
# SPAN.FU10.NEO.raw.data <- rename(SPAN.FU10.NEO.raw.data, "PARTID" = "D")
# SPAN.FU10.NEO.scored.data <- rename(SPAN.FU10.NEO.scored.data, "PARTID" = "D")

# Create raw dataframe of only subjects w/ NEO data
SPAN.FU10.NEO.raw.data_not.NAs <- SPAN.FU10.NEO.raw.data[rowSums(is.na(select(SPAN.FU10.NEO.raw.data, -1))) 
                       != ncol(select(SPAN.FU10.NEO.raw.data, -1)), ]
# Create list of SPAN subjects w/ FU10 NEO data
SPAN.FU10.subjs.w.NEO <- SPAN.FU10.NEO.raw.data_not.NAs[["PARTID"]]

# Create scored dataframe of only subjects w/ NEO data 
SPAN.FU10.NEO.scored.data_not.NAs <- filter(SPAN.FU10.NEO.scored.data, PARTID %in% SPAN.FU10.subjs.w.NEO)

##########
## FU12 ##
##########
SPAN.FU12.NEO.raw.data <- read.csv(paste(span.data.dir, "FU12/Participant/Raw/PFU12NEO.csv", sep=""), 
                                   na.strings = ".")
SPAN.FU12.NEO.scored.data <- read.csv(paste(span.data.dir, "FU12/Participant/Cooked/FU12NEO_Cooked.csv", sep = ""),  
                                   na.strings = ".")

# CURRENTLY COMMENTED OUT B/C MIGHT WANT TO INCLUDE NEO DATA FROM MULTIPLE TPS IN ONE MODEL
### Remove "PFU12" from beginning of each variable name
# names(SPAN.FU12.NEO.raw.data) <- substring(names(SPAN.FU12.NEO.raw.data), 6)
# names(SPAN.FU12.NEO.scored.data) <- substring(names(SPAN.FU12.NEO.scored.data), 6)

### Fix "PARTID" variable name (don't need if didn't run above code)
# SPAN.FU12.NEO.raw.data <- rename(SPAN.FU12.NEO.raw.data, "PARTID" = "D")
# SPAN.FU12.NEO.scored.data <- rename(SPAN.FU12.NEO.scored.data, "PARTID" = "D")

# Create raw dataframe of only subjects w/ NEO data
SPAN.FU12.NEO.raw.data_not.NAs <- SPAN.FU12.NEO.raw.data[rowSums(is.na(select(SPAN.FU12.NEO.raw.data, -1))) 
                      != ncol(select(SPAN.FU12.NEO.raw.data, -1)), ]
# Create list of SPAN subjects w/ FU12 NEO data
SPAN.FU12.subjs.w.NEO <- SPAN.FU12.NEO.raw.data_not.NAs[["PARTID"]]

# Create scored dataframe of only subjects w/ NEO data 
SPAN.FU12.NEO.scored.data_not.NAs <- filter(SPAN.FU12.NEO.scored.data, PARTID %in% SPAN.FU12.subjs.w.NEO)
```

## Personality Disorder data
Load personality disorder data from SPAN to validate OCPD composite/predict OCPD score from NEO

**SIDP**
```{r load-SIDP-data, include=FALSE}
#### SIDP ####

### Baseline ###
SPAN.SIDP.raw.data <- read_excel(paste(span.data.dir, "Baseline/Participant/Raw/SPAN_baseline_SIDP.xlsx", sep = ""),
                                  na = ".")
SPAN.SIDP.scored.data <- read_excel(paste(span.data.dir, "Baseline/Participant/Cooked/SPAN_baseline_SIDP_summary_scores.xlsx", sep = ""),
                                    na = ".")

# Create dichotomous vars for # of OCPD criteria endorsed 
# (e.g. 0 = no criteria endorsed,  1 = 1 or more criteria endorsed)
SPAN.SIDP.scored.data <- mutate(SPAN.SIDP.scored.data,  
                      SIDP_AnyOCsx = ifelse(SIDPOCC > 0 ,  1,  0),  
                      SIDP_2plusOCsx = ifelse(SIDPOCC > 1,  1,  0), # 2 or more sx endorsed
                      SIDP_3plusOCsx = ifelse(SIDPOCC > 2,  1,  0)) # 3 or more sx endorsed

# Create dataframe for only subjects w/ SIDP data
# SPAN.SIDP.raw.data_not.NAs <- SPAN.SIDP.raw.data[rowSums(is.na(select(SPAN.SIDP.raw.data, -1))) 
#                                                     != ncol(select(SPAN.SIDP.raw.data,  -1)), ]
## all subjects have SIDP data, so don't need to use this dataframe

SPAN.subjs.w.SIDP <- SPAN.SIDP.raw.data[["PARTID"]]

# Create dataframe for only subjects w/ SIDP + NEO data (not using for Aim1 ML analyses)
# SPAN.SIDP.raw.data_for.analyses <- filter(SPAN.SIDP.raw.data, PARTID %in% SPAN.subjs.w.NEO)
# SPAN.SIDP.scored.data_for.analyses <- filter(SPAN.SIDP.scored.data, PARTID %in% SPAN.subjs.w.NEO)

### FU10 ###
SPAN.FU10.SIDP.raw.data <- read.csv(paste(span.data.dir, "FU10/Participant/Raw/FU10SIDP.csv", sep = ""), 
                                    na.strings = ".")
SPAN.FU10.SIDP.scored.data <- read.csv(paste(span.data.dir, "FU10/Participant/Cooked/FU10SIDP.csv", sep = ""),
                                    na.strings = ".")

# Create dichotomous vars for # of OCPD criteria endorsed 
# (e.g. 0 = no criteria endorsed,  1 = 1 or more criteria endorsed)
SPAN.FU10.SIDP.scored.data <- mutate(SPAN.FU10.SIDP.scored.data,  
              FU10SIDP_AnyOCsx =   ifelse(FU10SIDPOCC > 0,  1,  0),  
              FU10SIDP_2plusOCsx = ifelse(FU10SIDPOCC > 1,  1,  0), # 2 or more sx endorsed
              FU10SIDP_3plusOCsx = ifelse(FU10SIDPOCC > 2,  1,  0)) # 3 or more sx endorsed

# Create dichotomous var indicating if 3+ sx on two SIDPs (Baseline + FU10)
## Note: used different code than above (E.g. FU10SIDP_AnyOCsx) b/c it wasn't
##       properly handling NAs for this situation
SPAN.FU10.SIDP.scored.data <- mutate(SPAN.FU10.SIDP.scored.data,  
      TwoSIDPs_w.3plusOCsx = case_when(
          FU10SIDP_3plusOCsx == 1 & SPAN.SIDP.scored.data$SIDP_3plusOCsx == 1 ~ 1, 
          is.na(FU10SIDP_3plusOCsx) | is.na(SPAN.SIDP.scored.data$SIDP_3plusOCsx) ~ NA_real_, 
                  TRUE ~ 0))

## Subjs w/ 3+ sx on two SIDPs
# SPAN.FU10.SIDP.scored.data[which(SPAN.FU10.SIDP.scored.data$TwoSIDPs_w.3plusOCsx == 1), 1]
# IDs: 1016 1057 1084 2088 2094 2288 3080 3501

## Version that adds baseline SIDP column for 3plus OC sx to same dataframe
### results were the same so should be fine to use version above
# SPAN.FU10.SIDP.scored.data.TEST <- left_join(SPAN.FU10.SIDP.scored.data, select(SPAN.SIDP.scored.data, PARTID, SIDP_3plusOCsx), by = "PARTID")
# SPAN.FU10.SIDP.scored.data.TEST <- mutate(SPAN.FU10.SIDP.scored.data.TEST,  
#                                     TwoSIDPs_w.3plusOCsx = ifelse(FU10SIDP_3plusOCsx == 1 
#                                                                   & SIDP_3plusOCsx == 1, 1, 0))

# setdiff(select(filter(SPAN.SIDP.scored.data, SIDP_3plusOCsx == 1), PARTID),
#          select(filter(SPAN.FU10.SIDP.scored.data, FU10SIDP_3plusOCsx == 1), PARTID))

# Create dataframe for only subjects w/ SIDP data
SPAN.FU10.SIDP.raw.data_not.NAs <- SPAN.FU10.SIDP.raw.data[rowSums(is.na(select(SPAN.FU10.SIDP.raw.data, -1))) 
                                                     != ncol(select(SPAN.FU10.SIDP.raw.data, -1)), ]

# Create list of SPAN subjects w/ FU10 SIDP data
SPAN.FU10.subjs.w.SIDP <- SPAN.FU10.SIDP.raw.data_not.NAs[["PARTID"]]

# Create scored dataframe for only subjects w/ SIDP data
SPAN.FU10.SIDP.scored.data_not.NAs <- filter(SPAN.FU10.SIDP.scored.data, 
                                              PARTID %in% SPAN.FU10.subjs.w.SIDP)

# Create dataframe for only subjects w/ SIDP + NEO data (not using for Aim1 ML analyses)
# SPAN.FU10.SIDP.raw.data_for.analyses <- filter(SPAN.FU10.SIDP.raw.data_not.NAs, PARTID %in% # SPAN.FU10.subjs.w.NEO)
# SPAN.FU10.SIDP.scored.data_for.analyses <- filter(SPAN.FU10.SIDP.scored.data_not.NAs, PARTID %in% # SPAN.FU10.subjs.w.NEO)

### FU12 ###
## not administered ##
```

**FF-OCI**

- SPAN rescored items on 0-4 scale instead of 1-5 to be consistent w/ NEO-PI-R item scale
"_scaled" variables = rescaled scores that divide the facet scale total by the number of items in the facet that were completed and multiplies by # of items expecting data (only if missing 1 or less items for facet-level or 2 or less items for E, O and C domain totals. otherwise ".")
"_nomiss" variables = scores for subjs w/ complete questionnaires (i.e., not missing any Qs)
- so don't use original scores since they don't properly account for missing data

```{r load-FFOCI-data}
#### FF-OCI (Five Factor Obsessive Compulsive Inventory) - Short Form (48 item) ####

### Baseline - not administered ###

### FU10 ###
# N=979 complete data (not missing responses to any items)
SPAN.FU10.FFOCI.raw.data <- read.csv(paste(span.data.dir, "FU10/Participant/Raw/FU10FFOCI.csv", sep = ""), 
                                     na.strings = ".")
SPAN.FU10.FFOCI.scored.data <- read.csv(paste(span.data.dir, "FU10/Participant/Cooked/FU10FFOCI.csv", 
                                              sep = ""), na.strings = ".")
### Add total score column that is a simple sum of all 48 items 
## NOTE: RAW DATA TOTAL USES ORIGINAL 1-5 SCALE, INSTEAD OF SPAN'S 0-4 SCALE ##
SPAN.FU10.FFOCI.raw.data <- SPAN.FU10.FFOCI.raw.data %>%
  rowwise() %>% # Need to group df by row, otherwise mutate calculates sum across all rows
  mutate(FU10FFOCI_Raw.Total.w.na = sum(c_across(FU10FFOCI1:FU10FFOCI48))) %>%
         #FU10FFOCI_Raw.Total.na.ignored = sum(c_across(FU10FFOCI1:FU10FFOCI48), na.rm = TRUE))
  ungroup()

SPAN.FU10.FFOCI.scored.data <- SPAN.FU10.FFOCI.scored.data %>%
  rowwise() %>% # Need to group df by row, otherwise mutate calculates sum across all rows
  mutate(FU10FFOCI_Total = sum(c(FU10OCN1, FU10OCE1, FU10OCE5,
                                 FU10OCO3, FU10OCO4, FU10OCO6,
                                 FU10OCC1, FU10OCC2, FU10OCC3,
                                 FU10OCC4, FU10OCC5, FU10OCC6)),
         FU10FFOCI_Scaled.Total = sum(c(FU10OCN1_scaled, FU10OCE1_scaled, FU10OCE5_scaled,
                                        FU10OCO3_scaled, FU10OCO4_scaled, FU10OCO6_scaled,
                                        FU10OCC1_scaled, FU10OCC2_scaled, FU10OCC3_scaled,
                                        FU10OCC4_scaled, FU10OCC5_scaled, FU10OCC6_scaled)),
         FU10FFOCI_NoMiss.Total = sum(c(FU10OCN1_nomiss, FU10OCE1_nomiss, FU10OCE5_nomiss,
                                        FU10OCO3_nomiss, FU10OCO4_nomiss, FU10OCO6_nomiss,
                                        FU10OCC1_nomiss, FU10OCC2_nomiss, FU10OCC3_nomiss,
                                        FU10OCC4_nomiss, FU10OCC5_nomiss, FU10OCC6_nomiss))) %>%
  ungroup()
# Create list of subjs w/ FU10 FFOCI data
SPAN.FU10.subjs.w.FFOCI <- SPAN.FU10.FFOCI.raw.data[rowSums(is.na(select(SPAN.FU10.FFOCI.raw.data, -1))) 
                                                != ncol(select(SPAN.FU10.FFOCI.raw.data, -1)), ] %>%
                          select(PARTID) %>% pull(PARTID)

### FU12 ###
SPAN.FU12.FFOCI.raw.data <- read.csv(paste(span.data.dir, "FU12/Participant/Raw/FU12FFOCI.csv", 
                                           sep = ""), na.strings = ".")
SPAN.FU12.FFOCI.scored.data <- read.csv(paste(span.data.dir, "FU12/Participant/Cooked/PFU12FFOCI_cooked.csv",
                                              sep = ""), na.strings = ".")

### Add total score column that is a simple sum of all 48 items
## NOTE: RAW DATA USES ORIGINAL 1-5 SCALE, INSTEAD OF SPAN'S 0-4 SCALE ##
SPAN.FU12.FFOCI.raw.data <- SPAN.FU12.FFOCI.raw.data %>%
  rowwise() %>% # Need to group df by row, otherwise mutate calculates sum across all rows
  mutate(FU12FFOCI_Raw.Total.w.na = sum(c_across(FU12PFFOCI1:FU12PFFOCI48)))
        #FU12FFOCI_Raw.Total.na.ignored = sum(c_across(FU12PFFOCI1:FU12PFFOCI48), na.rm = TRUE))

SPAN.FU12.FFOCI.scored.data <- SPAN.FU12.FFOCI.scored.data %>%
  rowwise() %>% # Need to group df by row, otherwise mutate calculates sum across all rows
  mutate(FU12FFOCI_Total = sum(c(FU12OCN1_score, FU12OCE1_score, FU12OCE5_score,
                                        FU12OCO3_score, FU12OCO4_score, FU12OCO6_score,
                                        FU12OCC1_score, FU12OCC2_score, FU12OCC3_score,
                                        FU12OCC4_score, FU12OCC5_score, FU12OCC6_score)),
         FU12FFOCI_Scaled.Total = sum(c(FU12OCN1_scaled, FU12OCE1_scaled, FU12OCE5_scaled,
                                        FU12OCO3_scaled, FU12OCO4_scaled, FU12OCO6_scaled,
                                        FU12OCC1_scaled, FU12OCC2_scaled, FU12OCC3_scaled,
                                        FU12OCC4_scaled, FU12OCC5_scaled, FU12OCC6_scaled)),
         FU12FFOCI_NoMiss.Total = sum(c(FU12OCN1_nomiss, FU12OCE1_nomiss, FU12OCE5_nomiss,
                                        FU12OCO3_nomiss, FU12OCO4_nomiss, FU12OCO6_nomiss,
                                        FU12OCC1_nomiss, FU12OCC2_nomiss, FU12OCC3_nomiss,
                                        FU12OCC4_nomiss, FU12OCC5_nomiss, FU12OCC6_nomiss)))

# Create list of subjs w/ FU12 FFOCI data
SPAN.FU12.subjs.w.FFOCI <- SPAN.FU12.FFOCI.raw.data[rowSums(is.na(select(SPAN.FU12.FFOCI.raw.data, -1))) 
                                                != ncol(select(SPAN.FU12.FFOCI.raw.data, -1)), ] %>%
                            select(PARTID) %>% pull(PARTID)
```

**MAPP**
```{r load-MAPP-data}
#### Multi-source Assessment of Personality Pathology (MAPP) ####

### Baseline ###
SPAN.MAPP.raw.data <- read_excel(paste(span.data.dir, "Baseline/Participant/Raw/PMAPP.xlsx", sep = ""),  
                                 na = ".")
SPAN.MAPP.scored.data <- read_excel(paste(span.data.dir,"Baseline/Participant/Cooked/PMAPP.xlsx", sep = ""),
                                 na = ".")

# Create dichotomous vars for # of OCPD criteria endorsed 
# (e.g. 0 = no criteria endorsed,  1 = 1 or more criteria endorsed)
SPAN.MAPP.scored.data <- mutate(SPAN.MAPP.scored.data,  
                                MAPP_AnyOCsx = ifelse(PMAPPOCC > 0 ,  1,  0),  
                                MAPP_2plusOCsx = ifelse(PMAPPOCC > 1,  1,  0), # 2 or more sx endorsed
                                MAPP_3plusOCsx = ifelse(PMAPPOCC > 2,  1,  0)) # 3 or more sx endorsed
# Create list of subjs w/ baseline MAPP data
SPAN.subjs.w.MAPP <- SPAN.MAPP.raw.data[rowSums(is.na(select(SPAN.MAPP.raw.data, -1))) 
                                                != ncol(select(SPAN.MAPP.raw.data, -1)), ] %>%
                    select(PARTID) %>% pull(PARTID)

### FU10 ###
SPAN.FU10.MAPP.raw.data <- read.csv(paste(span.data.dir, "FU10/Participant/Raw/PFU10MAPP.csv", sep = ""),  
                                    na.strings = ".")
SPAN.FU10.MAPP.scored.data <- read.csv(paste(span.data.dir, "FU10/Participant/Cooked/PFU10MAPP.csv", sep = ""),
                                    na.strings = ".")
# Create dichotomous vars for # of OCPD criteria endorsed 
# (e.g. 0 = no criteria endorsed,  1 = 1 or more criteria endorsed)
SPAN.FU10.MAPP.scored.data <- mutate(SPAN.FU10.MAPP.scored.data,  
            FU10MAPP_AnyOCsx = ifelse(PFU10MAPPOCC > 0 ,  1,  0),  
            FU10MAPP_2plusOCsx = ifelse(PFU10MAPPOCC > 1,  1,  0), # 2 or more sx endorsed
            FU10MAPP_3plusOCsx = ifelse(PFU10MAPPOCC > 2,  1,  0)) # 3 or more sx endorsed
# Create list of subjs w/ FU10 MAPP data
SPAN.FU10.subjs.w.MAPP <- SPAN.FU10.MAPP.raw.data[rowSums(is.na(select(SPAN.FU10.MAPP.raw.data, -1))) 
                                                != ncol(select(SPAN.FU10.MAPP.raw.data, -1)), ] %>%
                          select(PARTID) %>% pull(PARTID)

### FU12 ###
## for some reason FU12 was scored from 1-5 instead of 0-4 like baseline and FU10. 
## I realized this on 5/5/22 and Isabella rescored the data (the _fixed files)
SPAN.FU12.MAPP.raw.data <- read.csv(paste0(span.data.dir, "FU12/Participant/Raw/PFU12MAPP_fixed.csv"),
                                    na.strings = ".")
SPAN.FU12.MAPP.scored.data <- read.csv(paste0(span.data.dir, "FU12/Participant/Cooked/PFU12MAPP_cooked_fixed.csv"),  
                                    na.strings = ".")

# Rename the variables I need so the same syntax as baseline and FU12
SPAN.FU12.MAPP.scored.data <- rename(SPAN.FU12.MAPP.scored.data, c(PFU12MAPPOC=PFU12MAPP_COBC_score, PFU12MAPPOC_scaled=PFU12MAPP_COBC_scaled, 
  PFU12MAPPOC_nomiss=PFU12MAPP_COBC_nomiss, PFU12MAPPOCC=PFU12MAPPCOBC_C, PFU12MAPPOCD=PFU12MAPPCOBC_D))

# Create dichotomous vars for # of OCPD criteria endorsed 
# (e.g. 0 = no criteria endorsed,  1 = 1 or more criteria endorsed)
SPAN.FU12.MAPP.scored.data <- mutate(SPAN.FU12.MAPP.scored.data,  
              FU12MAPP_AnyOCsx = ifelse(PFU12MAPPOCC > 0, 1, 0),  
              FU12MAPP_2plusOCsx = ifelse(PFU12MAPPOCC > 1, 1, 0), # 2 or more sx endorsed
              FU12MAPP_3plusOCsx = ifelse(PFU12MAPPOCC > 2, 1, 0)) # 3 or more sx endorsed
# Create list of subjs w/ FU12 MAPP data
SPAN.FU12.subjs.w.MAPP <- SPAN.FU12.MAPP.raw.data[rowSums(is.na(select(SPAN.FU12.MAPP.raw.data, -1))) 
                                                != ncol(select(SPAN.FU12.MAPP.raw.data, -1)), ] %>%
                          select(PARTID) %>% pull(PARTID)
```

## Neuroimaging Data
```{r}
# Load aseg (i.e., subcortical) data 
DNS.aseg.vol.data <- read_csv(paste0(dns.data.dir, "Freesurfer_Structure/FreeSurfer_aseg_Volume_mm3.csv"))
DNS.aseg.vol.data2 <- read_csv(paste0(dns.data.dir, "Freesurfer_Structure/FreeSurfer_aseg_SummaryMeasures.csv"))
## Note: DNS1279 had FS error. not in first spreadsheet. all NAs in second spreadsheet
## Merge the two dataframes w/ volume info 
DNS.aseg.vol.data <- left_join(DNS.aseg.vol.data, DNS.aseg.vol.data2, by = "ID")
## Delete volume.data2 once merged it w/ volume.data df
rm(DNS.aseg.vol.data2)
## Change aseg vol variables names b/c can't have "-" in variable name
names(DNS.aseg.vol.data) <- gsub("-", ".", names(DNS.aseg.vol.data))

# Load aparc (i.e., cortical) data 
## Average Cortical Thickness
## These aparc summary measures are from the Destrieux atlas but Annchen confirmed that 
## the mean cortical thickness values (which is what using from this file) is identical
## for all 3 cortical atlases
DNS.aparc.Destrx.sum.measures <- read_csv(paste0(dns.data.dir, "Freesurfer_Structure/FreeSurfer_aparc.a2009s_SummaryMeasures.csv")) %>% 
  mutate(MeanThick = round(((lhMeanThickness + rhMeanThickness)/2), digits = 2))

## Desikan-Killiany Atlas
DNS.aparc.DK.cort.thick.data <- read_csv(paste0(dns.data.dir, 
                                                "Freesurfer_Structure/FreeSurfer_aparc_ThickAvg.csv"))
DNS.aparc.DK.surf.area.data <- read_csv(paste0(dns.data.dir, 
                                               "Freesurfer_Structure/FreeSurfer_aparc_SurfArea.csv"))
DNS.aparc.DK.vol.data <- read_csv(paste0(dns.data.dir, 
                                         "Freesurfer_Structure/FreeSurfer_aparc_GrayVol.csv"))
### Combine dfs into list. lst=Tibble version list, auto-generates element names
DNS.aparc.DK.data <- lst(DNS.aparc.DK.cort.thick.data, DNS.aparc.DK.surf.area.data, 
                         DNS.aparc.DK.vol.data)
### Add avg. CT to dfs to use as covariate
DNS.aparc.DK.data <- lapply(DNS.aparc.DK.data, function(df) left_join(df,
    select(DNS.aparc.Destrx.sum.measures, c(ID, MeanThick, lhMeanThickness, rhMeanThickness)), 
    by = "ID"))
### Add eTIV (estimated ICV) to dfs to use as covariate
DNS.aparc.DK.data <- lapply(DNS.aparc.DK.data, function(df) left_join(df, 
                      select(DNS.aseg.vol.data, c(ID, eTIV)), by = "ID"))
### DNS1279 is missing right hemi data. remove and make N=1,305
DNS.aparc.DK.data <- lapply(DNS.aparc.DK.data, function(df) {
      filter(df, ID != "DNS1279")})
### Delete ind. dataframes to save space in env.
rm(DNS.aparc.DK.cort.thick.data, DNS.aparc.DK.surf.area.data, DNS.aparc.DK.vol.data)
### Extract list to environment to update original dfs in env.
# list2env(DNS.aparc.DK.data, environment())

## Desikan-Killiany-Tourville Atlas
DNS.aparc.DKT.cort.thick.data <- read_csv(paste0(dns.data.dir,
    "Freesurfer_Structure/FreeSurfer_aparc.DKTatlas40_ThickAvg.csv"))
DNS.aparc.DKT.surf.area.data <- read_csv(paste0(dns.data.dir, 
    "Freesurfer_Structure/FreeSurfer_aparc.DKTatlas40_SurfArea.csv"))
DNS.aparc.DKT.vol.data <- read_csv(paste0(dns.data.dir,
    "Freesurfer_Structure/FreeSurfer_aparc.DKTatlas40_GrayVol.csv"))

### Combine dfs into list. lst=Tibble version list, auto-generates element names
DNS.aparc.DKT.data <- lst(DNS.aparc.DKT.cort.thick.data, DNS.aparc.DKT.surf.area.data, 
                          DNS.aparc.DKT.vol.data)

### Add avg. CT to dfs to use as covariate
DNS.aparc.DKT.data <- lapply(DNS.aparc.DKT.data, function(df) left_join(df,
    select(DNS.aparc.Destrx.sum.measures, c(ID, MeanThick, lhMeanThickness, rhMeanThickness)), 
    by = "ID"))
### Add eTIV (estimated ICV) to dfs to use as covariate
DNS.aparc.DKT.data <- lapply(DNS.aparc.DKT.data, function(df) left_join(df, 
                      select(DNS.aseg.vol.data, c(ID, eTIV)), by = "ID"))

### DNS1279 is missing right hemi data. remove and make N=1,305
DNS.aparc.DKT.data <- lapply(DNS.aparc.DKT.data, function(df) {
      filter(df, ID != "DNS1279")})
### Delete ind. dataframes to save space in env.
rm(DNS.aparc.DKT.cort.thick.data, DNS.aparc.DKT.surf.area.data, DNS.aparc.DKT.vol.data)
## Extract list to environment to update original dfs in env.
# list2env(DNS.aparc.DKT.data, environment())

## Destrieux Atlas
DNS.aparc.Destrieux.cort.thick.data <- read_csv(paste0(dns.data.dir,
    "Freesurfer_Structure/FreeSurfer_aparc.a2009s_ThickAvg.csv"))
DNS.aparc.Destrieux.surf.area.data <- read_csv(paste0(dns.data.dir, 
    "Freesurfer_Structure/FreeSurfer_aparc.a2009s_SurfArea.csv"))
DNS.aparc.Destrieux.vol.data <- read_csv(paste0(dns.data.dir,
    "Freesurfer_Structure/FreeSurfer_aparc.a2009s_GrayVol.csv"))

### Combine dfs into list. lst=Tibble version list, auto-generates element names
DNS.aparc.Destrieux.data <- lst(DNS.aparc.Destrieux.cort.thick.data, DNS.aparc.Destrieux.surf.area.data, 
                          DNS.aparc.Destrieux.vol.data)

### Add avg. CT to dfs to use as covariate
DNS.aparc.Destrieux.data <- lapply(DNS.aparc.Destrieux.data, function(df) left_join(df,
    select(DNS.aparc.Destrx.sum.measures, c(ID, MeanThick, lhMeanThickness, rhMeanThickness)), 
    by = "ID"))
### Add eTIV (estimated ICV) to dfs to use as covariate
DNS.aparc.Destrieux.data <- lapply(DNS.aparc.Destrieux.data, function(df) left_join(df, 
                      select(DNS.aseg.vol.data, c(ID, eTIV)), by = "ID"))

### DNS1279 is missing right hemi data. remove and make N=1,305
DNS.aparc.Destrieux.data <- lapply(DNS.aparc.Destrieux.data, function(df) {
      filter(df, ID != "DNS1279")})
### Delete ind. dataframes to save space in env.
rm(DNS.aparc.Destrieux.cort.thick.data, DNS.aparc.Destrieux.surf.area.data, DNS.aparc.Destrieux.vol.data)
## Extract list to environment to update original dfs in env.
# list2env(DNS.aparc.Destrieux.data, environment())

# Add scanner info to dataframes
## Load file w/ exam ID that can use to create scanner variable
## According to Annchen (at Duke), " If you have the scan IDs (format YYYYMMDD_#####, where ##### is the unique 5-digit scan ID), it’s easy to infer the scanner because for one of them (the newer one) the scan IDs are much higher, starting at 25###, whereas for the other one they range from 10### to 21###."
DNS.scanner.info <- read_xlsx(paste0(dns.data.dir, "DNS_VBM.xlsx"), sheet = "Paths", skip = 1)
# Row 29 is all blank. remove it. also remove duplicate scan sessions for 2 subjs that don't include the anatomicals (so make sure using the correct scanner ID for the included anatomical scan)
DNS.scanner.info <- DNS.scanner.info[-c(6,12,29), ]
# Create scanner variable, rename DNS ID to ID
DNS.scanner.info <- DNS.scanner.info %>%
  dplyr::rename(ID = DNSID) %>%
  mutate(ScanID = str_sub(Exam, start = -5)) %>%
  mutate(Scanner = as.factor(case_when(ScanID < 22000 ~ "Scanner1",
                             ScanID >= 25000 ~ "Scanner2")))
## Add scanner variable to neuroimaging dataframes
add.scanner <- function(df){
   left_join(df, select(DNS.scanner.info, c(ID, Scanner)), by = "ID")}

DNS.aseg.vol.data <- add.scanner(DNS.aseg.vol.data)
DNS.aparc.DK.data <- lapply(DNS.aparc.DK.data, function(df)
    df <- add.scanner(df))
DNS.aparc.DKT.data <- lapply(DNS.aparc.DKT.data, function(df)
    df <- add.scanner(df))
DNS.aparc.Destrieux.data <- lapply(DNS.aparc.Destrieux.data, function(df)
    df <- add.scanner(df))
### Extract list to environment to update original dfs in env.
#list2env(DNS.aparc.DK.data, environment())
#list2env(DNS.aparc.DKT.data, environment())

# Determine subjects to exclude who do not pass QC 
## David used 1,299 subjects for structural DNS data in his BPD paper. 
## Look at QC notes in ~/Library/CloudStorage/Box-Box/research/datasets/DNS/Freesurfer_Structure/INFO 
## to decide if should exclude additional subjects
# Conclusion: it is hard to decide without seeing the images myself. 

## DNS group's paper on personality + brain structure (Avinun et al. 2020) excluded 
## an additional 51 subjects beyond 1305 for small to moderate surface errors.
## Those must be all subjects w/ "notes for possible exclusion" in the ".../Freesurfer_Structure/INFO/BrainVolume_Freesurfer.csv" files. 
FS.QC.data <- read_xlsx("/Users/Shared/SharedDocs/from.Box/research/datasets/DNS/Freesurfer_Structure/INFO/BrainVolume_Freesurfer.xlsx", sheet = 2)

# Exclude subjects w/ reasons for exclusion in BrainVolume_FreeSurfer.xlsx
DNS.subjs.to.exclude <- filter(FS.QC.data, `Notes for possible exclusion` != ".") %>% 
  select(ID)

# Remove subjects w/ bad structural MRI data 
## Aseg
DNS.aseg.vol.data_filtered <- filter(DNS.aseg.vol.data, 
                                     !(ID %in% DNS.subjs.to.exclude$ID))
## Desikan-Killiany cortical data
DNS.aparc.DK.data_filtered <- lapply(DNS.aparc.DK.data, function(df) {
                                   filter(df, !(ID %in% DNS.subjs.to.exclude$ID))})
names(DNS.aparc.DK.data_filtered) <- paste0(names(DNS.aparc.DK.data_filtered), "_filtered")
## Desikan-Killiany-Tourville cortical data
DNS.aparc.DKT.data_filtered <- lapply(DNS.aparc.DKT.data, function(df) {
                                   filter(df, !(ID %in% DNS.subjs.to.exclude$ID))})
names(DNS.aparc.DKT.data_filtered) <- paste0(names(DNS.aparc.DKT.data_filtered), "_filtered")
## Destrieux atlas
DNS.aparc.Destrieux.data_filtered <- lapply(DNS.aparc.Destrieux.data, function(df) {
                                   filter(df, !(ID %in% DNS.subjs.to.exclude$ID))})
names(DNS.aparc.Destrieux.data_filtered) <- paste0(names(DNS.aparc.Destrieux.data_filtered), "_filtered")

## Extract list to environment to create ind. filtered dfs in env.
list2env(DNS.aparc.DK.data_filtered, environment())
list2env(DNS.aparc.DKT.data_filtered, environment())
list2env(DNS.aparc.Destrieux.data_filtered, environment())

## Note: if need breakdown of subjects excluded b/c of MRI, see ~/Library/CloudStorage/Box-Box/research/datasets/DNS/Freesurfer_Structure/INFO/BrainVolume_FreeSurfer.xlsx "Notes" sheet
```

## Other Data

### Demographic data
```{r}
# SPAN demographic data
SPAN.demo.data <- read.csv(paste(span.data.dir, "SPAN_PDEMO.csv", sep = ""),
                           na = ".")
SPAN.age.data <- read.csv(paste(span.data.dir, "PAGE.fixedFU12s.csv", sep = ""),
                          na = ".")
SPAN.demo.data <- full_join(SPAN.demo.data, SPAN.age.data, by = c("PARTID", "PDOB"))

## Remove separate age dataframe since now merged w/ demo.data
rm(SPAN.age.data)

## Fix missing FU12 ages (did once. no longer need b/c created file PAGE.fixedFU12s.csv to load)
# missingFU12ages <- read.csv(paste(span.data.dir, "SPAN_missingFU12ages.csv", sep = ""))
# SPAN.demo.data.TEST <- SPAN.demo.data
# SPAN.demo.data.TEST <- left_join(SPAN.demo.data.TEST, missingFU12ages, by = "PARTID",
#                                  suffix = c(".orig", ".revised"))
# SPAN.demo.data.TEST <- mutate(SPAN.demo.data.TEST, PFU12AGE.fixed = ifelse(PARTID %in% FU12.missing.age, 
#                                                 PFU12AGE.revised, PFU12AGE.orig))
# select(SPAN.demo.data.TEST, c(PARTID, PDOB, PAGE, PFU5AGE, PFU10AGE, PFU12AGE.fixed)) %>%
#   write.csv(., file = "PAGE.fixedFU12s.csv", row.names = FALSE, na = ".")
  
## Trying to calculate FU12 ages myself to double-check the values
# SPAN.demo.data.TEST <- mutate(SPAN.demo.data.TEST,
#                               PDOB.asDate = as.Date(PDOB, "%m/%d/%y"))

## Create dataframe of only subjects w/ NEO data (not using for Aim1 ML analyses)
# SPAN.demo.data_for.analyses <- filter(SPAN.demo.data, PARTID %in% SPAN.subjs.w.NEO)

# DNS gender + language data (age, race, and ethnicity already included in NEO files)
DNS.demo.data <- haven::read_spss(paste(dns.data.dir, "DUKE_NEUROGENETICS_STUDY_FINAL.sav", sep = ""),
                           col_select = c("ID", "SEX", "AGE", "LANGUAGE", "RACE", "LATINO"))
## variable called sex, although question asked participants their gender. renaming to gender
names(DNS.demo.data)[1] <- "GENDER" # sex is first variable in df b/c ID was later col in .sav

## Convert gender and race variables to factor and change age to numeric
DNS.demo.data <- mutate(DNS.demo.data, 
          GENDER.factor = factor(GENDER, levels = c(1,2), 
                        labels = c("Male", "Female")),
          RACE = factor(RACE, levels = c(1:6),
                        labels = c("White", "Black", "Asian", "NativeAmer", "Multiracial", "Other")),
          AGE = as.numeric(as.character(labelled::to_factor(AGE)))) 
```

Informant data
- not using
```{r eval=FALSE, include=FALSE}
SPAN.MAPP.informant.scored.data <- read_excel(paste(span.data.dir, "Baseline/Informant/Cooked/IMAPP.xlsx",
                                                    sep = ""), na = ".")
```

### Doug's datasets
Doug Samuel (Purdue University) provided three datasets to use for external validation of OCPD models. 
Two have IPIP-NEO instead of NEO-PI-R data, so can't use for direct external validation of model.
The third, from the original 2012 FFOCI paper, has NEO-PI-R and FFOCI data and is thus being 
used to externally validate the OCPD (i.e., FFOCI predictive) model trained in SPAN data.
```{r}
# Dataset from original 2012 FFOCI Paper 
Doug.2012paper.data <- read_spss("../Data/FFOCI.datasets.from.Doug/2012_FFOCI_Paper/Initial.Study-Validation.Half.sav")
# Datasets w/ IPIP-NEO Data
## not currently using (there are 2 in that directory)

# Add made-up ID variable to keep track of rows/data (the data was deidentified and didn't have original study ID)
Doug.2012paper.data$Fake.ID <- seq(from = 1, to = 203, by = 1)
```

### Criterion Validity data
```{r}
# Social Adjustment Scale
# Social Functioning Scale
# Social Network Questionnaire
# Supplementary demographics - help seeking (mental health tx + physical help at FU10 + FU12)
# Health Behavior Checklist
# Satisfaction with Life Scale
# UCLA Loneliness Scale

# Baseline - this also contains the personality and PD data
informantBLData <- setNames(lapply(list.files(path = paste0(span.data.dir, "Baseline/Informant/Cooked"), pattern = "*.xlsx", 
                                              full.names = TRUE), read_xlsx, na = "."),
        str_replace(list.files(path = paste0(span.data.dir, "Baseline/Informant/Cooked"), pattern = "*.xlsx"), ".xlsx", ""))
critValBLData <-  setNames(lapply(list.files(path = paste0(span.data.dir, "Baseline/Participant/Cooked"), pattern = "P*.xlsx", 
                                             full.names = TRUE), read_xlsx, na = "."), 
        str_replace(list.files(path = paste0(span.data.dir, "Baseline/Participant/Cooked"), pattern = "*.xlsx"), ".xlsx", "")) 
BLDemoSup <- read_xlsx(paste0(span.data.dir, "Baseline/Participant/PDEMO Supplementary.xlsx"), na=".") 

# FU10 - this also contains the personality and PD data
informantFU10Data <- setNames(lapply(list.files(path = paste0(span.data.dir, "FU10/Informant/Cooked"), pattern = "*.csv", 
                                                full.names = TRUE), read.csv, na.strings = "."),
                        str_replace(list.files(path = paste0(span.data.dir, "FU10/Informant/Cooked"), pattern = "*.csv"), ".csv", ""))
critValFU10Data <- setNames(lapply(list.files(path = paste0(span.data.dir, "FU10/Participant/Cooked"), pattern = "*.csv", 
                                              full.names = TRUE),  read.csv, na.strings = "."), 
                        str_replace(list.files(path = paste0(span.data.dir, "FU10/Participant/Cooked"), pattern = "*.csv"), ".csv", ""))
FU10Demo <- read.csv(paste0(span.data.dir, "FU10/Participant/PFU10DEMO.csv"), na.strings = ".")

# FU12 - this also contains the personality and PD data
informantFU12Data <- setNames(lapply(list.files(path = paste0(span.data.dir, "FU12/Informant/Cooked"), pattern = "*.csv", 
                                                full.names = TRUE), read.csv, na.strings = "."),
                            str_replace(list.files(path = paste0(span.data.dir, "FU12/Informant/Cooked"), pattern = "*.csv"), ".csv", ""))
critValFU12Data <- setNames(lapply(list.files(path = paste0(span.data.dir, "FU12/Participant/Cooked"), pattern = "*.csv", 
                                              full.names = TRUE), read.csv, na.strings = "."),
                            str_replace(list.files(path = paste0(span.data.dir, "FU12/Participant/Cooked"), pattern = "*.csv"), ".csv", ""))
FU12Demo <- read.csv(paste0(span.data.dir, "FU12/Participant/PFU12DEMO.csv"), na.strings = ".")
```

# Check Data
```{r}
# Determine how many SPAN subjs have data for all 3 TPs (Baseline, FU10, and FU12) 
# and all measures of interest (NEO, SIDP, FFOCI, MAPP)
SPAN.subjs.w.all.data <- Reduce(intersect, 
                list(SPAN.subjs.w.NEO, SPAN.FU10.subjs.w.NEO, SPAN.FU12.subjs.w.NEO,
                    SPAN.subjs.w.SIDP, SPAN.FU10.subjs.w.SIDP, # No SIDP at FU12
                    SPAN.FU10.subjs.w.FFOCI, SPAN.FU12.subjs.w.FFOCI, # No FFOCI at baseline
                    SPAN.subjs.w.MAPP, SPAN.FU10.subjs.w.MAPP, SPAN.FU12.subjs.w.MAPP)) 
# N=826
SPAN.subjs.w.all.baseline <- Reduce(intersect, list(SPAN.subjs.w.NEO,SPAN.subjs.w.SIDP,SPAN.subjs.w.MAPP)) 
# N=1,610
SPAN.subjs.w.all.FU10 <- Reduce(intersect, list(SPAN.FU10.subjs.w.NEO,SPAN.FU10.subjs.w.SIDP,
                                                SPAN.FU10.subjs.w.MAPP, SPAN.FU10.subjs.w.FFOCI))
# N=1,032
SPAN.subjs.w.all.FU12 <- Reduce(intersect, list(SPAN.FU12.subjs.w.NEO,SPAN.FU12.subjs.w.MAPP,
                                                SPAN.FU12.subjs.w.FFOCI))
# N=904
```

## NEO data
```{r check-NEO-data, eval=FALSE, include=FALSE}
# DNS #
summary(DNS.NEO.scored.data)
DNS.NEO.raw.data_not.NAs %>% summarise_if(is.numeric, max, na.rm = TRUE)
multi.hist(DNS.NEO.scored.data[ ,  2:36])

# Check how many DNS subjs have complete NEO data
table(complete.cases(DNS.NEO.raw.data))
# N=1359 (1 MISSING SOME - DNS0007)

# SPAN #
## Baseline ##
summary(SPAN.NEO.scored.data_not.NAs)
multi.hist(SPAN.NEO.scored.data_not.NAs[ ,  2:36])

# Check how many SPAN subjs have complete baseline NEO data
table(complete.cases(SPAN.NEO.raw.data))
# N=1336 (so ~300 subjs don't have complete data)
# Check item-level missing data
colSums(is.na(SPAN.NEO.raw.data))

## FU10 ##
summary(SPAN.FU10.NEO.scored.data_not.NAs)
multi.hist(SPAN.FU10.NEO.scored.data_not.NAs[ ,  2:36])

# Check how many SPAN subjs have complete FU10 NEO data
table(complete.cases(SPAN.FU10.NEO.raw.data))
# N=826 (SO 804 subjs don't have complete data)

# Check item-level missing data
colSums(is.na(SPAN.FU10.NEO.raw.data))

## FU12 ##
summary(SPAN.FU12.NEO.scored.data_not.NAs)
multi.hist(SPAN.FU12.NEO.scored.data[ ,  2:36])

# Check how many SPAN subjs have complete FU12 NEO data
table(complete.cases(SPAN.FU12.NEO.raw.data))
# N=623 

### ERROR IN DATA!!!! ###
### Variable PFU12NEOC66 has scores of 5, but max should be 4. 
### 2/25/22 - AM looking into this. Emailed IH
### 3/1/22 - IH identified Qualtrics scoring error and fixed. 
```

## Personality Disorder Data
```{r check-personality-data, eval=FALSE, include=FALSE}
# SIDP #
summary(SPAN.SIDP.raw.data)
summary(SPAN.SIDP.scored.data)
table(complete.cases(SPAN.SIDP.raw.data))

## OCPD ##
## Baseline ##
# Num of OCPD criteria endorsed
hist(SPAN.SIDP.scored.data$SIDPOCC, col = "light blue")
# Total score for OCPD items
hist(SPAN.SIDP.scored.data$SIDPOC, col = "light blue")
## OCPD Diagnoses
hist(SPAN.SIDP.scored.data$SIDPOCD, col = "light blue")

## FU10 ##
# Num of OCPD criteria endorsed
hist(SPAN.FU10.SIDP.scored.data$FU10SIDPOCC, col = "light blue")
# Total score for OCPD items
hist(SPAN.FU10.SIDP.scored.data$FU10SIDPOC, col = "light blue")
## OCPD Diagnoses
hist(SPAN.FU10.SIDP.scored.data$FU10SIDPOCD, col = "light blue")

# Comparing BL and FU10 and FU12 OCPD dx n's
BL.OCPD.PARTID <- filter(SPAN.FINAL.DATA$SPAN.bl.NEO.and.OCPD.data.not, SIDPOCD == 1) %>%
  select(., c(PARTID, SIDPOCD, SIDPOCC, SIDPOC_scaled, PMAPPOCD, PMAPPOCC, PMAPPOC_scaled))

OCPD.PARTID <- left_join(BL.OCPD.PARTID, select(SPAN.FINAL.DATA$SPAN.FU10.NEO.and.OCPD.data.n, c(PARTID, FU10SIDPOCD, FU10SIDPOCC, FU10SIDPOC_scaled, PFU10MAPPOCD, PFU10MAPPOCC, PFU10MAPPOC_scaled)), 
                         by = "PARTID")

OCPD.PARTID <- left_join(OCPD.PARTID, select(SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n, c(PARTID, PFU12MAPPOCD, PFU12MAPPOCC, PFU12MAPPOC_scaled)), by = "PARTID")

# write_csv(OCPD.PARTID, "SPAN.OCPD.data.for.bl.SIDP.dx.csv")

# FFOCI #
# Note: For summary scores, SPAN rescored FFOCI data as 0-4 scale instead of 1-5
# The scaled items (X_scaled) in the summary file rescale the raw sum score (ex: FU10OCN1) to account for # missing responses, but only if only 1 Q out of 4 for the facet subscales is missing. If 0, 2, 3 or 4 Qs missing, X_scaled will be "."
# For Missing Data: It appears to me that the code is written such that if there are missing items, "nomiss" = ".",
# and if there aren't # any missing responses, "nomiss" = the raw sum score. 

## FU10 ##
summary(SPAN.FU10.FFOCI.raw.data)
summary(SPAN.FU10.FFOCI.scored.data)
multi.hist(SPAN.FU10.FFOCI.scored.data[ , 2:49])
hist(SPAN.FU10.FFOCI.raw.data$FU10FFOCI_Total.complete, col = "light blue")
table(complete.cases(SPAN.FU10.FFOCI.raw.data))
# Number of questions skipped
table(rowSums(is.na(SPAN.FU10.FFOCI.raw.data) | SPAN.FU10.FFOCI.raw.data == ""))

## FU12 ##
hist(SPAN.FU12.FFOCI.raw.data$FU12FFOCI_Total.w.na, col = "light blue")
summary(SPAN.FU12.FFOCI.raw.data)

# MAPP # 
## Baseline ##
hist(SPAN.MAPP.scored.data$PMAPPOC, col = "light blue")
summary(SPAN.MAPP.raw.data)
# Number of questions skipped
table(rowSums(is.na(SPAN.MAPP.raw.data) | SPAN.MAPP.raw.data == ""))
## FU10 ##
hist(SPAN.FU10.MAPP.scored.data$PFU10MAPPOC_scaled, col = "light blue")
summary(SPAN.FU10.MAPP.scored.data)
## FU12 ##
hist(SPAN.FU12.MAPP.scored.data$PFU12MAPPOC, col = "light blue")
```

## Neuroimaging Data
```{r}
colSums(is.na(DNS.aseg.vol.data))
colSums(is.na(DNS.aseg.vol.data2))
colSums(is.na(DNS.aparc.DK.cort.thick.data))
colSums(is.na(DNS.aparc.DK.surf.area.data))
colSums(is.na(DNS.aparc.DK.vol.data))

# Check data for unexpected values
# rules <- validator()
```

## Doug's data
Check data and compare to publication
```{r check.data}
## Demographics - listed in publication for full sample. data is only for validation half
## so can't compare to publication but included for information purposes
mean(Doug.2012paper.data$Age, na.rm = TRUE)
sd(Doug.2012paper.data$Age, na.rm = TRUE)
table(Doug.2012paper.data$Age, useNA = "always")
table(Doug.2012paper.data$Gender, useNA = "always")
table(Doug.2012paper.data$Ethnicity, useNA = "always")
table(Doug.2012paper.data$Hispanic, useNA = "always")

## WISPI OCPD Scale mean item score
### Check for missing data
apply(Doug.2012paper.data[ ,723:742], 2, function(x) table(is.na(x)))
# Results: none. all look imputed
mean(rowMeans(Doug.2012paper.data[ ,723:742], na.rm = TRUE))
# mean = 4.39; sd = 1.497 (same as publication)

## SNAP-2 OCPD scale mean T score 
mean(Doug.2012paper.data$Snap_OCPD_t)
sd(Doug.2012paper.data$Snap_OCPD_t)
# MEAN = 52.4; SD = 12.4 (same as publication)

## DAPP-BQ Compulsivity Scale
mean(Doug.2012paper.data$DAPPcompulsivity)
sd(Doug.2012paper.data$DAPPcompulsivity)
# Mean = 52.66; SD = 12.05 (basically same as publication. depends on SD rounding)

## FFOCI Scale Means + SDs
apply(Doug.2012paper.data[ , c(paste0(rep("ffoci", 12), c("c1", "c2", "c3", "c4", "c5", "c6",
                                                         "e1", "e5", "n1", "o3", "o4", "o6")))],
      2, describe)
# 9/12 scales slightly different values for dataset vs. publications 

## FFOCI Scales Intercorrelations
round(cor(Doug.2012paper.data[ , c(paste0(rep("ffoci", 12), c("c1", "c2", "c3", "c4", "c5", "c6",
                                                          "e1", "e5", "n1", "o3", "o4", "o6")))]), 2)
# same as publication
```

# OCPD Scores
Use machine learning algorithms to predict OCPD "score" from NEO personality data

#### 1) Combine dataframes so all data in single one #### --------------------
```{r}
# Set seed for reproducibility (b/c splitting data + CV randomly assigns rows to test set)
set.seed(62) 

# Start parallel processing
cl <- makePSOCKcluster(5) # specify number of cores to use (my laptop has 8 but diminishing returns for >5)
registerDoParallel(cl)

# Specify where results/output should go (UPDATE THIS WHENEVER DOING SOMETHING DIFFERENT)
results.dir <- "~/Library/CloudStorage/Box-Box/research/projects/dissertation/Results/ML/Aim1.OCPD/OCPD.NAs.filtered.models/from.caretList/parallel/seed.GIVEN/all.unresid.models.run/NEW.all.rerun.fixed.FU12MAPP/"

#### 1) Combine dataframes so all data in single one #### --------------------
# Baseline
SPAN.bl.NEO.and.OCPD.data <- 
    SPAN.NEO.raw.data %>% full_join(SPAN.NEO.scored.data, by = "PARTID") %>%
    full_join(SPAN.SIDP.raw.data, by = "PARTID") %>% full_join(SPAN.SIDP.scored.data, by = "PARTID") %>%
    full_join(SPAN.MAPP.raw.data, by = "PARTID") %>% full_join(SPAN.MAPP.scored.data, by = "PARTID") %>%
    full_join(SPAN.demo.data, by = "PARTID")
## Filter this df to only include subjs w/ some data for all 3 measures (SPAN.subjs.w.all.baseline created in main script)
SPAN.bl.NEO.and.OCPD.data.notNAs <- filter(SPAN.bl.NEO.and.OCPD.data, 
                                           PARTID %in% SPAN.subjs.w.all.baseline)
# FU10
SPAN.FU10.NEO.and.OCPD.data <- 
    SPAN.FU10.NEO.raw.data %>% full_join(SPAN.FU10.NEO.scored.data, by = "PARTID") %>%
    full_join(SPAN.FU10.SIDP.raw.data, by = "PARTID") %>% full_join(SPAN.FU10.SIDP.scored.data, by = "PARTID") %>%
    full_join(SPAN.FU10.MAPP.raw.data, by = "PARTID") %>% full_join(SPAN.FU10.MAPP.scored.data, by = "PARTID") %>%
    full_join(SPAN.FU10.FFOCI.raw.data, by = "PARTID") %>% full_join(SPAN.FU10.FFOCI.scored.data, by = "PARTID") %>%
    full_join(SPAN.demo.data, by = "PARTID")
## Filter this df to only include subjs w/ some data for all 4 measures (SPAN.subjs.w.all.FU10 created in main script)
SPAN.FU10.NEO.and.OCPD.data.notNAs <- filter(SPAN.FU10.NEO.and.OCPD.data, 
                                             PARTID %in% SPAN.subjs.w.all.FU10)
# FU12
SPAN.FU12.NEO.and.OCPD.data <- 
    SPAN.FU12.NEO.raw.data %>% full_join(SPAN.FU12.NEO.scored.data, by = "PARTID") %>%
    full_join(SPAN.FU12.MAPP.raw.data, by = "PARTID") %>% full_join(SPAN.FU12.MAPP.scored.data, by = "PARTID") %>%
    full_join(SPAN.FU12.FFOCI.raw.data, by = "PARTID") %>% full_join(SPAN.FU12.FFOCI.scored.data, by = "PARTID") %>%
    full_join(SPAN.demo.data, by = "PARTID")
## Filter this df to only include subjs w/ some data for all 3 measures (SPAN.subjs.w.all.FU12 created in main script)
SPAN.FU12.NEO.and.OCPD.data.notNAs <- filter(SPAN.FU12.NEO.and.OCPD.data, 
                                             PARTID %in% SPAN.subjs.w.all.FU12)
# Combine dataframes into one list so can apply all data transformations below to all TPs at once
dfs <- list(SPAN.bl.NEO.and.OCPD.data, SPAN.bl.NEO.and.OCPD.data.notNAs,
            SPAN.FU10.NEO.and.OCPD.data, SPAN.FU10.NEO.and.OCPD.data.notNAs,
            SPAN.FU12.NEO.and.OCPD.data, SPAN.FU12.NEO.and.OCPD.data.notNAs)
names(dfs) <- c("SPAN.bl.NEO.and.OCPD.data", "SPAN.bl.NEO.and.OCPD.data.notNAs",
                "SPAN.FU10.NEO.and.OCPD.data", "SPAN.FU10.NEO.and.OCPD.data.notNAs",
                "SPAN.FU12.NEO.and.OCPD.data", "SPAN.FU12.NEO.and.OCPD.data.notNAs")

# Create dataframes of just OCPD data
# OCPD.sum.scores_SPAN.baseline <- select(SPAN.bl.NEO.and.OCPD.data,
#                                 c(SIDPOC, SIDPOC_scaled, SIDPOC_nomiss, SIDPOCC, SIDPOCD,
#                                   PMAPPOC, PMAPPOC_scaled, PMAPPOC_nomiss, PMAPPOCC, PMAPPOCD)) 
# OCPD.sum.scores_SPAN.FU10 <- select(SPAN.FU10.NEO.and.OCPD.data,
#                                 c(FU10SIDPOC, FU10SIDPOC_scaled, FU10SIDPOC_nomiss, FU10SIDPOCC, FU10SIDPOCD,
#                                   PFU10MAPPOC, PFU10MAPPOC_scaled, PFU10MAPPOC_nomiss, PFU10MAPPOCC, PFU10MAPPOCD,
#                                   FU10FFOCI_Total, FU10FFOCI_Scaled.Total, FU10FFOCI_NoMiss.Total)) 
# OCPD.sum.scores_SPAN.FU12 <- select(SPAN.FU12.NEO.and.OCPD.data,
#                                     c(PFU12MAPPOC, PFU12MAPPOC_scaled, PFU12MAPPOC_nomiss, PFU12MAPPOCC, PFU12MAPPOCD,
#                                       FU12FFOCI_Total, FU12FFOCI_Scaled.Total, FU12FFOCI_NoMiss.Total)) 
# OCPD.sum.scores_SPAN.baseline.10.12 <- bind_cols(OCPD.sum.scores_SPAN.baseline, OCPD.sum.scores_SPAN.FU10,
#                                                  OCPD.sum.scores_SPAN.FU12)

# # Correlation plot for SPAN OCPD data
# corrplot(SPAN.OCPD.correlations, type = "lower", method = "color", number.digits = 2, 
#          tl.col="black", number.font = 10, addCoef.col = "black", diag = FALSE)
```
## 2) Pre-processing (steps that want to do on all data) ####
```{r}
# # 2a: Check data for nero zero variance predictors, which may want to remove
# sapply(dfs, function(x) (nearZeroVar(x, names = TRUE)))
# # Outcome: SIDPOCD (all tps), SIDP_3plusOCsx (FU10), TwoSIDPs_w.3plusOCsx 
# # are only vars w/ near zero variance being used in analyses (and all outcome vars), 
# # so not removing any predictors
# 
# # 2b: Check for highly correlated predictor variables
# NEO.correlations_SPAN.bl <- cor(SPAN.NEO.raw.data_not.NAs[ ,-1], use = "pairwise.complete.obs")
# NEO.correlations_SPAN.FU10 <- cor(SPAN.FU10.NEO.raw.data_not.NAs[ ,-1], use = "pairwise.complete.obs")
# NEO.correlations_SPAN.FU12 <- cor(SPAN.FU12.NEO.raw.data_not.NAs[ ,-1], use = "pairwise.complete.obs")
# NEO.correlations_SPAN <- list(NEO.correlations_SPAN.bl, NEO.correlations_SPAN.FU10,
#                               NEO.correlations_SPAN.FU12)
# corrplot(SPAN.baseline.NEO.correlations, type = "lower", method = "color")
# lapply(NEO.correlations_SPAN, function(x) (findCorrelation(x, cutoff = 0.75)))
# # Outcome: no NEO items are highly correlated (i.e. r >0.75)

# 2c: Convert gender variable to factor
dfs <- lapply(dfs, function(x) {
            mutate(x, PGENDER.factor = factor(PGENDER, levels = c(1,2), 
                                        labels = c("male", "female")))})

# 2d: Remove subjs missing gender + age data, b/c need those data to residualize

# ## Subjs missing gender data
# which(is.na(SPAN.bl.NEO.and.OCPD.data$PGENDER))
# # PARTID = 2119, 3059, 3198, 3438, 3517, 4023, 4122, 4167, 4274, 4415, 4501
# # Note: All but one have DOB. otherwise missing all of PDEMO data.
# 
# ## Subjs missing baseline age data
# which(is.na(SPAN.bl.NEO.and.OCPD.data$PAGE))
# # PARTID = 2102, 4274 (both missing DOB. no other DOBs missing. Only 2102 has data though and would've been included)

## First, create new list of dfs that will only include subjs w/ some data for 
## NEO and OCPD measures
dfs.notNAs <- dfs[c("SPAN.bl.NEO.and.OCPD.data.notNAs",
                    "SPAN.FU10.NEO.and.OCPD.data.notNAs",
                    "SPAN.FU12.NEO.and.OCPD.data.notNAs")]

## Second, remove subjs missing gender and age data
dfs.notNAs <- lapply(dfs.notNAs, function(x) { 
    x <- filter(x, !is.na(PGENDER.factor))}) 
## Note: no subjs from the notNAs dfs were missing gender data

# To be safe, separately check for NAs in PAGE, PFU10AGE, PFU12AGE instead of just PDOB
# in case still some subjs w/ DOB but missing AGE var for some reason
dfs.notNAs$SPAN.bl.NEO.and.OCPD.data.notNAs <- filter(dfs.notNAs$SPAN.bl.NEO.and.OCPD.data.notNAs,
                                                      !is.na(PAGE))
dfs.notNAs$SPAN.FU10.NEO.and.OCPD.data.notNAs <- filter(dfs.notNAs$SPAN.FU10.NEO.and.OCPD.data.notNAs,
                                                        !is.na(PFU10AGE))
dfs.notNAs$SPAN.FU12.NEO.and.OCPD.data.notNAs <- filter(dfs.notNAs$SPAN.FU12.NEO.and.OCPD.data.notNAs,
                                                        !is.na(PFU12AGE))
## Note: 1 removed from bl (2102). 0 from FU10 or FU12. 

####
# 2e: Impute missing NEO items w/ facet mean #
####
# ## Number of NEO Qs subjs are missing data for
# sapply(dfs.notNAs, function(x) {
#     table(rowSums(is.na(x[ ,2:241])))})
# 
# ## potential subjects to remove: 
# which(rowSums(is.na(SPAN.bl.NEO.and.OCPD.data.notNAs[ ,2:241])) == 183) #row 1082 (PARTID 4016)
# which(rowSums(is.na(SPAN.bl.NEO.and.OCPD.data.notNAs[ ,2:241])) == 148) #row 465 (PARTID 2372)
# which(rowSums(is.na(SPAN.bl.NEO.and.OCPD.data.notNAs[ ,2:241])) == 64) #row 757 (PARTID 3216)

SPAN.baseline.subjs.missing.lots.of.NEO <- c(4016, 2372, 3216)

## Remove 3 subjects from baseline data missing > 25% of NEO Qs (none had SIDP OCPD dx at baseline)
## NOTE: No subjs for FU10 or FU12 missing >25% NEO Qs
dfs.notNAs.filtered <- dfs.notNAs
dfs.notNAs.filtered$SPAN.bl.NEO.and.OCPD.data.notNAs <- filter(dfs.notNAs.filtered$SPAN.bl.NEO.and.OCPD.data.notNAs, 
                                                    !PARTID %in% SPAN.baseline.subjs.missing.lots.of.NEO)
names(dfs.notNAs.filtered) <- c("SPAN.bl.NEO.and.OCPD.data.notNAs.filtered",
                                "SPAN.FU10.NEO.and.OCPD.data.notNAs",
                                "SPAN.FU12.NEO.and.OCPD.data.notNAs")

# ## Determine how many Qs subjs are missing data for on each facet
# NEO.facet.name <- c(sprintf("NEOO%s", seq(1:6)),
#     sprintf("NEOC%s", seq(1:6)), sprintf("NEOE%s", seq(1:6)),
#     sprintf("NEOA%s", seq(1:6)), sprintf("NEON%s", seq(1:6)))
# 
# for(i in NEO.facet.name){
#     print(i)
#     lapply(dfs.notNAs.filtered, function(x) {
#         print(table(rowSums(is.na(x[ , 
#                     grep(paste(i, "\\d", sep = ""),names(x), value = TRUE)]))))})
# }

## Facets w/ subjs missing >2 Qs (out of 8)
## Bl:   NEOO5 (3 MISS, N=1), NEOO6 (5 MISS, N=2), NEOA6 (4 MISS, N=1)
## FU10: NEOO1 (3 MISS, N=1), NEOO3 (3 MISS, N=1), NEOA5 (3 MISS, N=1), NEON4 (3 MISS, N=1)
## FU12: NEOO6 (4 MISS, N=1; 5 MISS, N=1), NEOC4 (5 MISS, N=1), NEOC6 (3 MISS, N=1), NEOE5 (3 MISS, N=1), 
##       NEOE6 (3 MISS, N=1), NEOA6 (4 MISS, N=1), NEON5 (3 MISS, N=1)

# Version for individual df (not using list + lapply)
# for(i in NEO.facet.name){
#     print(i)
#     paste(grep(paste(i, "\\d", sep = ""),names(SPAN.bl.NEO.and.OCPD.data.notNAs), value = TRUE), "_mean") <-
#                rowMeans(paste(i, "\\d", sep = ""), na.rm = TRUE)
# }     
# Combine all mean vectors into a dataframe 
#    NEO.facet.mean.vectors <- grep(".mean", names(.GlobalEnv), value = TRUE)
#    NEO.facet.means <- do.call("data.frame", mget(NEO.facet.mean.vectors))
#    # Add NEO facet means to dataframe
#    SPAN.bl.NEO.and.OCPD.data.notNAs.filtered <- bind_cols(
#        SPAN.bl.NEO.and.OCPD.data.notNAs.filtered, NEO.facet.means)

calc.facet.means <- function(df) {
    # Agreeableness
    df[["NEOA1.mean"]] <- df %>% select(matches("NEOA1\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    df[["NEOA2.mean"]] <- df %>% select(matches("NEOA2\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    df[["NEOA3.mean"]] <- df %>% select(matches("NEOA3\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    df[["NEOA4.mean"]] <- df %>% select(matches("NEOA4\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    df[["NEOA5.mean"]] <- df %>% select(matches("NEOA5\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    df[["NEOA6.mean"]] <- df %>% select(matches("NEOA6\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    # Extraversion
    df[["NEOE1.mean"]] <- df %>% select(matches("NEOE1\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    df[["NEOE2.mean"]] <- df %>% select(matches("NEOE2\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    df[["NEOE3.mean"]] <- df %>% select(matches("NEOE3\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    df[["NEOE4.mean"]] <- df %>% select(matches("NEOE4\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    df[["NEOE5.mean"]] <- df %>% select(matches("NEOE5\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    df[["NEOE6.mean"]] <- df %>% select(matches("NEOE6\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    # Conscientiousness
    df[["NEOC1.mean"]] <- df %>% select(matches("NEOC1\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    df[["NEOC2.mean"]] <- df %>% select(matches("NEOC2\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    df[["NEOC3.mean"]] <- df %>% select(matches("NEOC3\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    df[["NEOC4.mean"]] <- df %>% select(matches("NEOC4\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    df[["NEOC5.mean"]] <- df %>% select(matches("NEOC5\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    df[["NEOC6.mean"]] <- df %>% select(matches("NEOC6\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    # Openness
    df[["NEOO1.mean"]] <- df %>% select(matches("NEOO1\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    df[["NEOO2.mean"]] <- df %>% select(matches("NEOO2\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    df[["NEOO3.mean"]] <- df %>% select(matches("NEOO3\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    df[["NEOO4.mean"]] <- df %>% select(matches("NEOO4\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    df[["NEOO5.mean"]] <- df %>% select(matches("NEOO5\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    df[["NEOO6.mean"]] <- df %>% select(matches("NEOO6\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    # Neuroticism
    df[["NEON1.mean"]] <- df %>% select(matches("NEON1\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    df[["NEON2.mean"]] <- df %>% select(matches("NEON2\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    df[["NEON3.mean"]] <- df %>% select(matches("NEON3\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    df[["NEON4.mean"]] <- df %>% select(matches("NEON4\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    df[["NEON5.mean"]] <- df %>% select(matches("NEON5\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    df[["NEON6.mean"]] <- df %>% select(matches("NEON6\\d$")) %>% rowMeans(., na.rm = TRUE) %>% round(., 2)
    return(df)
}
    
dfs.notNAs.filtered <- lapply(dfs.notNAs.filtered, calc.facet.means)

# Replace NEO NA values w/ facet mean
## NOTE: currently replaces all NA values. a few facets had missing data for 3+/8 Qs
##       ideally, would modify this to not use facet mean when lots of Qs missing.
##       tried for a few hours, but can't figure out code.

impute.w.NEO.facet.means <- function(df){
    df <- df %>%
    mutate_at(.vars = vars(matches("NEOO1\\d$")), .funs = funs(ifelse(is.na(.), NEOO1.mean, .))) %>%
    mutate_at(.vars = vars(matches("NEOO2\\d$")), .funs = funs(ifelse(is.na(.), NEOO2.mean, .))) %>%    
    mutate_at(.vars = vars(matches("NEOO3\\d$")), .funs = funs(ifelse(is.na(.), NEOO3.mean, .))) %>% 
    mutate_at(.vars = vars(matches("NEOO4\\d$")), .funs = funs(ifelse(is.na(.), NEOO4.mean, .))) %>%  
    mutate_at(.vars = vars(matches("NEOO5\\d$")), .funs = funs(ifelse(is.na(.), NEOO5.mean, .))) %>%  
    mutate_at(.vars = vars(matches("NEOO6\\d$")), .funs = funs(ifelse(is.na(.), NEOO6.mean, .))) %>%
    mutate_at(.vars = vars(matches("NEOC1\\d$")), .funs = funs(ifelse(is.na(.), NEOC1.mean, .))) %>%
    mutate_at(.vars = vars(matches("NEOC2\\d$")), .funs = funs(ifelse(is.na(.), NEOC2.mean, .))) %>%    
    mutate_at(.vars = vars(matches("NEOC3\\d$")), .funs = funs(ifelse(is.na(.), NEOC3.mean, .))) %>% 
    mutate_at(.vars = vars(matches("NEOC4\\d$")), .funs = funs(ifelse(is.na(.), NEOC4.mean, .))) %>%  
    mutate_at(.vars = vars(matches("NEOC5\\d$")), .funs = funs(ifelse(is.na(.), NEOC5.mean, .))) %>%  
    mutate_at(.vars = vars(matches("NEOC6\\d$")), .funs = funs(ifelse(is.na(.), NEOC6.mean, .))) %>%
    mutate_at(.vars = vars(matches("NEOE1\\d$")), .funs = funs(ifelse(is.na(.), NEOE1.mean, .))) %>%
    mutate_at(.vars = vars(matches("NEOE2\\d$")), .funs = funs(ifelse(is.na(.), NEOE2.mean, .))) %>%    
    mutate_at(.vars = vars(matches("NEOE3\\d$")), .funs = funs(ifelse(is.na(.), NEOE3.mean, .))) %>% 
    mutate_at(.vars = vars(matches("NEOE4\\d$")), .funs = funs(ifelse(is.na(.), NEOE4.mean, .))) %>%  
    mutate_at(.vars = vars(matches("NEOE5\\d$")), .funs = funs(ifelse(is.na(.), NEOE5.mean, .))) %>%  
    mutate_at(.vars = vars(matches("NEOE6\\d$")), .funs = funs(ifelse(is.na(.), NEOE6.mean, .))) %>%
    mutate_at(.vars = vars(matches("NEOA1\\d$")), .funs = funs(ifelse(is.na(.), NEOA1.mean, .))) %>%
    mutate_at(.vars = vars(matches("NEOA2\\d$")), .funs = funs(ifelse(is.na(.), NEOA2.mean, .))) %>%    
    mutate_at(.vars = vars(matches("NEOA3\\d$")), .funs = funs(ifelse(is.na(.), NEOA3.mean, .))) %>% 
    mutate_at(.vars = vars(matches("NEOA4\\d$")), .funs = funs(ifelse(is.na(.), NEOA4.mean, .))) %>%  
    mutate_at(.vars = vars(matches("NEOA5\\d$")), .funs = funs(ifelse(is.na(.), NEOA5.mean, .))) %>%  
    mutate_at(.vars = vars(matches("NEOA6\\d$")), .funs = funs(ifelse(is.na(.), NEOA6.mean, .))) %>%
    mutate_at(.vars = vars(matches("NEON1\\d$")), .funs = funs(ifelse(is.na(.), NEON1.mean, .))) %>%
    mutate_at(.vars = vars(matches("NEON2\\d$")), .funs = funs(ifelse(is.na(.), NEON2.mean, .))) %>%    
    mutate_at(.vars = vars(matches("NEON3\\d$")), .funs = funs(ifelse(is.na(.), NEON3.mean, .))) %>% 
    mutate_at(.vars = vars(matches("NEON4\\d$")), .funs = funs(ifelse(is.na(.), NEON4.mean, .))) %>%  
    mutate_at(.vars = vars(matches("NEON5\\d$")), .funs = funs(ifelse(is.na(.), NEON5.mean, .))) %>%  
    mutate_at(.vars = vars(matches("NEON6\\d$")), .funs = funs(ifelse(is.na(.), NEON6.mean, .)))
    return(df)
}

dfs.notNAs.filtered.NEO.imputed <- lapply(dfs.notNAs.filtered, impute.w.NEO.facet.means)
names(dfs.notNAs.filtered.NEO.imputed) <- paste(names(dfs.notNAs.filtered.NEO.imputed), ".NEO.imputed", sep = "")

## 2f: possibly remove subjs missing data for OCPD outcome variables of interest

# Current # of subjs in dataframes before removing any due to missing OCPD outcome data
# Baseline = 1606, FU10 = 1032, FU12= 904

OCPD.outcome.vars <- unlist(lapply(dfs.notNAs.filtered.NEO.imputed, function(df) names(df %>% select(ends_with(
    c("SIDPOC", "SIDPOC_scaled", "SIDPOC_nomiss", "SIDPOCC", "SIDPOCD",
    "MAPPOC", "MAPPOC_scaled", "MAPPOC_nomiss", "MAPPOCC", "MAPPOCD",
    "FFOCI_Total", "FFOCI_Scaled.Total", "FFOCI_NoMiss.Total"))))), use.names = FALSE)

# # Number of subjs missing OCPD outcome data - **baseline**
# apply(dfs.notNAs.filtered.NEO.imputed[[1]][ ,c("SIDPOC", "SIDPOC_scaled", "SIDPOC_nomiss", "SIDPOCC", "SIDPOCD",
#                                                "PMAPPOC", "PMAPPOC_scaled", "PMAPPOC_nomiss", "PMAPPOCC", "PMAPPOCD")],
#       2, function(x) table(is.na(x)))
# ## RESULTS: No SIDP missing. PMAPPOC_nomiss has 30 NAs
# 
# # Number of subjs missing OCPD outcome data - **FU10**
# apply(dfs.notNAs.filtered.NEO.imputed[[2]][ ,c("FU10SIDPOC", "FU10SIDPOC_scaled", "FU10SIDPOC_nomiss", "FU10SIDPOCC", "FU10SIDPOCD",
#                                              "PFU10MAPPOC", "PFU10MAPPOC_scaled", "PFU10MAPPOC_nomiss", "PFU10MAPPOCC", "PFU10MAPPOCD",
#                                              "FU10FFOCI_Total", "FU10FFOCI_Scaled.Total", "FU10FFOCI_NoMiss.Total")],
#       2, function(x) table(is.na(x)))
# ## RESULTS: SIDPOC, SIDOCC, SIPDOCD missing 3. SIDPOC_scaled missing 8, SIDPOC_nomiss missing 11. 
# ##          MAPPOC_scaled missing 2, MAPPOC_nomiss missing 18. FFOCI_Scaled.Total missing 7, FFOCI_NoMiss.Total missing 74
# 
# # Number of subjs missing OCPD outcome data - **FU12**
# apply(dfs.notNAs.filtered.NEO.imputed[[3]][ ,c("PFU12MAPPOC", "PFU12MAPPOC_scaled", "PFU12MAPPOC_nomiss", "PFU12MAPPOCC", "PFU12MAPPOCD",
#                                              "FU12FFOCI_Total", "FU12FFOCI_Scaled.Total", "FU12FFOCI_NoMiss.Total")],
#       2, function(x) table(is.na(x)))
# ## RESULTS: MAPPOC_scaled missing 6, MAPPOC_nomiss missing 28. FFOCI_Scaled.Total missing 1, FFOCI_NoMiss.Total missing 91
# 
# ## Number of FFOCI Qs subjs are missing data for
# table(rowSums(is.na(dfs.notNAs.filtered.NEO.imputed[[2]][ ,603:650])))
# table(rowSums(is.na(dfs.notNAs.filtered.NEO.imputed[[3]][ ,484:531])))

# Remove subjs w/ NAs for the scaled versions of SIDP, MAPP, or FFOCI total scores
dfs.notNAs.EXTRAfiltered.NEO.imputed <- lapply(dfs.notNAs.filtered.NEO.imputed, function(df) { 
        df <- df[complete.cases(select(df, ends_with(
            c("SIDPOC_scaled", "MAPPOC_scaled", "FFOCI_Scaled.Total")))), ]
    })
## N's - baseline = 1606, FU10 = 1015, FU12 = 898
## for reference, if don't remove these subjs - baseline the same, FU10 = 1032, FU12 = 904

# Recalculate NEO summary scores using imputed raw scores 
recalc.NEO.sum.scores <- function(df) {
    # Agreeableness
    df[["NEOA1_imputed"]] <- df %>% select(matches("NEOA1\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEOA2_imputed"]] <- df %>% select(matches("NEOA2\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEOA3_imputed"]] <- df %>% select(matches("NEOA3\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEOA4_imputed"]] <- df %>% select(matches("NEOA4\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEOA5_imputed"]] <- df %>% select(matches("NEOA5\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEOA6_imputed"]] <- df %>% select(matches("NEOA6\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    # Extraversion
    df[["NEOE1_imputed"]] <- df %>% select(matches("NEOE1\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEOE2_imputed"]] <- df %>% select(matches("NEOE2\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEOE3_imputed"]] <- df %>% select(matches("NEOE3\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEOE4_imputed"]] <- df %>% select(matches("NEOE4\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEOE5_imputed"]] <- df %>% select(matches("NEOE5\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEOE6_imputed"]] <- df %>% select(matches("NEOE6\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    # Conscientiousness
    df[["NEOC1_imputed"]] <- df %>% select(matches("NEOC1\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEOC2_imputed"]] <- df %>% select(matches("NEOC2\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEOC3_imputed"]] <- df %>% select(matches("NEOC3\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEOC4_imputed"]] <- df %>% select(matches("NEOC4\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEOC5_imputed"]] <- df %>% select(matches("NEOC5\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEOC6_imputed"]] <- df %>% select(matches("NEOC6\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    # Openness
    df[["NEOO1_imputed"]] <- df %>% select(matches("NEOO1\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEOO2_imputed"]] <- df %>% select(matches("NEOO2\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEOO3_imputed"]] <- df %>% select(matches("NEOO3\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEOO4_imputed"]] <- df %>% select(matches("NEOO4\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEOO5_imputed"]] <- df %>% select(matches("NEOO5\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEOO6_imputed"]] <- df %>% select(matches("NEOO6\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    # Neuroticism
    df[["NEON1_imputed"]] <- df %>% select(matches("NEON1\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEON2_imputed"]] <- df %>% select(matches("NEON2\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEON3_imputed"]] <- df %>% select(matches("NEON3\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEON4_imputed"]] <- df %>% select(matches("NEON4\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEON5_imputed"]] <- df %>% select(matches("NEON5\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEON6_imputed"]] <- df %>% select(matches("NEON6\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    return(df)
    df[["NEOA_imputed"]] <- df %>% select(matches("NEOA\\d_imputed")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEOE_imputed"]] <- df %>% select(matches("NEOE\\d_imputed")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEOC_imputed"]] <- df %>% select(matches("NEOC\\d_imputed")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEOO_imputed"]] <- df %>% select(matches("NEOO\\d_imputed")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    df[["NEON_imputed"]] <- df %>% select(matches("NEON\\d_imputed")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
    return(df)
}
dfs.notNAs.EXTRAfiltered.NEO.imputed <- lapply(dfs.notNAs.EXTRAfiltered.NEO.imputed, recalc.NEO.sum.scores)

# Save SPAN data being used in analyses to file for future reference
# write_xlsx(dfs.notNAs.EXTRAfiltered.NEO.imputed, "../Data/SPAN.FINAL.DATA.xlsx")
```
#### 3) Split data into training, validation, and testing sets ####
```{r}
# 70% train, 10% validation, 20% test
## NOTE: if don't want to use dfs that removed subjs missing OCPD outcome vars, 
##       change code below to dfs.notNAs.filtered.NEO.imputed 

set.seed(62) # using a different seed for data splitting than running models. believe this is acceptable based on caret documentation example
# Get row numbers for the training data
trainRowNumbers.bl <- createDataPartition(as.factor(dfs.notNAs.EXTRAfiltered.NEO.imputed[[1]]$SIDPOCD), 
                                          p=0.7, list = FALSE) 
trainRowNumbers.FU10 <- createDataPartition(as.factor(dfs.notNAs.EXTRAfiltered.NEO.imputed[[2]]$FU10SIDPOCD), 
                                          p=0.7, list = FALSE) 
trainRowNumbers.FU12 <- createDataPartition(as.factor(dfs.notNAs.EXTRAfiltered.NEO.imputed[[3]]$PFU12MAPPOCD), ## no SIDP at FU12
                                          p=0.7, list = FALSE) 
# Create training dataset
trainData.bl   <- dfs.notNAs.EXTRAfiltered.NEO.imputed[[1]][trainRowNumbers.bl, ]
trainData.FU10 <- dfs.notNAs.EXTRAfiltered.NEO.imputed[[2]][trainRowNumbers.FU10, ]
trainData.FU12 <- dfs.notNAs.EXTRAfiltered.NEO.imputed[[3]][trainRowNumbers.FU12, ]

# Create dataset of rest of data to split up further into validation and testing
val.and.testData.bl  <-  dfs.notNAs.EXTRAfiltered.NEO.imputed[[1]][-trainRowNumbers.bl, ]
val.and.testData.FU10 <- dfs.notNAs.EXTRAfiltered.NEO.imputed[[2]][-trainRowNumbers.FU10, ]
val.and.testData.FU12 <- dfs.notNAs.EXTRAfiltered.NEO.imputed[[3]][-trainRowNumbers.FU12, ]
# Get row numbers of validation data
valRowNumbers.bl <- createDataPartition(as.factor(val.and.testData.bl$SIDPOCD),
                                     p=0.33, list = FALSE)
valRowNumbers.FU10 <- createDataPartition(as.factor(val.and.testData.FU10$FU10SIDPOCD),
                                     p=0.33, list = FALSE)
valRowNumbers.FU12 <- createDataPartition(as.factor(val.and.testData.FU12$PFU12MAPPOCD), ## no SIDP at FU12
                                     p=0.33, list = FALSE)
# Create validation dataset
valData.bl <- val.and.testData.bl[valRowNumbers.bl, ]
valData.FU10 <- val.and.testData.FU10[valRowNumbers.FU10, ]
valData.FU12 <- val.and.testData.FU12[valRowNumbers.FU12, ]
# Create testing dataset
testData.bl <- val.and.testData.bl[-valRowNumbers.bl, ]
testData.FU10 <- val.and.testData.FU10[-valRowNumbers.FU10, ]
testData.FU12 <- val.and.testData.FU12[-valRowNumbers.FU12, ]

# Save info on which subjs in training, validation, and test data to file
max_length <- length(trainRowNumbers.bl)

data.split.info <- data.frame(
    bl.train.row = trainRowNumbers.bl,
    bl.train.ID = c(trainData.bl[ , "PARTID"], rep(NA, max_length - length(trainData.bl[ , "PARTID"]))),
    bl.val.row = c(valRowNumbers.bl, rep(NA, max_length - length(valRowNumbers.bl))),
    bl.val.ID = c(valData.bl[ , "PARTID"], rep(NA, max_length - length(valData.bl[ , "PARTID"]))),
    bl.test.row = rep("NA", max_length),
    bl.test.ID = c(testData.bl[ , "PARTID"], rep(NA, max_length - length(testData.bl[ , "PARTID"]))),
    FU10.train.row = c(trainRowNumbers.FU10, rep(NA, max_length - length(trainRowNumbers.FU10))),
    FU10.train.ID = c(trainData.FU10[ , "PARTID"], rep(NA, max_length - length(trainData.FU10[ , "PARTID"]))),
    FU10.val.row = c(valRowNumbers.FU10, rep(NA, max_length - length(valRowNumbers.FU10))),
    FU10.val.ID = c(valData.FU10[ , "PARTID"], rep(NA, max_length - length(valData.FU10[ , "PARTID"]))),
    FU10.test.row = rep("Figure.out", max_length),
    FU10.test.ID = c(testData.FU10[ , "PARTID"], rep(NA, max_length - length(testData.FU10[ , "PARTID"]))),
    FU12.train.row = c(trainRowNumbers.FU12, rep(NA, max_length - length(trainRowNumbers.FU12))),
    FU12.train.ID = c(trainData.FU12[ , "PARTID"], rep(NA, max_length - length(trainData.FU12[ , "PARTID"]))),
    FU12.val.row = c(valRowNumbers.FU12, rep(NA, max_length - length(valRowNumbers.FU12))),
    FU12.val.ID = c(valData.FU12[ , "PARTID"], rep(NA, max_length - length(valData.FU12[ , "PARTID"]))),
    FU12.test.row = rep("Figure.out", max_length),
    FU12.test.ID = c(testData.FU12[ , "PARTID"], rep(NA, max_length - length(testData.FU12[ , "PARTID"])))
)

# write.csv(data.split.info, paste0(results.dir, "data.split.info.csv"))
```
#### 4) Residualize variables to control for covariates ####
```{r}
# for OCPD model, "controlling for" gender and age 
# NOTE: cannot use for categorical outcome

# Combine training, validating, and testing dataframes into lists
dfs.for.OCPD.ML <- list(trainData.bl, trainData.FU10, trainData.FU12, 
                        valData.bl, valData.FU10, valData.FU12,
                        testData.bl, testData.FU10 , testData.FU12)
names(dfs.for.OCPD.ML) <- c("trainData.bl", "trainData.FU10", "trainData.FU12", 
                            "valData.bl", "valData.FU10", "valData.FU12",
                            "testData.bl", "testData.FU10" , "testData.FU12")
dfs.for.OCPD.ML_bl <- dfs.for.OCPD.ML[c(1, 4, 7)]
dfs.for.OCPD.ML_FU10 <- dfs.for.OCPD.ML[c(2, 5, 8)]
dfs.for.OCPD.ML_FU12 <- dfs.for.OCPD.ML[c(3, 6, 9)]
rm(dfs.for.OCPD.ML)

# NOTE: Using separate functions for each TP b/c need to use different age var for each
residualize.predictors.bl <- function(df){
    #print(paste("residualizing", cat(names(df))))
    X <- df[c("PGENDER.factor", "PAGE")]  # covariates
    #print(names(X))
    Y <- select(df, c(2:241, ends_with(c("SIDPOC", "SIDPOC_scaled", "SIDPOC_nomiss", "SIDPOCC", 
                                     "MAPPOC", "MAPPOC_scaled", "MAPPOC_nomiss", "MAPPOCC",
                                     "FFOCI_Total", "FFOCI_Scaled.Total", "FFOCI_NoMiss.Total"))))  # (continuous) outcomes and predictors
    #print(names(Y))
    list_models <- lapply(Y, function(Y) with(X, lm(Y ~ PGENDER.factor + PAGE, 
                                                    na.action="na.exclude"))) # Run all models
    list_resid <- lapply(list_models, resid) # List residuals from all models
    df_resid <- do.call(cbind.data.frame, list_resid) # Put residuals in dataframe
    colnames(df_resid) <- paste(colnames(df_resid), "res", sep = ".") # Add ".res" to variable names
    df <- cbind(df, df_resid) # Add residualized variables to df
    return(df) # Make function return the dataframe
    #print(paste("successfully residualized", cat(names(df))))
}
dfs.for.OCPD.ML_bl <- lapply(dfs.for.OCPD.ML_bl, residualize.predictors.bl)

residualize.predictors.FU10 <- function(df){
    #print(paste("residualizing", cat(names(df))))
    X <- df[c("PGENDER.factor", "PFU10AGE")]  # covariates
    Y <- select(df, c(2:241, ends_with(c("SIDPOC", "SIDPOC_scaled", "SIDPOC_nomiss", "SIDPOCC", 
                                         "MAPPOC", "MAPPOC_scaled", "MAPPOC_nomiss", "MAPPOCC",
                                         "FFOCI_Total", "FFOCI_Scaled.Total", "FFOCI_NoMiss.Total"))))  # (continuous) outcomes and predictors
    #print(names(Y)) # confirm correct variables were subsetted
    list_models <- lapply(Y, function(Y) with(X, lm(Y ~ PGENDER.factor + PFU10AGE, 
                                                    na.action="na.exclude"))) # Run all models
    list_resid <- lapply(list_models, resid) # List residuals from all models
    df_resid <- do.call(cbind.data.frame, list_resid) # Put residuals in dataframe
    colnames(df_resid) <- paste(colnames(df_resid), "res", sep = ".") # Add ".res" to variable names
    df <- cbind(df, df_resid) # Add residualized variables to df
    return(df) # Make function return the dataframe
    #print(paste("successfully residualized", cat(names(df))))
}
dfs.for.OCPD.ML_FU10 <- lapply(dfs.for.OCPD.ML_FU10, residualize.predictors.FU10)

residualize.predictors.FU12 <- function(df){
    #print(paste("residualizing", cat(names(df))))
    X <- df[c("PGENDER.factor", "PFU12AGE")]  # covariates
    Y <- select(df, c(2:241, ends_with(c("SIDPOC", "SIDPOC_scaled", "SIDPOC_nomiss", "SIDPOCC", 
                                         "MAPPOC", "MAPPOC_scaled", "MAPPOC_nomiss", "MAPPOCC",
                                         "FFOCI_Total", "FFOCI_Scaled.Total", "FFOCI_NoMiss.Total"))))  # (continuous) outcomes and predictors
    #print(names(Y)) # confirm correct variables were subsetted
    list_models <- lapply(Y, function(Y) with(X, lm(Y ~ PGENDER.factor + PFU12AGE, 
                                                    na.action="na.exclude"))) # Run all models
    list_resid <- lapply(list_models, resid) # List residuals from all models
    df_resid <- do.call(cbind.data.frame, list_resid) # Put residuals in dataframe
    colnames(df_resid) <- paste(colnames(df_resid), "res", sep = ".") # Add ".res" to variable names
    df <- cbind(df, df_resid) # Add residualized variables to df
    return(df) # Make function return the dataframe
    #print(paste("successfully residualized", cat(names(df))))
}
dfs.for.OCPD.ML_FU12 <- lapply(dfs.for.OCPD.ML_FU12, residualize.predictors.FU12)

# Check residuals to see if distributions seem right
## NEO items - all residuals around -3 to 3
# lapply(dfs.for.OCPD.ML_FU12, function(df) {
#     df %>% select(., matches("\\d.res")) %>%   
#     boxplot(.)})
# ## OCPD items
# lapply(dfs.for.OCPD.ML_FU10, function(df) {
#     df %>% select(., ends_with(c("SIDPOC.res", "SIDPOC_scaled.res", "SIDPOC_nomiss.res", "SIDPOCC.res", 
#             "MAPPOC.res", "MAPPOC_scaled.res", "MAPPOC_nomiss.res", "MAPPOCC.res",
#             "FFOCI_Total.res", "FFOCI_Scaled.Total.res", "FFOCI_NoMiss.Total.res"))) %>%
#     boxplot(.)})
#             #        summary(.)})

# Extract preprocessed data ready for ML from list into separate dataframes
list2env(dfs.for.OCPD.ML_bl, environment()) # need 2nd arg to make the dfs objects in current global env.
list2env(dfs.for.OCPD.ML_FU10, environment())
list2env(dfs.for.OCPD.ML_FU12, environment())
```
#### 5) Create reusable objects to customize cross-validation + tuning parameters  ####
```{r}
# Specify indices to use for CV (if don't, results from caretList and models run individually differ b/c use slightly different resampling sets for CV)
set.seed(62) # same seed as used for splitting data into training/val/test
BLtrainCVindices <- createMultiFolds(trainData.bl$SIDPOCD, k = 5, times = 5)
set.seed(62)
FU10trainCVindices <- createMultiFolds(trainData.FU10$FU10SIDPOCD, k = 5, times = 5)
set.seed(62)
FU12trainCVindices <- createMultiFolds(trainData.FU12$PFU12MAPPOCD, k = 5, times = 5)

# Create random seems to use within CV, which are needed for parallel processing
## NOTES: for details see trainControl() help, https://jaehyeon-kim.github.io/2015/05/Setup-Random-Seeds-on-Caret-Package.html,
##        and https://topepo.github.io/caret/model-training-and-tuning.html#repro and 
set.seed(110)
seeds.5by5.adaptiveCV.tuneLength100 <- vector(mode = "list", length = 26) # legth = 5x5+1
for(i in 1:25) {
  seeds.5by5.adaptiveCV.tuneLength100[[i]] <- sample.int(1000, 100) # 100 is # of combos of tuning parameters trying, 
}                                      # which I'm currently setting to 100 in tuneLength for adaptive CV
## For the last model (run on all training data after caret determines best hyperparameters):
seeds.5by5.adaptiveCV.tuneLength100[[26]] <- sample.int(1000, 1)

# trainControl

## NO INDEX (do not use)
# myControl <- trainControl(
#     method = "repeatedcv", # method for cross-validation (other options)
#     number = 5, # number of folds
#     repeats = 5, # repeats entire cross-validating procedure X times 
#     verboseIter = TRUE)
## for grid search hyperparameter tuning (this is the default, so don't actually need to use this)
# gridsearchControl <- trainControl(
#     method = "repeatedcv", # method for cross-validation (other options)
#     number = 5, # number of folds
#     repeats = 5, # repeats entire cross-validating procedure X times 
#     verboseIter = TRUE,
#     search = "grid") # this is the default, so don't technically need to specify
## for random search hyperparameter tuning
# randomsearchControl <- trainControl(
#     method = "repeatedcv", # method for cross-validation (other options)
#     number = 5, # number of folds
#     repeats = 5, # repeats entire cross-validating procedure X times 
#     verboseIter = TRUE,
#     search = "random")
## for adaptive resampling hyperparameter tuning
## https://topepo.github.io/caret/adaptive-resampling.html
# adaptControl <- trainControl(
#     method = "adaptive_cv",
#     number = 5, # number of folds
#     repeats = 5, # repeats entire cross-validating procedure X times 
#     verboseIter = TRUE,
#     search = "random",
#     adaptive = list(min = 5, # min # of resamples for each tuning parameter (default = 5)
#                     alpha = 0.05, # conf level to remove parameter settings
#                     method = "gls", # linear model 
#                     complete = TRUE)) # whether train should generate full resampling set if finds
#                                       # optimal solution before end of resampling. need if want to know estimated performance
## Index set (USE)
# seeds = NULL added on 4/4/22
myControl.w.BLindex <- trainControl(
    method = "repeatedcv", # method for cross-validation (other options)
    number = 5, # number of folds
    repeats = 5, # repeats entire cross-validating procedure X times 
    verboseIter = TRUE,
    seeds = seeds.5by5.adaptiveCV.tuneLength100,
    #seeds = NULL, # caret sets random number seeds to use for reproducibility
    index = BLtrainCVindices) # specifies rows to be used in each CV fold for reproducibility + parallel abilities
myControl.w.FU10index <- trainControl(
    method = "repeatedcv", # method for cross-validation (other options)
    number = 5, # number of folds
    repeats = 5, # repeats entire cross-validating procedure X times 
    verboseIter = TRUE,
    seeds = seeds.5by5.adaptiveCV.tuneLength100,
    #seeds = NULL, # caret sets random number seeds to use for reproducibility
    index = FU10trainCVindices) # specifies rows to be used in each CV fold for reproducibility + parallel abilities
myControl.w.FU12index <- trainControl(
    method = "repeatedcv", # method for cross-validation (other options)
    number = 5, # number of folds
    repeats = 5, # repeats entire cross-validating procedure X times 
    verboseIter = TRUE,
    seeds = seeds.5by5.adaptiveCV.tuneLength100,
    #seeds = NULL, # caret sets random number seeds to use for reproducibility
    index = FU12trainCVindices) # specifies rows to be used in each CV fold for reproducibility + parallel abilities

adaptControl.w.BLindex <- trainControl(
    method = "adaptive_cv",
    number = 5, # number of folds
    repeats = 5, # repeats entire cross-validating procedure X times 
    verboseIter = TRUE,
    search = "random", # must specify random for adaptive resampling
    index = BLtrainCVindices, # specifies rows to be used in each CV fold for reproducibility + parallel abilities
    seeds = seeds.5by5.adaptiveCV.tuneLength100,
    #seeds = NULL, # caret sets random number seeds to use for reproducibility (esp. w/ parallel processing)
    adaptive = list(min = 5, # min # of resamples for each tuning parameter (default = 5)
                    alpha = 0.05, # conf level to remove parameter settings
                    method = "gls", # linear model 
                    complete = TRUE)) # whether train should generate full resampling set if finds
                                      # optimal solution before end of resampling. need if want to know estimated performance
adaptControl.w.FU10index <- trainControl(
    method = "adaptive_cv",
    number = 5, # number of folds
    repeats = 5, # repeats entire cross-validating procedure X times 
    verboseIter = TRUE,
    search = "random", # must specify random for adaptive resampling
    index = FU10trainCVindices, # specifies rows to be used in each CV fold for reproducibility + parallel abilities
    seeds = seeds.5by5.adaptiveCV.tuneLength100,
    #seeds = NULL, # caret sets random number seeds to use for reproducibility (esp. w/ parallel processing)
    adaptive = list(min = 5, # min # of resamples for each tuning parameter (default = 5)
                    alpha = 0.05, # conf level to remove parameter settings
                    method = "gls", # linear model 
                    complete = TRUE)) # whether train should generate full resampling set if finds
                                      # optimal solution before end of resampling. need if want to know estimated performance
adaptControl.w.FU12index <- trainControl(
    method = "adaptive_cv",
    number = 5, # number of folds
    repeats = 5, # repeats entire cross-validating procedure X times 
    verboseIter = TRUE,
    search = "random", # must specify random for adaptive resampling
    index = FU12trainCVindices, # specifies rows to be used in each CV fold for reproducibility + parallel abilities
    seeds = seeds.5by5.adaptiveCV.tuneLength100,
    #seeds = NULL, # caret sets random number seeds to use for reproducibility (esp. w/ parallel processing)
    adaptive = list(min = 5, # min # of resamples for each tuning parameter (default = 5)
                    alpha = 0.05, # conf level to remove parameter settings
                    method = "gls", # linear model 
                    complete = TRUE)) # whether train should generate full resampling set if finds
                                      # optimal solution before end of resampling. need if want to know estimated performance

# (hyperparameter) tuning grids (if using grid search tuning - not used for adaptive resampling)
glmnetGrid <- expand.grid(alpha = seq(0,1,length=4),
                          lambda = seq(0.0001, 5, length=20))
gbmGrid <- expand.grid(.interaction.depth = (1:5)*2, 
                       .n.trees = (1:10)*25, 
                       .shrinkage = 0.1,
                       .nminobsinnode = 10)
linearsvrGrid <- expand.grid(C = seq(0.25, 8, length = 20))
# radialsvrGrid <- expand.grid(C = seq(0.25, 8, length = 20), 
#                              sigma = ) I don't know what values to try for sigma. prob use random search
```
#### 6) Run the train function - 1. preprocesses data, 2. does cross-validation,    ####
                             3. automatically tunes hyperparameters, 4. runs model
#### 7) Try various models (different CV and tuning parameters, ####
##                        different ML algorithms)              ##
```{r}
# NOTE: if end up imputing data at this stage (i.e., not separately before), 
#       will need to add na.action = na.pass arg to all train calls.
#       if use formula instead of x= and y=, must specify na.pass to use imputed NAs

####################################################
# Run numerous models all at once with caretList() #
####################################################
algorithmList <- c("glmnet", "gbm", "svmLinear", "svmRadial")

# MAPP #
## Baseline ##
# Residualized, adaptive resampling tuning
set.seed(84)
BL.MAPPOC.res.adapt.model.list <- caretList(
    as.formula(paste("PMAPPOC_scaled.res ~ ", paste(names(trainData.bl)[grepl("NEO.*\\.res$", colnames(trainData.bl))], collapse = " + "))), 
    data = trainData.bl,
    preProcess = c("center", "scale"), # centers and scales, not imputing b/c already imputed w/ facet means
    trControl = adaptControl.w.BLindex,
    tuneLength = 100,
    methodList = algorithmList) # ML algorithms using
## Save model
lapply(seq_along(BL.MAPPOC.res.adapt.model.list), function(i) saveRDS(BL.MAPPOC.res.adapt.model.list[[i]], 
                      file = paste(results.dir, "BL.MAPPOC.res.adapt.", names(BL.MAPPOC.res.adapt.model.list)[[i]], ".Rds", sep = "")))
# Unresidualized, adaptive resampling tuning
set.seed(84)
BL.MAPPOC.adapt.model.list <- caretList(
   as.formula(paste("PMAPPOC_scaled ~ ", paste(names(trainData.bl)[grepl("NEO\\w\\d\\d$", colnames(trainData.bl))], collapse = " + "))), 
   data = trainData.bl,
   preProcess = c("center", "scale"), # centers and scales, not imputing b/c already imputed w/ facet means
   trControl = adaptControl.w.BLindex,
   tuneLength = 100,
   methodList = algorithmList) # ML algorithms using
## Save model
lapply(seq_along(BL.MAPPOC.adapt.model.list), function(i) saveRDS(BL.MAPPOC.adapt.model.list[[i]], 
                file = paste(results.dir, "BL.MAPPOC.adapt.", names(BL.MAPPOC.adapt.model.list)[[i]], ".Rds", sep = "")))
## FU10 ##
# Residualized, adaptive resampling tuning
set.seed(84)
FU10.MAPPOC.res.adapt.model.list <- caretList(
    as.formula(paste("PFU10MAPPOC_scaled.res ~ ", paste(names(trainData.FU10)[grepl("NEO.*\\.res$", colnames(trainData.FU10))], collapse = " + "))), 
    data = trainData.FU10,
    preProcess = c("center", "scale"), # centers and scales, not imputing b/c already imputed w/ facet means
    trControl = adaptControl.w.FU10index,
    tuneLength = 100,
    methodList = algorithmList) # ML algorithms using
## Save model
lapply(seq_along(FU10.MAPPOC.res.adapt.model.list), function(i) saveRDS(FU10.MAPPOC.res.adapt.model.list[[i]], 
                      file = paste(results.dir, "FU10.MAPPOC.res.adapt.", names(FU10.MAPPOC.res.adapt.model.list)[[i]], ".Rds", sep = "")))
# Unresidualized, adaptive resampling tuning
set.seed(84)
FU10.MAPPOC.adapt.model.list <- caretList(
    as.formula(paste("PFU10MAPPOC_scaled ~ ", paste(names(trainData.FU10)[grepl("NEO\\w\\d\\d$", colnames(trainData.FU10))], collapse = " + "))), 
    data = trainData.FU10,
    preProcess = c("center", "scale"), # centers and scales, not imputing b/c already imputed w/ facet means
    trControl = adaptControl.w.FU10index,
    tuneLength = 100,
    methodList = algorithmList) # ML algorithms using
## Save model
lapply(seq_along(FU10.MAPPOC.adapt.model.list), function(i) saveRDS(FU10.MAPPOC.adapt.model.list[[i]], 
           file = paste(results.dir, "FU10.MAPPOC.adapt.", names(FU10.MAPPOC.adapt.model.list)[[i]], ".Rds", sep = "")))
## FU12 ##
# Residualized, adaptive resampling tuning
set.seed(84)
FU12.MAPPOC.res.adapt.model.list <- caretList(
    as.formula(paste("PFU12MAPPOC_scaled.res ~ ", paste(names(trainData.FU12)[grepl("NEO.*\\.res$", colnames(trainData.FU12))], collapse = " + "))), 
    data = trainData.FU12,
    preProcess = c("center", "scale"), # centers and scales, not imputing b/c already imputed w/ facet means
    trControl = adaptControl.w.FU12index,
    tuneLength = 100,
    methodList = algorithmList) # ML algorithms using
## Save model
lapply(seq_along(FU12.MAPPOC.res.adapt.model.list), function(i) saveRDS(FU12.MAPPOC.res.adapt.model.list[[i]], 
                  file = paste(results.dir, "FU12.MAPPOC.res.adapt.", names(FU12.MAPPOC.res.adapt.model.list)[[i]], ".Rds", sep = "")))
# Unresidualized, adaptive resampling tuning
set.seed(84)
FU12.MAPPOC.adapt.model.list <- caretList(
    as.formula(paste("PFU12MAPPOC_scaled ~ ", paste(names(trainData.FU12)[grepl("NEO\\w\\d\\d$", colnames(trainData.FU12))], collapse = " + "))), 
    data = trainData.FU12,
    preProcess = c("center", "scale"), # centers and scales, not imputing b/c already imputed w/ facet means
    trControl = adaptControl.w.FU12index,
    tuneLength = 100,
    methodList = algorithmList) # ML algorithms using
## Save model
lapply(seq_along(FU12.MAPPOC.adapt.model.list), function(i) saveRDS(FU12.MAPPOC.adapt.model.list[[i]], 
            file = paste(results.dir, "FU12.MAPPOC.adapt.", names(FU12.MAPPOC.adapt.model.list)[[i]], ".Rds", sep = "")))
# SIDP #
## Baseline ##
# Residualized, adaptive resampling tuning
set.seed(84)
BL.SIDPOC.res.adapt.model.list <- caretList(
  as.formula(paste("SIDPOC_scaled.res ~ ", paste(names(trainData.bl)[grepl("NEO.*\\.res$", colnames(trainData.bl))], collapse = " + "))), 
  data = trainData.bl,
  preProcess = c("center", "scale"), # centers and scales, not imputing b/c already imputed w/ facet means
  trControl = adaptControl.w.BLindex,
  tuneLength = 100,
  methodList = algorithmList) # ML algorithms using
## Save model
lapply(seq_along(BL.SIDPOC.res.adapt.model.list), function(i) saveRDS(BL.SIDPOC.res.adapt.model.list[[i]], 
               file = paste(results.dir, "BL.SIDPOC.res.adapt.", names(BL.SIDPOC.res.adapt.model.list)[[i]], ".Rds", sep = "")))
# Unresidualized, adaptive resampling tuning
set.seed(84)
BL.SIDPOC.adapt.model.list <- caretList(
  as.formula(paste("SIDPOC_scaled ~ ", paste(names(trainData.bl)[grepl("NEO\\w\\d\\d$", colnames(trainData.bl))], collapse = " + "))), 
  data = trainData.bl,
  preProcess = c("center", "scale"), # centers and scales, not imputing b/c already imputed w/ facet means
  trControl = adaptControl.w.BLindex,
  tuneLength = 100,
  methodList = algorithmList) # ML algorithms using
## Save model
lapply(seq_along(BL.SIDPOC.adapt.model.list), function(i) saveRDS(BL.SIDPOC.adapt.model.list[[i]], 
               file = paste(results.dir, "BL.SIDPOC.adapt.", names(BL.SIDPOC.adapt.model.list)[[i]], ".Rds", sep = "")))
## FU10 ##
# Residualized, adaptive resampling tuning
set.seed(84)
FU10.SIDPOC.res.adapt.model.list <- caretList(
  as.formula(paste("FU10SIDPOC_scaled.res ~ ", paste(names(trainData.FU10)[grepl("NEO.*\\.res$", colnames(trainData.FU10))], collapse = " + "))), 
  data = trainData.FU10,
  preProcess = c("center", "scale"), # centers and scales, not imputing b/c already imputed w/ facet means
  trControl = adaptControl.w.FU10index,
  tuneLength = 100,
  methodList = algorithmList) # ML algorithms using
## Save model
lapply(seq_along(FU10.SIDPOC.res.adapt.model.list), function(i) saveRDS(FU10.SIDPOC.res.adapt.model.list[[i]], 
                              file = paste(results.dir, "FU10.SIDPOC.res.adapt.", names(FU10.SIDPOC.res.adapt.model.list)[[i]], ".Rds", sep = "")))
# Unresidualized, adaptive resampling tuning
set.seed(84)
FU10.SIDPOC.adapt.model.list <- caretList(
  as.formula(paste("FU10SIDPOC_scaled ~ ", paste(names(trainData.FU10)[grepl("NEO\\w\\d\\d$", colnames(trainData.FU10))], collapse = " + "))), 
  data = trainData.FU10,
  preProcess = c("center", "scale"), # centers and scales, not imputing b/c already imputed w/ facet means
  trControl = adaptControl.w.FU10index,
  tuneLength = 100,
  methodList = algorithmList) # ML algorithms using
## Save model
lapply(seq_along(FU10.SIDPOC.adapt.model.list), function(i) saveRDS(FU10.SIDPOC.adapt.model.list[[i]], 
             file = paste(results.dir, "FU10.SIDPOC.adapt.", names(FU10.SIDPOC.adapt.model.list)[[i]], ".Rds", sep = "")))
## FU12 ##
# NOT ADMINISTERED

# FFOCI #
## FU10 ##
# Residualized, adapative resampling tuning
set.seed(84)
FU10.FFOCI.res.adapt.model.list <- caretList(
    as.formula(paste("FU10FFOCI_Scaled.Total.res ~ ", paste(names(trainData.FU10)[grepl("NEO.*\\.res$", colnames(trainData.FU10))], collapse = " + "))), 
    data = trainData.FU10,
    preProcess = c("center", "scale"),
    trControl = adaptControl.w.FU10index, 
    tuneLength = 100,
    methodList = algorithmList)
## Save model
lapply(seq_along(FU10.FFOCI.res.adapt.model.list), function(i) saveRDS(FU10.FFOCI.res.adapt.model.list[[i]], 
                     file = paste(results.dir, "FU10.FFOCI.res.adapt.", names(FU10.FFOCI.res.adapt.model.list)[[i]], ".Rds", sep = "")))
# Unresidualized, adaptive resampling tuning
set.seed(84)
FU10.FFOCI.adapt.model.list <- caretList(
    as.formula(paste("FU10FFOCI_Scaled.Total ~ ", paste(names(trainData.FU10)[grepl("NEO\\w\\d\\d$", colnames(trainData.FU10))], collapse = " + "))), 
    data = trainData.FU10,
    preProcess = c("center", "scale"),
    trControl = adaptControl.w.FU10index, 
    tuneLength = 100,
    methodList = algorithmList)
## Save model
lapply(seq_along(FU10.FFOCI.adapt.model.list), function(i) saveRDS(FU10.FFOCI.adapt.model.list[[i]], 
             file = paste(results.dir, "FU10.FFOCI.adapt.", names(FU10.FFOCI.adapt.model.list)[[i]], ".Rds", sep = "")))

## FU12 ## 
# Residualized, adaptive resampling tuning
set.seed(84)
FU12.FFOCI.res.adapt.model.list <- caretList(
    as.formula(paste("FU12FFOCI_Scaled.Total.res ~ ", paste(names(trainData.FU12)[grepl("NEO.*\\.res$", colnames(trainData.FU12))], collapse = " + "))), 
    data = trainData.FU12,
    preProcess = c("center", "scale"),
    trControl = adaptControl.w.FU12index, 
    tuneLength = 100,
    methodList = algorithmList)
## Save model
lapply(seq_along(FU12.FFOCI.res.adapt.model.list), function(i) saveRDS(FU12.FFOCI.res.adapt.model.list[[i]], 
                  file = paste(results.dir, "FU12.FFOCI.res.adapt.", names(FU12.FFOCI.res.adapt.model.list)[[i]], ".Rds", sep = "")))
# Unresidualized, adaptive resampling tuning
set.seed(84)
FU12.FFOCI.adapt.model.list <- caretList(
    as.formula(paste("FU12FFOCI_Scaled.Total ~ ", paste(names(trainData.FU12)[grepl("NEO\\w\\d\\d$", colnames(trainData.FU12))], collapse = " + "))), 
    data = trainData.FU12,
    preProcess = c("center", "scale"),
    trControl = adaptControl.w.FU12index, 
    tuneLength = 100,
    methodList = algorithmList)
## Save model
lapply(seq_along(FU12.FFOCI.adapt.model.list), function(i) saveRDS(FU12.FFOCI.adapt.model.list[[i]], 
          file = paste(results.dir, "FU12.FFOCI.adapt.", names(FU12.FFOCI.adapt.model.list)[[i]], ".Rds", sep = "")))

## Figuring out Parallel Processing
# library(doParallel)
# cl <- makePSOCKcluster(5)
# registerDoParallel(cl)

# set.seed(84)
# glmnet.FFOCIScaledTotal.res.FU10.adapt.PARALLEL.TEST.seeds.set <- train(
#   as.formula(paste("FU10FFOCI_Scaled.Total.res ~ ", paste(names(trainData.FU10)[grepl("NEO.*\\.res$", colnames(trainData.FU10))], collapse = " + "))), 
#   data = trainData.FU10,
#   preProcess = c("center", "scale"), # centers and scales, not imputing b/c already imputed NEO w/ facet means
#   method = "glmnet", # ML algorithm using
#   trControl = trainControl(
#     method = "adaptive_cv",
#     number = 5, # number of folds
#     repeats = 5, # repeats entire cross-validating procedure X times 
#     verboseIter = TRUE,
#     search = "random",
#     index = FU10trainCVindices,
#     seeds = NULL,
#     adaptive = list(min = 5, # min # of resamples for each tuning parameter (default = 5)
#                     alpha = 0.05, # conf level to remove parameter settings
#                     method = "gls", # linear model 
#                     complete = TRUE)), # whether train should generate full resampling set if finds
#   tuneLength = 10) # adaptive resampling will try 100 ???
# 
# # Residualized, adapative resampling tuning
# set.seed(84)
# FU10.FFOCI.res.adapt.model.list.PARALLEL <- caretList(
#     as.formula(paste("FU10FFOCI_Scaled.Total.res ~ ", paste(names(trainData.FU10)[grepl("NEO.*\\.res$", colnames(trainData.FU10))], collapse = " + "))), 
#     data = trainData.FU10,
#     preProcess = c("center", "scale"),
#     trControl = trainControl(
#       method = "adaptive_cv",
#       number = 5, # number of folds
#       repeats = 5, # repeats entire cross-validating procedure X times 
#       verboseIter = TRUE,
#       search = "random",
#       index = FU10trainCVindices,
#       seeds = NULL,
#       adaptive = list(min = 5, # min # of resamples for each tuning parameter (default = 5)
#                       alpha = 0.05, # conf level to remove parameter settings
#                       method = "gls", # linear model 
#                       complete = TRUE)), # whether train should generate full resampling set if finds
#     tuneLength = 100,
#     methodList = algorithmList)
# 
# set.seed(84)
# FU10.SIDPOC.res.adapt.model.list.PARALLEL <- caretList(
#   as.formula(paste("FU10SIDPOC_scaled.res ~ ", paste(names(trainData.FU10)[grepl("NEO.*\\.res$", colnames(trainData.FU10))], collapse = " + "))), 
#   data = trainData.FU10,
#   preProcess = c("center", "scale"),
#   trControl = trainControl(
#     method = "adaptive_cv",
#     number = 5, # number of folds
#     repeats = 5, # repeats entire cross-validating procedure X times 
#     verboseIter = TRUE,
#     search = "random",
#     index = FU10trainCVindices,
#     seeds = NULL,
#     adaptive = list(min = 5, # min # of resamples for each tuning parameter (default = 5)
#                     alpha = 0.05, # conf level to remove parameter settings
#                     method = "gls", # linear model 
#                     complete = TRUE)), # whether train should generate full resampling set if finds
#   tuneLength = 100,
#   methodList = algorithmList)
# 
# set.seed(84)
# FU10.MAPPOC.res.adapt.model.list.PARALLEL <- caretList(
#   as.formula(paste("PFU10MAPPOC_scaled.res ~ ", paste(names(trainData.FU10)[grepl("NEO.*\\.res$", colnames(trainData.FU10))], collapse = " + "))), 
#   data = trainData.FU10,
#   preProcess = c("center", "scale"),
#   trControl = trainControl(
#     method = "adaptive_cv",
#     number = 5, # number of folds
#     repeats = 5, # repeats entire cross-validating procedure X times 
#     verboseIter = TRUE,
#     search = "random",
#     index = FU10trainCVindices,
#     seeds = NULL,
#     adaptive = list(min = 5, # min # of resamples for each tuning parameter (default = 5)
#                     alpha = 0.05, # conf level to remove parameter settings
#                     method = "gls", # linear model 
#                     complete = TRUE)), # whether train should generate full resampling set if finds
#   tuneLength = 100,
#   methodList = algorithmList)
# 
# lapply(seq_along(FU10.MAPPOC.res.adapt.model.list.PARALLEL), function(i) saveRDS(FU10.MAPPOC.res.adapt.model.list.PARALLEL[[i]], 
#                               file = paste("./Results/ML/Aim1.OCPD/OCPD.NAs.filtered.models/from.caretList/parallel/FU10.MAPPOC.res.adapt.", 
#                               names(FU10.MAPPOC.res.adapt.model.list.PARALLEL)[[i]], ".Rds", sep = "")))

# Save seeds used to rerun in future for reproducibility
## THIS LAPPLY ISN'T WORKING. $control$seeds works manually. something about the indexing method
# lapply(seq_along(FU10.MAPPOC.res.adapt.model.list.PARALLEL), 
#        function(i) 
#          paste("FU10.MAPPOC.res.adapt.", names(FU10.MAPPOC.res.adapt.model.list.PARALLEL)[[i]], ".parallel.seeds", sep = "")  <-
#                               i$control$seeds)

# Output to file that can reload in future
# parallel.seed.objs <- mget(grep("parallel.seeds$", ls(), value = TRUE))
# lapply(seq_along(parallel.seed.objs), function(i) saveRDS(parallel.seed.objs[[i]], 
#                   file = paste("./Results/ML/Aim1.OCPD/OCPD.NAs.filtered.models/from.caretList/parallel/seed.NULL/seeds.autoset.by.caret/", 
#                           names(parallel.seed.objs)[[i]], ".Rds", sep="")))

## Test if same seeds used when running models again in parallel (w/ seeds = NULL)
# set.seed(84)
# FU10.MAPPOC.res.adapt.model.list.PARALLEL.SEED.TEST <- caretList(
#   as.formula(paste("PFU10MAPPOC_scaled.res ~ ", paste(names(trainData.FU10)[grepl("NEO.*\\.res$", colnames(trainData.FU10))], collapse = " + "))), 
#   data = trainData.FU10,
#   preProcess = c("center", "scale"),
#   trControl = trainControl(
#     method = "adaptive_cv",
#     number = 5, # number of folds
#     repeats = 5, # repeats entire cross-validating procedure X times 
#     verboseIter = TRUE,
#     search = "random",
#     index = FU10trainCVindices,
#     seeds = NULL,
#     adaptive = list(min = 5, # min # of resamples for each tuning parameter (default = 5)
#                     alpha = 0.05, # conf level to remove parameter settings
#                     method = "gls", # linear model 
#                     complete = TRUE)), # whether train should generate full resampling set if finds
#   tuneLength = 100,
#   methodList = c("glmnet", "svmRadial"))
## RESULTS: The seeds were the same when 1) rerunning it in same session while still running parallel,
##          2) rerunning it in the same session after ending and restarting running parallel, and
##          3) rerunning it in brand new R session 

# Stop parallel processing
# stopCluster(cl)

```
#### 8) Compare models and select the best one ####
```{r}
# Create model list
model_list <- mget(grep("model.list", ls(), value = TRUE))
# Unlist the caretLists so each model is separate
model_list <- do.call(c, unlist(model_list, recursive = FALSE))
# Remove "model.list" and duplicated alg. name from list element names  
names(model_list) <- sub("model.list.", "", names(model_list))
names(model_list) <- gsub("\\.[[:alpha:]]*[[:digit:]]*$", "", names(model_list))

# Make separate model lists for each TP
bl_model_list <- model_list[grep("BL", names(model_list))] 
FU10_model_list <- model_list[grep("FU10", names(model_list))]
FU12_model_list <- model_list[grep("FU12", names(model_list))]

# Pass model_list to resamples(): 
resamples <- resamples(model_list)

# Summarize the results for training data
summary(resamples)

# View results/compare for training data
bwplot(resamples, metric = "RMSE") # boxplots of out-of-sample RMSE  
xyplot(resamples, metric = "RMSE") # scatterplot of model performances on different folds
plotObsVsPred(resamples)

# Check performance metrics for final models in training data
# (summary(resamples) gives metrics across all CV resamples)
lapply(model_list, function(x) getTrainPerf(x))

# Create spreadsheet of results
# (getTrainPerf() seems to report the mean values from CV resampling that resamples() reports)
TrainPerf.df <- do.call(rbind, lapply(model_list, function(x) as.data.frame(getTrainPerf(x))))

## for some reason the code below only works if a dataframe is already initialized properly, which works if still run getTrainPerf above. 
## it then regenerates those columns in the code below. trying to create an empty dataframe using as.data.frame below doesn't work for some reason.
#TrainPerf.df <- as.data.frame(matrix(ncol = 24, nrow = length(FU12.MAPPOC.adapt.model.list))) 
TrainPerf.df <- TrainPerf.df %>%
  mutate(Model.Name = do.call(rbind, lapply(seq_along(model_list), function(i) paste(names(model_list)[i]))),
          Time.Point = do.call(rbind, lapply(seq_along(model_list), function(i) substr(names(model_list)[i], 1, 4))), # will include extra for baseline. potentially make smarter to search until first .
            Outcome.Measure = do.call(rbind, lapply(model_list, function(x) all.vars(x$terms)[1])),
            Algorithm = do.call(rbind, lapply(model_list, function(x) x$method)),
            Tuning.Type = do.call(rbind, lapply(model_list, function(x) x$control$method)), # says adaptive_cv for adaptive resampling
            tuneLength = do.call(rbind, lapply(model_list, function(x) print(x$call$tuneLength))),
            CV = do.call(rbind, lapply(model_list, function(x) print(paste0(x$control$number, "x", x$control$repeats)))),
#            Index.Set = if(x$control$index ==,
#            Seed = , couldn't figure out how to get it to just say whether "given" or "null" or nothing specified in trainControl
#            Parallel = , there is a parallel arg in train() but it's default is TRUE so that doesn't tell you if parallel processing was running
            TrainRMSE = do.call(rbind, lapply(model_list, function(x) getTrainPerf(x)[[1]])),
            TrainRsquared = do.call(rbind, lapply(model_list, function(x) getTrainPerf(x)[[2]])),
            TrainMAE = do.call(rbind, lapply(model_list, function(x) getTrainPerf(x)[[3]])),
            Outcome.SD = do.call(rbind, lapply(model_list, function(x) print(sd(x$trainingData$.outcome)))),
#            RMSE.to.SD = TrainRMSE/Outcome.SD, don't think mutate can use a variable created in the same call for calculations. must run this separately at end
            Hyperparameter1 = do.call(rbind, lapply(model_list, function(x) names(x$bestTune)[[1]])),
            Final.Value1 = do.call(rbind, lapply(model_list, function(x) x$bestTune[[1]])),
           Hyperparameter2 = do.call(rbind, lapply(model_list, function(x) {if(length(x$bestTune) < 2) {NA} else {names(x$bestTune)[[2]]}})),
            Final.Value2 = do.call(rbind, lapply(model_list, function(x) {if(length(x$bestTune) < 2) {NA} else {x$bestTune[[2]]}})),
           Hyperparameter3 = do.call(rbind, lapply(model_list, function(x) {if(length(x$bestTune) < 3) {NA} else {names(x$bestTune)[[3]]}})),
            Final.Value3 = do.call(rbind, lapply(model_list, function(x) {if(length(x$bestTune) < 3) {NA} else {x$bestTune[[3]]}})),
           Hyperparameter4 = do.call(rbind, lapply(model_list, function(x) {if(length(x$bestTune) < 4) {NA} else {names(x$bestTune)[[4]]}})),
            Final.Value4 = do.call(rbind, lapply(model_list, function(x) {if(length(x$bestTune) < 4) {NA} else {x$bestTune[[4]]}})),
            Predictors = do.call(rbind, lapply(model_list, function(x) length(predictors(x)))),
            N = do.call(rbind, lapply(model_list, function(x) dim(x$trainingData)[1]))) %>%
  mutate(RMSE.to.SD = TrainRMSE/Outcome.SD)

write.csv(TrainPerf.df, file = paste0(results.dir, "training.data.insample.performance.AUTO.csv"), row.names = F)

## To look at coefficients
# coef(<model.name>$finalModel, <model.name>$bestTune$<one of the tuning parameters>)

# See which predictor variables were kept in the models
## if just want to know how many variables kept, add length() outside of the predictors call
predictors <- lapply(model_list, function(x) predictors(x))
## save to file
# predictors.df <- do.call(cbind, lapply(model_list, function(x) as.data.frame(predictors(x))))
# lapply(X = predictors, function(x) {write(x, append = T, file = "predictors.txt", ncolumns = 56) })
predictors.df <- do.call(cbind, lapply(predictors, function(x) paste(x, collapse = " "))) 
# note this puts all predictors in single cell for each model
# couldn't figure out how to make this better. had to open the file in google sheets and use formula =TRANSPOSE(SPLIT(A2," "))
write.csv(predictors.df, file = paste0(results.dir, "predictors.csv"))


# Variable Importance
varImpInfo <- lapply(model_list, function(x) varImp(x, scale = FALSE))
## Print to file
varImpInfo.df <- do.call(cbind, lapply(varImpInfo, function(x) as.data.frame(x$importance)))
names(varImpInfo.df) <- names(varImpInfo)
write.csv(varImpInfo.df, file = paste0(results.dir, 'varImpInfo.csv'), col.names = TRUE)
# it uses NEOXXX.res for row names, but the values are correct regardless of whether the model was residualized or unresidiualized
# so manually changed row names to not say .res since the columns give results for both versions (see column name to know if residualized or not)

## Correctly generates plots w/ titles
lapply(seq_along(varImpInfo), function(x) {
  plot(varImpInfo[[x]], top = 20, main = paste(names(varImpInfo)[[x]]))
})
## Figure out how to also save to files
## Not nice manual way using Rstudio temp files (but plots aren't blurry)
#dir.create(path = paste0(results.dir, "VarImpPlots")) # (only need to create this dir once)
plots.dir.path <- list.files(tempdir(), pattern="rs-graphics", full.names = TRUE); 
plots.png.paths <- list.files(plots.dir.path, pattern=".png", full.names = TRUE)
file.copy(from=plots.png.paths, to=paste0(results.dir, "VarImpPlots/"))

## This works, but plots are blurry. could probably use lapply option. 
## think adding print(plot()) is what made it work
# for(x in 1:length(varImpInfo)){
#   print(paste0(results.dir, "VarImpPlots/", names(varImpInfo)[x], ".Var.Imp.png"))
#   png(filename = paste0(results.dir, "VarImpPlots/", names(varImpInfo)[x], ".Var.Imp.png"), )
#   print(plot(varImpInfo[[x]], top = 20, main = paste(names(varImpInfo)[[x]])))
#   dev.off()
# }

 # lapply(seq_along(varImpInfo), function(x) {
 #   jpeg(filename = paste0(results.dir, names(varImpInfo)[[x]], ".Var.Imp.jpeg"))
 #   plot(varImpInfo[[x]], top = 20, main = paste(names(varImpInfo)[[x]]))
 #   dev.off()
 # })

# Calculate RMSE for predicted values in validation data 
# NOTE: SHOULD ONLY BE DOING FOR BEST MODEL FOR EACH TP/MEASURE. 
#       also didn't figure out extractPrediction function so using lapply instead
## Baseline ##
valData.bl.predictions <- lapply(bl_model_list, function(model) predict(model, valData.bl))
## FU10 ##
valData.FU10.predictions <- lapply(FU10_model_list, function(model) predict(model, valData.FU10))
## FU12 ##
valData.FU12.predictions <- lapply(FU12_model_list, function(model) predict(model, valData.FU12))

# Create dataframe that output as file
valPerf.df <- as.data.frame(rbind( 
  # BL
  do.call(rbind, lapply(valData.bl.predictions[grep("MAPPOC.adapt", names(valData.bl.predictions))], function(model) 
    postResample(pred = model, obs = valData.bl$PMAPPOC_scaled))), # not residualized (if run)
  do.call(rbind, lapply(valData.bl.predictions[grep("MAPPOC.res.adapt", names(valData.bl.predictions))], function(model)  
    postResample(pred = model, obs = valData.bl$PMAPPOC_scaled.res))), 
  do.call(rbind, lapply(valData.bl.predictions[grep("SIDPOC.adapt", names(valData.bl.predictions))], function(model) 
    postResample(pred = model, obs = valData.bl$SIDPOC_scaled))), # not residualized (if run)
  do.call(rbind, lapply(valData.bl.predictions[grep("SIDPOC.res.adapt", names(valData.bl.predictions))], function(model) 
    postResample(pred = model, obs = valData.bl$SIDPOC_scaled.res))), # residualized
  # FU10
  do.call(rbind, lapply(valData.FU10.predictions[grep("MAPPOC.adapt", names(valData.FU10.predictions))], function(model) 
    postResample(pred = model, obs = valData.FU10$PFU10MAPPOC_scaled))), # not residualized (if run)
  do.call(rbind, lapply(valData.FU10.predictions[grep("MAPPOC.res.adapt", names(valData.FU10.predictions))], function(model) 
    postResample(pred = model, obs = valData.FU10$PFU10MAPPOC_scaled.res))), # residualized
  do.call(rbind, lapply(valData.FU10.predictions[grep("SIDPOC.adapt", names(valData.FU10.predictions))], function(model) 
    postResample(pred = model, obs = valData.FU10$FU10SIDPOC_scaled))), # not residualized (if run)
  do.call(rbind, lapply(valData.FU10.predictions[grep("SIDPOC.res.adapt", names(valData.FU10.predictions))], function(model) 
    postResample(pred = model, obs = valData.FU10$FU10SIDPOC_scaled.res))), # residualized
  do.call(rbind, lapply(valData.FU10.predictions[grep("FFOCI.adapt", names(valData.FU10.predictions))], function(model)
    postResample(pred = model, obs = valData.FU10$FU10FFOCI_Scaled.Total))), # not residualized (if run)
  do.call(rbind, lapply(valData.FU10.predictions[grep("FFOCI.res.adapt", names(valData.FU10.predictions))], function(model)
    postResample(pred = model, obs = valData.FU10$FU10FFOCI_Scaled.Total.res))), # residualized
  # FU12
  do.call(rbind, lapply(valData.FU12.predictions[grep("MAPPOC.adapt", names(valData.FU12.predictions))], function(model) 
    postResample(pred = model, obs = valData.FU12$PFU12MAPPOC_scaled))), # not residualized (if run)
  do.call(rbind, lapply(valData.FU12.predictions[grep("MAPPOC.res.adapt", names(valData.FU12.predictions))], function(model) 
    postResample(pred = model, obs = valData.FU12$PFU12MAPPOC_scaled.res))), # residualized
  do.call(rbind, lapply(valData.FU12.predictions[grep("FFOCI.adapt", names(valData.FU12.predictions))], function(model)
    postResample(pred = model, obs = valData.FU12$FU12FFOCI_Scaled.Total))), # not residualized (if run)
  do.call(rbind, lapply(valData.FU12.predictions[grep("FFOCI.res.adapt", names(valData.FU12.predictions))], function(model)
    postResample(pred = model, obs = valData.FU12$FU12FFOCI_Scaled.Total.res))))) # residualized

## Add outcome SD + RMSE/OutcomeSD to the dataframe for reference
valPerf.df <- mutate(valPerf.df, 
    OutcomeSD =
      c(rep(sd(valData.bl$PMAPPOC_scaled), 4), rep(sd(valData.bl$PMAPPOC_scaled.res), 4), rep(sd(valData.bl$SIDPOC_scaled), 4), rep(sd(valData.bl$SIDPOC_scaled.res), 4),
        rep(sd(valData.FU10$PFU10MAPPOC_scaled), 4), rep(sd(valData.FU10$PFU10MAPPOC_scaled.res), 4), rep(sd(valData.FU10$FU10SIDPOC_scaled), 4), rep(sd(valData.FU10$FU10SIDPOC_scaled.res), 4), rep(sd(valData.FU10$FU10FFOCI_Scaled.Total), 4), rep(sd(valData.FU10$FU10FFOCI_Scaled.Total.res), 4),  
        rep(sd(valData.FU12$PFU12MAPPOC_scaled), 4), rep(sd(valData.FU12$PFU12MAPPOC_scaled.res), 4), rep(sd(valData.FU12$FU12FFOCI_Scaled.Total), 4), rep(sd(valData.FU12$FU12FFOCI_Scaled.Total.res), 4)))    
valPerf.df <- mutate(valPerf.df, RMSE.to.SD = RMSE/OutcomeSD)

write.csv(valPerf.df, file = paste0(results.dir, "validation.data.out.of.sample.performance.csv"), row.names = TRUE)
          
#valOutcomeVars <- c(rep("valData.bl$PMAPPOC_scaled.res", 4), rep("valData.bl$PMAPPOC_scaled", 4), rep("valData.bl$SIDPPOC_scaled.res", 4), rep("valData.bl$SIDPPOC_scaled", 4), 
#          rep("valData.FU10$PFU10MAPPOC_scaled.res", 4), rep("valData.FU10$PFU10MAPPOC_scaled", 4), rep("valData.FU10$FU10SIDPPOC_scaled.res", 4), rep("valData.FU10$FU10SIDPPOC_scaled", 4), rep("valData.FU10$FU10FFOCI_Scaled.Total.res", 4), rep("valData.FU10$FU10FFOCI_Scaled.Total", 4),  
#          rep("valData.FU12$PFU12MAPPOC_scaled.res", 4), rep("valData.FU12$PFU12MAPPOC_scaled", 4), rep("valData.FU12$FU12FFOCI_Scaled.Total.res", 4), rep("valData.FU12$FU12FFOCI_Scaled.Total", 4)), 1, FUN = sd))

# Calculate performance for final model in test data
# residulized
testData.final.model.res.FU12.predictions <- predict(FU12.FFOCI.res.adapt.model.list$glmnet, testData.FU12)
postResample(pred = testData.final.model.res.FU12.predictions, obs = testData.FU12$FU12FFOCI_Scaled.Total.res)
#       RMSE   Rsquared        MAE 
# 12.0668300  0.5527414  9.6055055 
RMSE(pred = testData.final.model.res.FU12.predictions, obs = testData.FU12$FU12FFOCI_Scaled.Total.res)/sd(testData.FU12$FU12FFOCI_Scaled.Total.res)
# 0.6669442
# unresidualized
testData.final.model.NOTres.FU12.predictions <- predict(FU12.FFOCI.adapt.model.list$glmnet, testData.FU12)
postResample(pred = testData.final.model.NOTres.FU12.predictions, obs = testData.FU12$FU12FFOCI_Scaled.Total)
# RMSE   Rsquared        MAE 
# 12.4118016  0.5623333  9.5960002 
RMSE(pred = testData.final.model.NOTres.FU12.predictions, obs = testData.FU12$FU12FFOCI_Scaled.Total)/sd(testData.FU12$FU12FFOCI_Scaled.Total)
# 0.6775621

testPerf.df <- as.data.frame(rbind(
  postResample(pred = testData.final.model.res.FU12.predictions, obs = testData.FU12$FU12FFOCI_Scaled.Total.res),
  postResample(pred = testData.final.model.NOTres.FU12.predictions, obs = testData.FU12$FU12FFOCI_Scaled.Total))) %>% 
  mutate(model = c("FU12.FFOCI.res.adapt.model.list$glmnet", "FU12.FFOCI.adapt.model.list$glmnet"),
         OutcomeSD = c(sd(testData.FU12$FU12FFOCI_Scaled.Total.res), sd(testData.FU12$FU12FFOCI_Scaled.Total))) %>%
  mutate(RMSE.to.SD = RMSE/OutcomeSD)
write.csv(testPerf.df, paste0(results.dir, "test.data.performance.csv"))

extractPrediction(FU12.FFOCI.res.adapt.model.list$glmnet, testX = select(testData.FU12, matches("NEO.*\\.res$")), 
                  testY = testData.FU12$FU12FFOCI_Scaled.Total.res)

# Load saved models (if needed)
rdsfiles <- list.files(path = results.dir, pattern = ".Rds$")
saved.models <- lapply(rdsfiles, function(x) readRDS(paste0(results.dir, x)))
names(saved.models) <- gsub("\\.Rds*$","", rdsfiles)
list2env(saved.models, envir = environment())
bl_model_list <- saved.models[grep("bl", names(saved.models))]
FU10_model_list <- saved.models[grep("FU10", names(saved.models))]
FU12_model_list <- saved.models[grep("FU12", names(saved.models))]

# Stop parallel processing
stopCluster(cl)
```

#### 9) Evaluate external validity in Doug's data ----------------------------
```{r}
# Run separate script "External.Validity.Rmd"
```

#### 10) Apply trained model to DNS NEO data #### -----------------------------
```{r}
# Note: All subjs have some NEO data so _not.NAs df same as orig one
# ADD DEMOG VARAIBLES TO NEO DF
DNS.NEO.raw.data_not.NAs <- full_join(DNS.NEO.raw.data_not.NAs, DNS.demo.data, by = "ID")
DNS.NEO.raw.data_not.NAs <- DNS.NEO.raw.data_not.NAs %>%
                            select(-c("AGE.y", "RACE.y", "LATINO.y")) %>%
                            rename(c(AGE = AGE.x, RACE = RACE.x, LATINO = LATINO.x))

# Rename DNS NEO data to fit SPAN variable name scheme since trained models use SPAN var names
## NOTE: tried many combinations of names(select()) and rename() or rename_with() and mutate_at(). 
##       none worked, so using this slightly janky base R method
rename.DNS.NEO <- function(df){
  # Neuroticism
  names(df)[names(df) %in% paste0("NEO_", c(1, 31, 61, 91, 121, 151, 181, 211))] <- sprintf("NEON1%d", 1:8)
  names(df)[names(df) %in% paste0("NEO_", c(6, 36, 66, 96, 126, 156, 186, 216))] <- sprintf("NEON2%d", 1:8)
  names(df)[names(df) %in% paste0("NEO_", c(11, 41, 71, 101, 131, 161, 191, 221))] <- sprintf("NEON3%d", 1:8)
  names(df)[names(df) %in% paste0("NEO_", c(16, 46, 76, 106, 136, 166, 196, 226))] <- sprintf("NEON4%d", 1:8)
  names(df)[names(df) %in% paste0("NEO_", c(21, 51, 81, 111, 141, 171, 201, 231))] <- sprintf("NEON5%d", 1:8)
  names(df)[names(df) %in% paste0("NEO_", c(26, 56, 86, 116, 146, 176, 206, 236))] <- sprintf("NEON6%d", 1:8)
  # Extraversion
  names(df)[names(df) %in% paste0("NEO_", c(2, 32, 62, 92, 122, 152, 182, 212))] <- sprintf("NEOE1%d", 1:8)
  names(df)[names(df) %in% paste0("NEO_", c(7, 37, 67, 97, 127, 157, 187, 217))] <- sprintf("NEOE2%d", 1:8)
  names(df)[names(df) %in% paste0("NEO_", c(12, 42, 72, 102, 132, 162, 192, 222))] <- sprintf("NEOE3%d", 1:8)
  names(df)[names(df) %in% paste0("NEO_", c(17, 47, 77, 107, 137, 167, 197, 227))] <- sprintf("NEOE4%d", 1:8)
  names(df)[names(df) %in% paste0("NEO_", c(22, 52, 82, 112, 142, 172, 202, 232))] <- sprintf("NEOE5%d", 1:8)
  names(df)[names(df) %in% paste0("NEO_", c(27, 57, 87, 117, 147, 177, 207, 237))] <- sprintf("NEOE6%d", 1:8)
  # Openness   
  names(df)[names(df) %in% paste0("NEO_", c(3, 33, 63, 93, 123, 153, 183, 213))] <- sprintf("NEOO1%d", 1:8) 
  names(df)[names(df) %in% paste0("NEO_", c(8, 38, 68, 98, 128, 158, 188, 218))] <- sprintf("NEOO2%d", 1:8) 
  names(df)[names(df) %in% paste0("NEO_", c(13, 43, 73, 103, 133, 163, 193, 223))] <- sprintf("NEOO3%d", 1:8) 
  names(df)[names(df) %in% paste0("NEO_", c(18, 48, 78, 108, 138, 168, 198, 228))] <- sprintf("NEOO4%d", 1:8) 
  names(df)[names(df) %in% paste0("NEO_", c(23, 53, 83, 113, 143, 173, 203, 233))] <- sprintf("NEOO5%d", 1:8) 
  names(df)[names(df) %in% paste0("NEO_", c(28, 58, 88, 118, 148, 178, 208, 238))] <- sprintf("NEOO6%d", 1:8) 
  # Agreeableness
  names(df)[names(df) %in% paste0("NEO_", c(4, 34, 64, 94, 124, 154, 184, 214))] <- sprintf("NEOA1%d", 1:8)
  names(df)[names(df) %in% paste0("NEO_", c(9, 39, 69, 99, 129, 159, 189, 219))] <- sprintf("NEOA2%d", 1:8)
  names(df)[names(df) %in% paste0("NEO_", c(14, 44, 74, 104, 134, 164, 194, 224))] <- sprintf("NEOA3%d", 1:8)
  names(df)[names(df) %in% paste0("NEO_", c(19, 49, 79, 109, 139, 169, 199, 229))] <- sprintf("NEOA4%d", 1:8)
  names(df)[names(df) %in% paste0("NEO_", c(24, 54, 84, 114, 144, 174, 204, 234))] <- sprintf("NEOA5%d", 1:8)
  names(df)[names(df) %in% paste0("NEO_", c(29, 59, 89, 119, 149, 179, 209, 239))] <- sprintf("NEOA6%d", 1:8)
  # Conscientiousness
  names(df)[names(df) %in% paste0("NEO_", c(5, 35, 65, 95, 125, 155, 185, 215))] <- sprintf("NEOC1%d", 1:8)
  names(df)[names(df) %in% paste0("NEO_", c(10, 40, 70, 100, 130, 160, 190, 220))] <- sprintf("NEOC2%d", 1:8)
  names(df)[names(df) %in% paste0("NEO_", c(15, 45, 75, 105, 135, 165, 195, 225))] <- sprintf("NEOC3%d", 1:8)
  names(df)[names(df) %in% paste0("NEO_", c(20, 50, 80, 110, 140, 170, 200, 230))]  <- sprintf("NEOC4%d", 1:8)
  names(df)[names(df) %in% paste0("NEO_", c(25, 55, 85, 115, 145, 175, 205, 235))] <- sprintf("NEOC5%d", 1:8)
  names(df)[names(df) %in% paste0("NEO_", c(30, 60, 90, 120, 150, 180, 210, 240))] <- sprintf("NEOC6%d", 1:8)
  return(df)
}
DNS.NEO.raw.data_not.NAs <- rename.DNS.NEO(DNS.NEO.raw.data_not.NAs)

# Convert gender variable to factor
DNS.NEO.raw.data_not.NAs <- mutate(DNS.NEO.raw.data_not.NAs, GENDER.factor = factor(GENDER, levels = c(1,2), 
                                    labels = c("male", "female")))

# Remove subjs missing gender + age data, b/c need those data to residualize
## Subjs missing gender data
which(is.na(DNS.NEO.raw.data_not.NAs$GENDER))
### None missing
## Subjs missing  age data
which(is.na(DNS.NEO.raw.data_not.NAs$AGE))
### None missing

# Handle missing NEO data
## Number of NEO Qs subjs are missing data for
table(rowSums(is.na(DNS.NEO.raw.data_not.NAs[ ,5:244])))
# 1 subj (DNS007) is missing data - 24 Qs. 
# 24 < 25% of NEO Qs, so not removing subject
# DNS0047 doesn't have any NEO data and isn't in the dataframe

## Determine how many Qs subjs are missing data for on each facet
NEO.facet.name <- c(sprintf("NEOO%s", seq(1:6)),
     sprintf("NEOC%s", seq(1:6)), sprintf("NEOE%s", seq(1:6)),
     sprintf("NEOA%s", seq(1:6)), sprintf("NEON%s", seq(1:6)))

for(i in NEO.facet.name){
    print(i)
    print(table(rowSums(is.na(DNS.NEO.raw.data_not.NAs[ , 
                     grep(paste(i, "\\d", sep = ""), names(DNS.NEO.raw.data_not.NAs), value = TRUE)]))))
}

## Calculate facet means
DNS.NEO.raw.data_not.NAs <- calc.facet.means(DNS.NEO.raw.data_not.NAs)

## Replace NEO NA values w/ facet mean
DNS.NEO.raw.data_not.NAs.NEO.imputed <- impute.w.NEO.facet.means(DNS.NEO.raw.data_not.NAs)

## Residualize variables to control for covariates 
# for OCPD model, "controlling for" gender and age 
# NOTE: cannot use for categorical outcome

residualize.predictors.DNS <- function(df){
    X <- df[c("GENDER.factor", "AGE")]  # covariates
    Y <- select(df, matches("^NEO[A-Z]\\d\\d$"))  # NEO items
    list_models <- lapply(Y, function(Y) with(X, lm(Y ~ GENDER.factor + AGE, 
                                                    na.action = "na.exclude"))) # Run all models
    list_resid <- lapply(list_models, resid) # List residuals from all models
    df_resid <- do.call(cbind.data.frame, list_resid) # Put residuals in dataframe
    colnames(df_resid) <- paste(colnames(df_resid), "res", sep = ".") # Add ".res" to variable names
    df <- cbind(df, df_resid) # Add residualized variables to df
    return(df) # Make function return the dataframe
}
DNS.NEO.raw.data_not.NAs.NEO.imputed <- residualize.predictors.DNS(DNS.NEO.raw.data_not.NAs.NEO.imputed)

## Predict FFOCI scores for DNS participants using final model trained in SPAN data
final.SPAN.model.res <- FU12.FFOCI.res.adapt.model.list$glmnet
final.SPAN.model.NOT.res <- FU12.FFOCI.adapt.model.list$glmnet

# Remove PFU12 from the variable names so the model can predict on DNS data that don't have that in variable names (this doesn't work)
# final.SPAN.model$terms[[3]] <- gsub('PFU12', '', final.SPAN.model$terms[[3]])
# substr(final.SPAN.model$terms[[3]], start = 6, stop = nchar(final.SPAN.model$terms[[3]]))
# terms.gsub.lapply <- lapply(final.SPAN.model, function(x) grepl('PFU12', names(x)))
# final.SPAN.model$terms <- as.formula(parse(text = gsub("PFU12", "", format(final.SPAN.model$terms))))
#
# final.SPAN.model.res$terms[[3]] <- parse(text = gsub("PFU12", "", format(final.SPAN.model.res$terms[[3]])))
# final.SPAN.model.res$terms <- as.formula(paste0("FU12FFOCI_Scaled.Total.res ~ ", gsub("PFU12", "", final.SPAN.model.res$terms)[3]))
# final.SPAN.model.res$coefnames <- gsub("PFU12", "", final.SPAN.model.res$coefnames)
# None of these above really work when try to use predict function
# DNS.predicted.FFOCI <- predict(final.SPAN.model, DNS.NEO.raw.data_not.NAs.NEO.imputed)

# it works if make DNS var names the same as SPAN final model (i.e., start w/ PFU12)
colnames(DNS.NEO.raw.data_not.NAs.NEO.imputed) <- paste0("PFU12", colnames(DNS.NEO.raw.data_not.NAs.NEO.imputed))

# NOTE: caret automatically applies the same pre-processing specified during model training (here, centering + scaling)
# to the new data when generating predictions (https://topepo.github.io/caret/model-training-and-tuning.html#customizing-the-tuning-process)

## RESIDUALIZED MODEL
DNS.predicted.FFOCI.res <- predict(final.SPAN.model.res, DNS.NEO.raw.data_not.NAs.NEO.imputed) %>% 
  as.data.frame(., col.names = c("predicted.score")) %>%
  mutate(., DNSID = DNS.NEO.raw.data_not.NAs.NEO.imputed$PFU12ID)
write.csv(DNS.predicted.FFOCI.res, file = paste0(results.dir, "DNS.predicted.FFOCI.Scaled.Total.Res_FU12glmnet.model.csv"),
            row.names = FALSE)
## UNRESIDUALIZED MODEL
DNS.predicted.FFOCI.not.res <- predict(final.SPAN.model.NOT.res, DNS.NEO.raw.data_not.NAs.NEO.imputed) %>%
  as.data.frame(., col.names = c("predicted.score")) %>%
  mutate(., DNSID = DNS.NEO.raw.data_not.NAs.NEO.imputed$PFU12ID)
write.csv(DNS.predicted.FFOCI.not.res, file = paste0(results.dir, "DNS.predicted.FFOCI.Scaled.Total.Not.Res_FU12glmnet.model.csv"),
          row.names = FALSE)

# Change back DNS variable names
colnames(DNS.NEO.raw.data_not.NAs.NEO.imputed) <- gsub("PFU12", "", colnames(DNS.NEO.raw.data_not.NAs.NEO.imputed))
# Should probably figure out how to get predictions w/o having to name the DNS data as "PFU12..." but already spent hours on this

## Check how correlated predictions are for residualized vs. non-residualized models
cor(DNS.predicted.FFOCI.res$., DNS.predicted.FFOCI.not.res$.)
# r=0.9976 
summary(lm(DNS.predicted.FFOCI.res$. ~ DNS.predicted.FFOCI.not.res$. + DNS.NEO.raw.data_not.NAs.NEO.imputed$AGE + 
             DNS.NEO.raw.data_not.NAs.NEO.imputed$GENDER.factor))

### Recalculate NEO facet totals using imputed item data
calc.facet.totals <- function(df) {
    # Agreeableness
    df[["NEOA1_imputed"]] <- df %>% select(matches("^NEOA1\\d$")) %>% rowSums(., na.rm = TRUE) 
    df[["NEOA2_imputed"]] <- df %>% select(matches("^NEOA2\\d$")) %>% rowSums(., na.rm = TRUE) 
    df[["NEOA3_imputed"]] <- df %>% select(matches("^NEOA3\\d$")) %>% rowSums(., na.rm = TRUE) 
    df[["NEOA4_imputed"]] <- df %>% select(matches("^NEOA4\\d$")) %>% rowSums(., na.rm = TRUE) 
    df[["NEOA5_imputed"]] <- df %>% select(matches("^NEOA5\\d$")) %>% rowSums(., na.rm = TRUE) 
    df[["NEOA6_imputed"]] <- df %>% select(matches("^NEOA6\\d$")) %>% rowSums(., na.rm = TRUE)
    df[["NEOA_imputed"]] <- df %>% select(matches("^NEOA\\d_imputed$")) %>% rowSums(., na.rm = TRUE) #factor/domain total
    # Extraversion
    df[["NEOE1_imputed"]] <- df %>% select(matches("^NEOE1\\d$")) %>% rowSums(., na.rm = TRUE) 
    df[["NEOE2_imputed"]] <- df %>% select(matches("^NEOE2\\d$")) %>% rowSums(., na.rm = TRUE) 
    df[["NEOE3_imputed"]] <- df %>% select(matches("^NEOE3\\d$")) %>% rowSums(., na.rm = TRUE) 
    df[["NEOE4_imputed"]] <- df %>% select(matches("^NEOE4\\d$")) %>% rowSums(., na.rm = TRUE) 
    df[["NEOE5_imputed"]] <- df %>% select(matches("^NEOE5\\d$")) %>% rowSums(., na.rm = TRUE) 
    df[["NEOE6_imputed"]] <- df %>% select(matches("^NEOE6\\d$")) %>% rowSums(., na.rm = TRUE) 
    df[["NEOE_imputed"]] <- df %>% select(matches("^NEOE\\d_imputed$")) %>% rowSums(., na.rm = TRUE) #factor/domain total
    # Conscientiousness
    df[["NEOC1_imputed"]] <- df %>% select(matches("^NEOC1\\d$")) %>% rowSums(., na.rm = TRUE) 
    df[["NEOC2_imputed"]] <- df %>% select(matches("^NEOC2\\d$")) %>% rowSums(., na.rm = TRUE) 
    df[["NEOC3_imputed"]] <- df %>% select(matches("^NEOC3\\d$")) %>% rowSums(., na.rm = TRUE) 
    df[["NEOC4_imputed"]] <- df %>% select(matches("^NEOC4\\d$")) %>% rowSums(., na.rm = TRUE) 
    df[["NEOC5_imputed"]] <- df %>% select(matches("^NEOC5\\d$")) %>% rowSums(., na.rm = TRUE) 
    df[["NEOC6_imputed"]] <- df %>% select(matches("^NEOC6\\d$")) %>% rowSums(., na.rm = TRUE)
    df[["NEOC_imputed"]] <- df %>% select(matches("^NEOC\\d_imputed$")) %>% rowSums(., na.rm = TRUE) #factor/domain total
    # Openness
    df[["NEOO1_imputed"]] <- df %>% select(matches("^NEOO1\\d$")) %>% rowSums(., na.rm = TRUE) 
    df[["NEOO2_imputed"]] <- df %>% select(matches("^NEOO2\\d$")) %>% rowSums(., na.rm = TRUE) 
    df[["NEOO3_imputed"]] <- df %>% select(matches("^NEOO3\\d$")) %>% rowSums(., na.rm = TRUE) 
    df[["NEOO4_imputed"]] <- df %>% select(matches("^NEOO4\\d$")) %>% rowSums(., na.rm = TRUE) 
    df[["NEOO5_imputed"]] <- df %>% select(matches("^NEOO5\\d$")) %>% rowSums(., na.rm = TRUE) 
    df[["NEOO6_imputed"]] <- df %>% select(matches("^NEOO6\\d$")) %>% rowSums(., na.rm = TRUE) 
    df[["NEOO_imputed"]] <- df %>% select(matches("^NEOO\\d_imputed$")) %>% rowSums(., na.rm = TRUE) #factor/domain total
    # Neuroticism
    df[["NEON1_imputed"]] <- df %>% select(matches("^NEON1\\d$")) %>% rowSums(., na.rm = TRUE) 
    df[["NEON2_imputed"]] <- df %>% select(matches("^NEON2\\d$")) %>% rowSums(., na.rm = TRUE) 
    df[["NEON3_imputed"]] <- df %>% select(matches("^NEON3\\d$")) %>% rowSums(., na.rm = TRUE) 
    df[["NEON4_imputed"]] <- df %>% select(matches("^NEON4\\d$")) %>% rowSums(., na.rm = TRUE) 
    df[["NEON5_imputed"]] <- df %>% select(matches("^NEON5\\d$")) %>% rowSums(., na.rm = TRUE) 
    df[["NEON6_imputed"]] <- df %>% select(matches("^NEON6\\d$")) %>% rowSums(., na.rm = TRUE)
    df[["NEON_imputed"]] <- df %>% select(matches("^NEON\\d_imputed$")) %>% rowSums(., na.rm = TRUE) #factor/domain total
    return(df)
}
DNS.NEO.raw.data_not.NAs.NEO.imputed <- calc.facet.totals(DNS.NEO.raw.data_not.NAs.NEO.imputed)

```
##11) Crit. Validity

Correlations between predicted and actual FFOCI scores and variables related to OCPD
```{r}
# BDI #
## Load data + add to main dataframes
SPAN.BL.BDI <- read.csv(paste0(span.data.dir, "Baseline/Participant/Cooked/BDI.csv"), na.strings = ".")
SPAN.FU10.BDI <- read.csv(paste0(span.data.dir, "FU10/Participant/Cooked/FU10BDI.csv"), na.strings = ".")
SPAN.FU12.BDI <- read.csv(paste0(span.data.dir, "FU12/Participant/Cooked/FU12BDI.csv"), na.strings = ".")

SPAN.FINAL.DATA$SPAN.bl.NEO.and.OCPD.data.not <- left_join(SPAN.FINAL.DATA$SPAN.bl.NEO.and.OCPD.data.not, SPAN.BL.BDI, by = "PARTID")
SPAN.FINAL.DATA$SPAN.FU10.NEO.and.OCPD.data.n <- left_join(SPAN.FINAL.DATA$SPAN.FU10.NEO.and.OCPD.data.n, SPAN.FU10.BDI, by = "PARTID")
SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n <- left_join(SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n, SPAN.FU12.BDI, by = "PARTID")

## Correlations
### Actual FFOCI
cor(SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n$FU12FFOCI_Scaled.Total, SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n$FU12BDI_scaled, 
    use = "complete.obs")
#### r=0.156678
### MAPP
cor(SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n$PFU12MAPPOC_scaled, SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n$FU12BDI_scaled, 
    use = "complete.obs")
#### [1] 0.2659305

### Predicted FFOCI
cor(FU12.predicted.FFOCI.glmnet.res, SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n$FU12BDI_scaled, use = "complete.obs")
#### r=0.1981928

# Relationship Satisfaction #
SPAN.BL.DAS.P <- read_xls(paste0(span.data.dir, "Baseline/Participant/Cooked/PDAS_Cooked.xlsx"), na = ".")
SPAN.FU10.DAS.P <- read_csv(paste0(span.data.dir, "FU10/Participant/Cooked/PFU10DAS_Cooked.csv"), na = ".")
SPAN.FU12.DAS.P <- read_csv(paste0(span.data.dir, "FU12/Participant/Cooked/PFU12DAS_Cooked.csv"), na = ".")
SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n <- left_join(SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n, SPAN.FU12.DAS.P, by = "PARTID")
## Correlations
### Actual FFOCI
cor(SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n$FU12FFOCI_Scaled.Total, SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n$PFU12DAS_scaled, 
    use = "complete.obs")
#### r= -0.08614307
### Predicted FFOCI
cor(FU12.predicted.FFOCI.glmnet.res, SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n$PFU12DAS_scaled, use = "complete.obs")
#### r= -0.08912061
```

OCPD measures' ability to predict functioning, impairment, help-seeking, etc.
```{r}
# Add criterion validity variables/measures to the dataframes
SPAN.FINAL.DATA$SPAN.bl.NEO.and.OCPD.data.not <- left_join(SPAN.FINAL.DATA$SPAN.bl.NEO.and.OCPD.data.not, 
                                                                critValBLData$PSAS, by = "PARTID") %>%
                                                  left_join(., critValBLData$PDAS_Cooked, by = "PARTID") %>%
                                                  left_join(., informantBLData$IDAS_Cooked, by = "PARTID") %>%
                                                  left_join(., informantBLData$ISAS, by = "PARTID") %>%
                                                            left_join(., BLDemoSup, by = "PARTID")

SPAN.FINAL.DATA$SPAN.FU10.NEO.and.OCPD.data.n <- left_join(SPAN.FINAL.DATA$SPAN.FU10.NEO.and.OCPD.data.n, 
                                                           critValFU10Data$PFU10SAS, by = "PARTID") %>%
                                                left_join(., critValFU10Data$FU10SNQ, by = "PARTID") %>%
                                                left_join(., critValFU10Data$FU10SWLS , by = "PARTID") %>%
                                                left_join(., critValFU10Data$FU10UCLA , by = "PARTID") %>%
                                                left_join(., critValFU10Data$PFU10HBC , by = "PARTID") %>%
                                                left_join(., critValFU10Data$PFU10HSI , by = "PARTID") %>%
                                                left_join(., critValFU10Data$PFU10SFS , by = "PARTID") %>%
                                                left_join(., FU10Demo, by = "PARTID") %>%

  SPAN.FINAL.DATA$SPAN.FU10.NEO.and.OCPD.data.n <-  left_join(SPAN.FINAL.DATA$SPAN.FU10.NEO.and.OCPD.data.n, informantFU10Data$IFU10DAS_Cooked, by = "PARTID") %>%
                                                left_join(., informantFU10Data$IFU10SFS)

SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n <- left_join(SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n, 
                                                           critValFU12Data$FU12SNQ, by = "PARTID") %>%
                                                left_join(., critValFU12Data$FU12UCLA , by = "PARTID") %>%
                                                left_join(., critValFU12Data$PFU12HBC , by = "PARTID") %>%  
                                                left_join(., critValFU12Data$PFU12HSI , by = "PARTID") %>%  
                                                left_join(., critValFU12Data$PFU12SAS , by = "PARTID") %>%  
                                                left_join(., critValFU12Data$PFU12SFS , by = "PARTID") %>%  
                                                left_join(., critValFU12Data$PFU12SWLS , by = "PARTID") %>%  
                                                left_join(., FU12Demo, by = "PARTID")

  SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n <-  left_join(SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n, informantFU12Data$IFU12DAS_Cooked, by = "PARTID") %>%
                                                left_join(., informantFU12Data$IFU12SFS)


# Help-seeking
## Baseline - SD5 (Have you ever received treatment for a mental disorder or advice from a mental health professional on problems in life (e.g. Life 	coach)?)
#BL.MH.tx.MAPP <- glm(as.factor(SD5) ~ PMAPPOC_scaled, data = SPAN.FINAL.DATA$SPAN.bl.NEO.and.OCPD.data.not, family = "binomial")
#BL.MH.tx.SIDP <- glm(as.factor(SD5) ~ SIDPOC_scaled, data = SPAN.FINAL.DATA$SPAN.bl.NEO.and.OCPD.data.not, family = "binomial")

# Run analyses together
# Baseline models
BL.crit.validity.models = list()
for (i in c("PSASFactorC", "PSASFactorA", "PEdu", "BDI_scaled", "PDAS_scaled", "IDAS_scaled.x")){
  for (j in c("PMAPPOC_scaled", "SIDPOC_scaled")){
    BL.crit.validity.models[[paste("DV", i, "vs", "IV", j, sep = "_")]] <- 
      lm(as.formula(paste(i, "~", j)), data = SPAN.FINAL.DATA$SPAN.bl.NEO.and.OCPD.data.not)
    BL.crit.validity.models[[paste("DV", "Bl.MH.tx", "vs", "IV", j, sep = "_")]] <- 
      glm(as.formula(paste("as.factor(SD5) ~ ", j)), data = SPAN.FINAL.DATA$SPAN.bl.NEO.and.OCPD.data.not, family = "binomial")
  }
}

## standardized - equivalent to correlations below (But this shows model fit statistics for comparison)
BL.crit.validity.models.std <- lapply(BL.crit.validity.models[c(1, 3, 5:14)], lm.beta) #doesn't include MH tx (Yes/NO) 
# b/c those were factor variables which was causing issues for standardization

## Results table
tab_model(BL.crit.validity.models, show.se = TRUE, show.stat = TRUE, digits = 3, collapse.ci = TRUE, show.fstat = TRUE, show.dev = TRUE,
          file = paste0(project.dir, "Results/Criterion.Validity/BL.crit.validity.results.html"))
tab_model(BL.crit.validity.models.std, show.se = TRUE, show.stat = TRUE, digits = 3, collapse.ci = TRUE, show.fstat = TRUE, show.dev = TRUE,
          file = paste0(project.dir, "Results/Criterion.Validity/BL.crit.validity.std.results.html"))

# FU10 models
FU10.crit.validity.models = list()
for (i in c("PFU10SASFactorC", "PFU10SFS_scaled",  "FU10SNQ_scaled", # social functioning 
            "PEdu", "FU10BDI_scaled", "PFU10DAS_scaled", "IFU10DAS_scaled", 
            "FU10SWLS_scaled", "FU10UCLA_scaled", # satisfaction w/ life, loneliness
            "GHP16_scaled", # good health practices scale from HBC
            "FU10Demo14A")){ # times visited doctor's office in past 6 months
  for (j in c("PFU10MAPPOC_scaled", "FU10SIDPOC_scaled", "FU10FFOCI_Scaled.Total")){
    FU10.crit.validity.models[[paste("DV", i, "vs", "IV", j, sep = "_")]] <- 
      lm(as.formula(paste(i, "~", j)), data = SPAN.FINAL.DATA$SPAN.FU10.NEO.and.OCPD.data.n)
    FU10.crit.validity.models[[paste("DV", "FU10.MH.tx", "vs", "IV", j, sep = "_")]] <- 
      glm(as.formula(paste("as.factor(FU10Demo15) ~ ", j)), data = SPAN.FINAL.DATA$SPAN.FU10.NEO.and.OCPD.data.n, family = "binomial")
  }
}

FU10.crit.validity.models.std <- lapply(FU10.crit.validity.models[-c(2,4,6)], lm.beta)
## Results table
tab_model(FU10.crit.validity.models, show.se = TRUE, show.stat = TRUE, digits = 3, collapse.ci = TRUE, show.dev = TRUE, show.fstat = TRUE,
          file = paste0(project.dir, "Results/Criterion.Validity/FU10.crit.validity.results.html"))
tab_model(FU10.crit.validity.models.std, show.se = TRUE, show.stat = TRUE, digits = 3, collapse.ci = TRUE, show.dev = TRUE, show.fstat = TRUE,
          file = paste0(project.dir, "Results/Criterion.Validity/FU10.crit.validity.std.results.html"))
# FU12 models
FU12.crit.validity.models = list()
for (i in c("PFU12SASFactorC", "PFU12SFS_scaled", "FU12SNQ_scaled", # social functioning 
            "PEdu", "FU12BDI_scaled", "PFU12DAS_scaled", "IFU12DAS_scaled", 
            "FU12SWLS_scaled", "FU12UCLA_scaled", # satisfaction w/ life, loneliness
            "GHP16_scaled", # good health practices scale from HBC
            "FU12Demo14a")){ # times visited doctor's office in past 6 months
  for (j in c("PFU12MAPPOC_scaled", "FU12FFOCI_Scaled.Total")){
    FU12.crit.validity.models[[paste("DV", i, "vs", "IV", j, sep = "_")]] <- 
      lm(as.formula(paste(i, "~", j)), data = SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n)
    FU12.crit.validity.models[[paste("DV", "FU12.MH.tx", "vs", "IV", j, sep = "_")]] <- 
      glm(as.formula(paste("as.factor(FU12Demo15) ~ ", j)), data = SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n, family = "binomial")
  }
}
FU12.crit.validity.models.std <- lapply(FU12.crit.validity.models[-c(2,4)], lm.beta)
## Results table
tab_model(FU12.crit.validity.models, show.se = TRUE, show.stat = TRUE, digits = 3, collapse.ci = TRUE,
          file = paste0(project.dir, "Results/Criterion.Validity/FU12.crit.validity.results.html"))
tab_model(FU12.crit.validity.models.std, show.se = TRUE, show.stat = TRUE, digits = 3, collapse.ci = TRUE, show.dev = TRUE, show.fstat = TRUE,
          file = paste0(project.dir, "Results/Criterion.Validity/FU12.crit.validity.std.results.html"))
# -------------------------

# Correlations (instead of regressions. i.e. the standardized regression coefficients since didn't include covariates above)
## BASELINE
sapply(select(SPAN.FINAL.DATA$SPAN.bl.NEO.and.OCPD.data.not, c("PSASFactorC", "PSASFactorA", "PEdu", "BDI_scaled", "PDAS_scaled", "IDAS_scaled.x")), 
       cor, use = "complete.obs", # use = is an argument of the cor function that is specified to handle NAs
       y=SPAN.FINAL.DATA$SPAN.bl.NEO.and.OCPD.data.not$PMAPPOC_scaled) # specify the variable that will be the same in all of them w/ y=
# SASFactorC PSASFactorA        PEdu  BDI_scaled PDAS_scaled IDAS_scaled.x 
# 0.22650083  0.07046467  0.01393220  0.26963513 -0.08682293 -0.07333226 

biserial(SPAN.FINAL.DATA$SPAN.bl.NEO.and.OCPD.data.not$PMAPPOC_scaled, as.factor(SPAN.FINAL.DATA$SPAN.bl.NEO.and.OCPD.data.not$SD5))

sapply(select(SPAN.FINAL.DATA$SPAN.bl.NEO.and.OCPD.data.not, c("PSASFactorC", "PSASFactorA", "PEdu", "BDI_scaled", "PDAS_scaled", "IDAS_scaled.x")), 
       cor, use = "complete.obs", # use = is an argument of the cor function that is specified to handle NAs
       y=SPAN.FINAL.DATA$SPAN.bl.NEO.and.OCPD.data.not$SIDPOC_scaled) # specify the variable that will be the same in all of them w/ y=
# PSASFactorC PSASFactorA        PEdu  BDI_scaled PDAS_scaled  IDAS_scaled.x
# 0.08581164  0.05807120  0.04430632  0.12930203 -0.05870962  -0.06674767 
biserial(SPAN.FINAL.DATA$SPAN.bl.NEO.and.OCPD.data.not$SIDPOC_scaled, as.factor(SPAN.FINAL.DATA$SPAN.bl.NEO.and.OCPD.data.not$SD5))

## FU10
sapply(select(SPAN.FINAL.DATA$SPAN.FU10.NEO.and.OCPD.data.n, c("PFU10SASFactorC", "PFU10SFS_scaled",  "FU10SNQ_scaled", "IFU10SFSa_scaled",# social functioning (add informant SFS - confused about vars. emailed Abby)
            "PEdu", "FU10BDI_scaled", "PFU10DAS_scaled", "IFU10DAS_scaled", 
            "FU10SWLS_scaled", "FU10UCLA_scaled", # satisfaction w/ life, loneliness
            "GHP16_scaled", # good health practices scale from HBC
            "FU10Demo14A")), cor, use = "complete.obs", y = SPAN.FINAL.DATA$SPAN.FU10.NEO.and.OCPD.data.n$PFU10MAPPOC_scaled)
biserial(SPAN.FINAL.DATA$SPAN.FU10.NEO.and.OCPD.data.n$PFU10MAPPOC_scaled, as.factor(SPAN.FINAL.DATA$SPAN.FU10.NEO.and.OCPD.data.n$FU10Demo15))
# -0.02436981

sapply(select(SPAN.FINAL.DATA$SPAN.FU10.NEO.and.OCPD.data.n, c("PFU10SASFactorC", "PFU10SFS_scaled",  "FU10SNQ_scaled", "IFU10SFSa_scaled",# social functioning (add informant SFS - confused about vars. emailed Abby)
            "PEdu", "FU10BDI_scaled", "PFU10DAS_scaled", "IFU10DAS_scaled", 
            "FU10SWLS_scaled", "FU10UCLA_scaled", # satisfaction w/ life, loneliness
            "GHP16_scaled", # good health practices scale from HBC
            "FU10Demo14A")), cor, use = "complete.obs", y = SPAN.FINAL.DATA$SPAN.FU10.NEO.and.OCPD.data.n$FU10SIDPOC_scaled)
biserial(SPAN.FINAL.DATA$SPAN.FU10.NEO.and.OCPD.data.n$FU10SIDPOC_scaled, as.factor(SPAN.FINAL.DATA$SPAN.FU10.NEO.and.OCPD.data.n$FU10Demo15))
# 0.1244889

sapply(select(SPAN.FINAL.DATA$SPAN.FU10.NEO.and.OCPD.data.n, c("PFU10SASFactorC", "PFU10SFS_scaled",  "FU10SNQ_scaled", "IFU10SFSa_scaled",# social functioning (add informant SFS - confused about vars. emailed Abby)
            "PEdu", "FU10BDI_scaled", "PFU10DAS_scaled", "IFU10DAS_scaled", 
            "FU10SWLS_scaled", "FU10UCLA_scaled", # satisfaction w/ life, loneliness
            "GHP16_scaled", # good health practices scale from HBC
            "FU10Demo14A")), cor, use = "complete.obs", y = SPAN.FINAL.DATA$SPAN.FU10.NEO.and.OCPD.data.n$FU10FFOCI_Scaled.Total)
# PFU10SASFactorC PFU10SFS_scaled  FU10SNQ_scaled            PEdu  FU10BDI_scaled PFU10DAS_scaled IFU10DAS_scaled FU10SWLS_scaled FU10UCLA_scaled    GHP16_scaled 
#     0.25943460      0.14583901     -0.19410455     -0.12208406      0.20291690     -0.18678022     -0.04793892     -0.17555508      0.23741837     -0.06475120 
#    FU10Demo14A 
#     0.01023123 
biserial(SPAN.FINAL.DATA$SPAN.FU10.NEO.and.OCPD.data.n$FU10FFOCI_Scaled.Total, as.factor(SPAN.FINAL.DATA$SPAN.FU10.NEO.and.OCPD.data.n$FU10Demo15))
# -0.02906137

## FU12
sapply(select(SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n, c("PFU12SASFactorC", "PFU12SFS_scaled",  "FU12SNQ_scaled", "Ifu12SFSa_scaled", # social functioning (add informant SFS - confused about vars. emailed Abby)
            "PEdu", "FU12BDI_scaled", "PFU12DAS_scaled", "IFU12DAS_scaled", 
            "FU12SWLS_scaled", "FU12UCLA_scaled", # satisfaction w/ life, loneliness
            "GHP16_scaled", # good health practices scale from HBC
            "FU12Demo14a")), cor, use = "complete.obs", y = SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n$PFU12MAPPOC_scaled)
# 
biserial(SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n$PFU12MAPPOC_scaled, as.factor(SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n$FU12Demo15))

sapply(select(SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n, c("PFU12SASFactorC", "PFU12SFS_scaled",  "FU12SNQ_scaled", "Ifu12SFSa_scaled",# social functioning (add informant SFS - confused about vars. emailed Abby)
            "PEdu", "FU12BDI_scaled", "PFU12DAS_scaled", "IFU12DAS_scaled", 
            "FU12SWLS_scaled", "FU12UCLA_scaled", # satisfaction w/ life, loneliness
            "GHP16_scaled", # good health practices scale from HBC
            "FU12Demo14a")), cor, use = "complete.obs", y = SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n$FU12FFOCI_Scaled.Total)
# 

biserial(SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n$FU12FFOCI_Scaled.Total, as.factor(SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n$FU12Demo15))

### Predicted FFOCI scores using final ML model
sapply(select(SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n, c("PFU12SASFactorC", "PFU12SFS_scaled",  "FU12SNQ_scaled", "Ifu12SFSa_scaled",# social functioning (add informant SFS - confused about vars. emailed Abby)
            "PEdu", "FU12BDI_scaled", "PFU12DAS_scaled", "IFU12DAS_scaled", 
            "FU12SWLS_scaled", "FU12UCLA_scaled", # satisfaction w/ life, loneliness
            "GHP16_scaled", # good health practices scale from HBC
            "FU12Demo14a")), cor, use = "complete.obs", y = FU12.predicted.FFOCI.glmnet.res)
# PFU12SASFactorC PFU12SFS_scaled  FU12SNQ_scaled            PEdu  FU12BDI_scaled PFU12DAS_scaled IFU12DAS_scaled FU12SWLS_scaled FU12UCLA_scaled    GHP16_scaled 
#     0.23057284      0.18343384     -0.16994274     -0.16203119      0.19819280     -0.08912061     -0.08740606     -0.09840352      0.22465482     -0.09839208 
#    FU12Demo14a 
#    -0.04785889 
biserial(FU12.predicted.FFOCI.glmnet.res, as.factor(SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n$FU12Demo15))
# 0.06857156
```


##11) Misc
```{r}
# SPAN predicted FFOCI-SF scores using final model
## generate for all subjects at once, so residualize all together (not separated into training, val and test)

SPAN.FINAL.DATA$SPAN.bl.NEO.and.OCPD.data.not <- residualize.predictors.bl(SPAN.FINAL.DATA$SPAN.bl.NEO.and.OCPD.data.not)
SPAN.FINAL.DATA$SPAN.FU10.NEO.and.OCPD.data.n <- residualize.predictors.bl(SPAN.FINAL.DATA$SPAN.FU10.NEO.and.OCPD.data.n)
SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n <- residualize.predictors.FU12(SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n)

final.SPAN.model.res <- FU12_model_list$FU12.FFOCI.res.adapt.glmnet

FU12.predicted.FFOCI.glmnet.res <- predict(final.SPAN.model.res, SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n)
FU12.predicted.FFOCI.glmnet.res <- predict(FU12.FFOCI.res.adapt.glmnet, SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data.n)

```

# Neuroimaging Analyses

## Prepare data
1,305 subjects have complete (aseg + aparc), QC-passed structural MRI data
(DNS1279 doesn't have volume data, which is why volume df has 1,305 rows while aparc dfs have 1,306 rows)
One of these subjects (DNS0047) does not have NEO data, so final N for neuroimaging analyses is 1,304. 

```{r}
# Load predicted FFOCI scores (residualized version)
predicted.FFOCI.DNS <- read.csv("/Users/Shared/SharedDocs/from.Box/research/projects/dissertation/Results/Aim1.OCPD/ML/OCPD.NAs.filtered.models/from.caretList/parallel/seed.GIVEN/all.unresid.models.run/NEW.all.rerun.fixed.FU12MAPP/predicted.scores/DNS.predicted.FFOCI.Scaled.Total.Res_FU12glmnet.model.csv")
names(predicted.FFOCI.DNS) <- c("FFOCISF.pred.res", "ID")

## unresidualized version
predicted.FFOCI.notRES.DNS <- read.csv("/Users/Shared/SharedDocs/from.Box/research/projects/dissertation/Results/Aim1.OCPD/ML/OCPD.NAs.filtered.models/from.caretList/parallel/seed.GIVEN/all.unresid.models.run/NEW.all.rerun.fixed.FU12MAPP/predicted.scores/DNS.predicted.FFOCI.Scaled.Total.Not.Res_FU12glmnet.model.csv")
names(predicted.FFOCI.notRES.DNS) <- c("FFOCISF.pred", "ID")

# Combine neuroimaging dataframes into list for batch preprocessing
DNS.MRI.data_filtered.for.ML <- lst(DNS.aseg.vol.data_filtered, 
## Desikan-Killiany atlas (i.e., DK data) - includes aseg data too
                  #unlist(DNS.aparc.DK.data_filtered, recursive = FALSE, use.names = FALSE),
                                    DNS.aparc.DK.cort.thick.data_filtered,
                                    DNS.aparc.DK.surf.area.data_filtered, 
                                    DNS.aparc.DK.vol.data_filtered,
## Desikan-Killiany-Tourville atlas (i.e., DKT data) - includes aseg data too
                  #unlist(DNS.aparc.DKT.data_filtered, recursive = FALSE, use.names = FALSE))
                                    DNS.aparc.DKT.cort.thick.data_filtered,
                                    DNS.aparc.DKT.surf.area.data_filtered, 
                                    DNS.aparc.DKT.vol.data_filtered,
## DESTRIEUX ATLAS
                                    DNS.aparc.Destrieux.cort.thick.data_filtered,
                                    DNS.aparc.Destrieux.surf.area.data_filtered, 
                                    DNS.aparc.Destrieux.vol.data_filtered,
)

# Remove individual dfs to clear up environment and avoid confusion/mistakes
rm(DNS.aseg.vol.data_filtered, DNS.aparc.DK.cort.thick.data_filtered,
   DNS.aparc.DK.surf.area.data_filtered, 
   DNS.aparc.DK.vol.data_filtered,
   DNS.aparc.DKT.cort.thick.data_filtered,
   DNS.aparc.DKT.surf.area.data_filtered, 
   DNS.aparc.DKT.vol.data_filtered,
   DNS.aparc.Destrieux.cort.thick.data_filtered,
   DNS.aparc.Destrieux.surf.area.data_filtered, 
   DNS.aparc.Destrieux.vol.data_filtered)

# Add phenotype to column names so columns of thickness, surface area, + volume cortical data can be combined
# (currently, each df in list has the same column names - the cortical ROIs)
## Desikan-Killiany Atlas (i.e., DK data) - includes aseg data too
names(DNS.MRI.data_filtered.for.ML$DNS.aparc.DK.vol.data_filtered)[-c(1,70:74)] <-
  paste0(names(DNS.MRI.data_filtered.for.ML$DNS.aparc.DK.vol.data_filtered)[-c(1,70:74)], "_vol")
names(DNS.MRI.data_filtered.for.ML$DNS.aparc.DK.cort.thick.data_filtered)[-c(1,70:74)] <-
  paste0(names(DNS.MRI.data_filtered.for.ML$DNS.aparc.DK.cort.thick.data_filtered)[-c(1,70:74)], "_thick") 
names(DNS.MRI.data_filtered.for.ML$DNS.aparc.DK.surf.area.data_filtered)[-c(1,70:74)] <-
  paste0(names(DNS.MRI.data_filtered.for.ML$DNS.aparc.DK.surf.area.data_filtered)[-c(1,70:74)], "_area")
## Desikan-Killiany-Tourville Atlas (i.e., DKT data) - includes aseg data too
names(DNS.MRI.data_filtered.for.ML$DNS.aparc.DKT.vol.data_filtered)[-c(1,64:68)] <-
  paste0(names(DNS.MRI.data_filtered.for.ML$DNS.aparc.DKT.vol.data_filtered)[-c(1,64:68)], "_vol")
names(DNS.MRI.data_filtered.for.ML$DNS.aparc.DKT.cort.thick.data_filtered)[-c(1,64:68)] <-
  paste0(names(DNS.MRI.data_filtered.for.ML$DNS.aparc.DKT.cort.thick.data_filtered)[-c(1,64:68)], "_thick") 
names(DNS.MRI.data_filtered.for.ML$DNS.aparc.DKT.surf.area.data_filtered)[-c(1,64:68)] <-
  paste0(names(DNS.MRI.data_filtered.for.ML$DNS.aparc.DKT.surf.area.data_filtered)[-c(1,64:68)], "_area")
## Destrieux Atlas - includes aseg data too 
names(DNS.MRI.data_filtered.for.ML$DNS.aparc.Destrieux.vol.data_filtered)[-c(1,150:154)] <-
  paste0(names(DNS.MRI.data_filtered.for.ML$DNS.aparc.Destrieux.vol.data_filtered)[-c(1,150:154)], "_vol")
names(DNS.MRI.data_filtered.for.ML$DNS.aparc.Destrieux.cort.thick.data_filtered)[-c(1,150:154)] <-
  paste0(names(DNS.MRI.data_filtered.for.ML$DNS.aparc.Destrieux.cort.thick.data_filtered)[-c(1,150:154)], "_thick") 
names(DNS.MRI.data_filtered.for.ML$DNS.aparc.Destrieux.surf.area.data_filtered)[-c(1,150:154)] <-
  paste0(names(DNS.MRI.data_filtered.for.ML$DNS.aparc.Destrieux.surf.area.data_filtered)[-c(1,150:154)], "_area")


# Add predicted FFOCI scores to neuroimaging dataframes
## residualized
DNS.MRI.data_filtered.for.ML <- lapply(DNS.MRI.data_filtered.for.ML, function(df){
  left_join(df, predicted.FFOCI.DNS, by = "ID")})
## NOT residualized
DNS.MRI.data_filtered.for.ML <- lapply(DNS.MRI.data_filtered.for.ML, function(df){
  left_join(df, predicted.FFOCI.notRES.DNS, by = "ID")})

# Remove subject (DNS0047) who doesn't have predicted FFOCI score (b/c don't have NEO data)
DNS.MRI.data_filtered.for.ML <- lapply(DNS.MRI.data_filtered.for.ML, function(df){
  filter(df, ID != "DNS0047")})

# Add demographic variables to neuroimaging dfs for subsequent residualizing
DNS.MRI.data_filtered.for.ML <- lapply(DNS.MRI.data_filtered.for.ML, function(df){
  df <- left_join(df, DNS.demo.data, by = "ID")})

# Split data into training and test subsets 
set.seed(64)
## Randomly sample 70% of data into training dataset and remaining 30% into testing dataset
### NOTE: samples subjects into train vs. test trying to keep similar distributions of FFOCI scores
MRITrainingIndex <- createDataPartition(DNS.MRI.data_filtered.for.ML$DNS.aseg.vol.data_filtered$FFOCISF.pred.res, p=0.7) # doesn't matter which MRI df used - all have same FFOCI scores for each subj.
DNS.MRI.training.data <- Map(function(x, y) x[y, ], DNS.MRI.data_filtered.for.ML, MRITrainingIndex) 
DNS.MRI.test.data <- Map(function(x, y) x[-y, ], DNS.MRI.data_filtered.for.ML, MRITrainingIndex) 

# Save info on which subjs in training and test data to file
max_length <- length(unlist(MRITrainingIndex))

MRI.data.split.info <- data.frame(
    MRI.train.row = unlist(MRITrainingIndex),
    MRI.train.ID = c(DNS.MRI.training.data[[c(1, 1)]], 
                     rep(NA, max_length - length(DNS.MRI.training.data[[c(1, 1)]]))),
    MRI.test.row = c(rep("Don't.know", length(DNS.MRI.test.data[[c(1, 1)]])), 
                     rep(NA, (max_length - length(DNS.MRI.test.data[[c(1, 1)]])))),
    MRI.test.ID = c(DNS.MRI.test.data[[c(1, 1)]], 
                    rep(NA, max_length - length(DNS.MRI.test.data[[c(1,1)]]))))

#write.csv(MRI.data.split.info, "../Results/DNS.MRI.data.split.info.csv")

## OPTIONAL: histogram of predicted FFOCI scores for training and testing data
# training data
ggplot(DNS.MRI.training.data$DNS.aparc.DK.surf.area.data_filtered, aes(FFOCISF.pred.res)) +
  geom_histogram(aes(y= ..density..), bins=30, fill="lightgray", col="black") + 
  stat_function(fun = dnorm, args = list(mean=mean(DNS.MRI.training.data$DNS.aparc.DK.surf.area.data_filtered$FFOCISF.pred.res), 
                                         sd=sd(DNS.MRI.training.data$DNS.aparc.DK.surf.area.data_filtered$FFOCISF.pred.res)), col='red') +
  ggtitle("DNS Training Data\nInput Predicted FFOCI Residualized") + theme(plot.title=element_text(hjust=0.5, face="bold"))
# test data
ggplot(DNS.MRI.test.data$DNS.aparc.DK.surf.area.data_filtered, aes(FFOCISF.pred.res)) +
  geom_histogram(aes(y= ..density..), bins=30, fill="lightgray", col="black") + 
  stat_function(fun = dnorm, args = list(mean=mean(DNS.MRI.test.data$DNS.aparc.DK.surf.area.data_filtered$FFOCISF.pred.res), 
                                         sd=sd(DNS.MRI.test.data$DNS.aparc.DK.surf.area.data_filtered$FFOCISF.pred.res)), col='red') +
  ggtitle("DNS Testing Data\nInput Predicted FFOCI Residualized") + theme(plot.title=element_text(hjust=0.5, face="bold"))


# Residualize neuroimaging data for ML analyses
## Residualize data for gender, age, race, and scanner
### First, remove aseg variables that are all 0 and probably cause problems for lmer 
# FULL DATASET
DNS.MRI.data_filtered.for.ML$DNS.aseg.vol.data_filtered <- 
select(DNS.MRI.data_filtered.for.ML$DNS.aseg.vol.data_filtered, 
      -c("Left.WM.hypointensities", "Right.WM.hypointensities", 
         "Left.non.WM.hypointensities", "Right.non.WM.hypointensities")) 
         # possibly also 5th-ventricle 
# TRAINING DATASET
DNS.MRI.training.data$DNS.aseg.vol.data_filtered <-
  select(DNS.MRI.training.data$DNS.aseg.vol.data_filtered, 
      -c("Left.WM.hypointensities", "Right.WM.hypointensities", 
         "Left.non.WM.hypointensities", "Right.non.WM.hypointensities")) 
         # possibly also 5th-ventricle 
# TESTING DATASET
DNS.MRI.test.data$DNS.aseg.vol.data_filtered <-
  select(DNS.MRI.test.data$DNS.aseg.vol.data_filtered, 
      -c("Left.WM.hypointensities", "Right.WM.hypointensities", 
         "Left.non.WM.hypointensities", "Right.non.WM.hypointensities")) 
         # possibly also 5th-ventricle 

### Second, define residualizing function
#### NOT INCLUDING GLOBAL BRAIN STRUCTURE
residualize.DNS.neuro <- function(df){
    X <- df[c("GENDER.factor", "AGE", "RACE", "Scanner")] # covariates 
    Y <- select(df, -c("ID","FFOCISF.pred.res", "FFOCISF.pred", "GENDER","AGE","RACE","LATINO", # neuroimaging variables
                       "LANGUAGE", "GENDER.factor", "Scanner"))  
    #list_models <- lapply(Y, function(Y) with(X, lmer(Y ~ GENDER.factor + AGE + RACE + (1 | Scanner), 
    #                                          na.action="na.exclude", control = cl_d))) # Run all models (singularity warnings when use lmer())
    list_models <- lapply(Y, function(Y) with(X, lme(Y ~ GENDER.factor + AGE + RACE, 
                                        random = ~1 | Scanner, na.action="na.exclude"))) # Run all models
    list_resid <- lapply(list_models, resid) # List residuals from all models
    df_resid <- do.call(cbind.data.frame, list_resid) # Put residuals in a dataframe
    colnames(df_resid) <- paste(colnames(df_resid), "res", sep = ".") # Add ".res" to variable names
    df <- cbind(df, df_resid) # Add residualized variables to df
    return(df) # Make function return the dataframe
}
#### INCLUDING ICV (FOR VOLUME AND SURFACE AREA ANALYSES)
residualize.DNS.neuro.w.ICV <- function(df){
    X <- df[c("GENDER.factor", "AGE", "RACE", "Scanner", "eTIV")] # covariates 
    Y <- select(df, -c("ID","FFOCISF.pred.res", "FFOCISF.pred", "GENDER","AGE","RACE","LATINO", # neuroimaging variables
                       "LANGUAGE", "GENDER.factor", "Scanner"))  
    #list_models <- lapply(Y, function(Y) with(X, lmer(Y ~ GENDER.factor + AGE + RACE + eTIV + (1 | Scanner), 
    #                                          na.action="na.exclude", control = cl_d))) # Run all models (singularity warnings when use lmer())
    list_models <- lapply(Y, function(Y) with(X, lme(Y ~ GENDER.factor + AGE + RACE + eTIV, 
                                        random = ~1 | Scanner, na.action="na.exclude"))) # Run all models
    list_resid <- lapply(list_models, resid) # List residuals from all models
    df_resid <- do.call(cbind.data.frame, list_resid) # Put residuals in a dataframe
    colnames(df_resid) <- paste(colnames(df_resid), "res", sep = ".") # Add ".res" to variable names
    df <- cbind(df, df_resid) # Add residualized variables to df
    return(df) # Make function return the dataframe
}
#### INCLUDING AVG. CORTICAL THICKNESS (FOR THICKNESS ANALYSES)
residualize.DNS.neuro.w.avg.thick <- function(df){
    X <- df[c("GENDER.factor", "AGE", "RACE", "Scanner", "MeanThick")] # covariates 
    Y <- select(df, -c("ID","FFOCISF.pred.res", "FFOCISF.pred", "GENDER","AGE","RACE","LATINO",# neuroimaging variables
                       "LANGUAGE", "GENDER.factor", "Scanner"))  
    #list_models <- lapply(Y, function(Y) with(X, lmer(Y ~ GENDER.factor + AGE + RACE + MeanThick + (1 | Scanner), 
    #                                          na.action="na.exclude", control = cl_d))) # Run all models (singularity warnings when use lmer())
    list_models <- lapply(Y, function(Y) with(X, lme(Y ~ GENDER.factor + AGE + RACE + MeanThick, 
                                        random = ~1 | Scanner, na.action="na.exclude"))) # Run all models
    list_resid <- lapply(list_models, resid) # List residuals from all models
    df_resid <- do.call(cbind.data.frame, list_resid) # Put residuals in a dataframe
    colnames(df_resid) <- paste(colnames(df_resid), "res", sep = ".") # Add ".res" to variable names
    df <- cbind(df, df_resid) # Add residualized variables to df
    return(df) # Make function return the dataframe
}

### Third, apply residualizing function to the MRI data 
#### Data not split into training and testing datasets, to run like standard regression 
DNS.MRI.data_filtered.for.ML.ICV.res <- lapply(DNS.MRI.data_filtered.for.ML[c(1,3,4,6,7)], 
                                               residualize.DNS.neuro.w.ICV)
DNS.MRI.data_filtered.for.ML.avgthick.res <- lapply(DNS.MRI.data_filtered.for.ML[c(2,5)], 
                                                    residualize.DNS.neuro.w.avg.thick)
DNS.MRI.data_filtered.for.ML <- c(DNS.MRI.data_filtered.for.ML.ICV.res, 
                                  DNS.MRI.data_filtered.for.ML.avgthick.res)
rm(DNS.MRI.data_filtered.for.ML.ICV.res, DNS.MRI.data_filtered.for.ML.avgthick.res)

#### Data split into training and testing datasets - residualize separately
# Training
DNS.MRI.training.data_ICV.res <- lapply(DNS.MRI.training.data[c(1,3,4,6,7)], 
                                       residualize.DNS.neuro.w.ICV)
DNS.MRI.training.data_avgthick.res <- lapply(DNS.MRI.training.data[c(2,5)], 
                                       residualize.DNS.neuro.w.avg.thick)
DNS.MRI.training.data <- c(DNS.MRI.training.data_ICV.res, 
                           DNS.MRI.training.data_avgthick.res)
rm(DNS.MRI.training.data_ICV.res, DNS.MRI.training.data_avgthick.res)

# Testing
DNS.MRI.test.data_ICV.res <- lapply(DNS.MRI.test.data[c(1,3,4,6,7)], 
                                       residualize.DNS.neuro.w.ICV)
DNS.MRI.test.data_avgthick.res <- lapply(DNS.MRI.test.data[c(2,5)], 
                                       residualize.DNS.neuro.w.avg.thick)
DNS.MRI.test.data <- c(DNS.MRI.test.data_ICV.res, 
                       DNS.MRI.test.data_avgthick.res)
rm(DNS.MRI.test.data_ICV.res, DNS.MRI.test.data_avgthick.res)

#### when rerunning these to get neuroticism + conscientiousness post-hoc testing results, FFOCISF.pred.res was duplicated and causing problems.
#### second instance of the variable was incorrect. remove it
# column 155 for aparc DK data, 143 for DKT data, 135 for aseg 
DNS.MRI.data_filtered.for.ML_TEST <- lapply(DNS.MRI.data_filtered.for.ML[c(1)], #aseg
                                            function(x) x[ ,-135]) #col 135 has duplicated FFOCISF.pred.res
DNS.MRI.data_filtered.for.ML_DKT.TEST <- lapply(DNS.MRI.data_filtered.for.ML[c(4,5,7)], #dkt dfs
                                            function(x) x[ ,-143])
DNS.MRI.data_filtered.for.ML_DK.TEST <- lapply(DNS.MRI.data_filtered.for.ML[c(2,3,6)], #dk dfs
                                            function(x) x[ ,-155])
DNS.MRI.data_filtered.for.ML <- c(DNS.MRI.data_filtered.for.ML_TEST, DNS.MRI.data_filtered.for.ML_DKT.TEST, DNS.MRI.data_filtered.for.ML_DK.TEST) 

## training data
DNS.MRI.training.data_TEST <- lapply(DNS.MRI.training.data[c(1)], #aseg
                                            function(x) x[ ,-135]) #col 135 has duplicated FFOCISF.pred.res
DNS.MRI.training.data_DKT.TEST <- lapply(DNS.MRI.training.data[c(4,5,7)], #dkt dfs
                                            function(x) x[ ,-143])
DNS.MRI.training.data_DK.TEST <- lapply(DNS.MRI.training.data[c(2,3,6)], #dk dfs
                                            function(x) x[ ,-155])
DNS.MRI.training.data <- c(DNS.MRI.training.data_TEST, DNS.MRI.training.data_DKT.TEST, DNS.MRI.training.data_DK.TEST) 

## testing data
DNS.MRI.test.data_TEST <- lapply(DNS.MRI.test.data[c(1)], #aseg
                                            function(x) x[ ,-135]) #col 135 has duplicated FFOCISF.pred.res
DNS.MRI.test.data_DKT.TEST <- lapply(DNS.MRI.test.data[c(4,5,7)], #dkt dfs
                                            function(x) x[ ,-143])
DNS.MRI.test.data_DK.TEST <- lapply(DNS.MRI.test.data[c(2,3,6)], #dk dfs
                                            function(x) x[ ,-155])
DNS.MRI.test.data <- c(DNS.MRI.test.data_TEST, DNS.MRI.test.data_DKT.TEST, DNS.MRI.test.data_DK.TEST) 

# Add dataframes to list that have all DK or DKT aparc data + aseg data 
# (to run models w/ all data simultaneously)
## Create the dataframes
### FULL DATASET
DNS.aseg.and.DKT.aparc.data <- Reduce(function(...) left_join(..., by=c('ID', 'Scanner', 'eTIV', "FFOCISF.pred.res", "FFOCISF.pred", "GENDER", "AGE","RACE","LATINO","LANGUAGE","GENDER.factor")), list(DNS.MRI.data_filtered.for.ML$DNS.aseg.vol.data_filtered, DNS.MRI.data_filtered.for.ML$DNS.aparc.DKT.cort.thick.data_filtered, DNS.MRI.data_filtered.for.ML$DNS.aparc.DKT.surf.area.data_filtered, DNS.MRI.data_filtered.for.ML$DNS.aparc.DKT.vol.data_filtered)) %>%
  select(-c("MeanThick.x", "MeanThick.y", "lhMeanThickness.x", "lhMeanThickness.y", 
            "rhMeanThickness.x", "rhMeanThickness.y"))
DNS.aseg.and.DK.aparc.data <- Reduce(function(...) left_join(..., by=c('ID', 'Scanner', 'eTIV',
"FFOCISF.pred.res", "FFOCISF.pred", "GENDER", "AGE","RACE","LATINO","LANGUAGE","GENDER.factor")), list(DNS.MRI.data_filtered.for.ML$DNS.aseg.vol.data_filtered, DNS.MRI.data_filtered.for.ML$DNS.aparc.DK.cort.thick.data_filtered, DNS.MRI.data_filtered.for.ML$DNS.aparc.DK.surf.area.data_filtered, DNS.MRI.data_filtered.for.ML$DNS.aparc.DK.vol.data_filtered)) %>%
  select(-c("MeanThick.x", "MeanThick.y", "lhMeanThickness.x", "lhMeanThickness.y", 
            "rhMeanThickness.x", "rhMeanThickness.y"))
DNS.aseg.and.Destrieux.aparc.data <- Reduce(function(...) left_join(..., by=c('ID', 'Scanner', 'eTIV',
"FFOCISF.pred.res", "FFOCISF.pred", "GENDER", "AGE","RACE","LATINO","LANGUAGE","GENDER.factor")), list(DNS.MRI.data_filtered.for.ML$DNS.aseg.vol.data_filtered, DNS.MRI.data_filtered.for.ML$DNS.aparc.Destrieux.cort.thick.data_filtered, DNS.MRI.data_filtered.for.ML$DNS.aparc.Destrieux.surf.area.data_filtered, DNS.MRI.data_filtered.for.ML$DNS.aparc.Destrieux.vol.data_filtered)) %>%
  select(-c("MeanThick.x", "MeanThick.y", "lhMeanThickness.x", "lhMeanThickness.y", 
            "rhMeanThickness.x", "rhMeanThickness.y"))

### TRAINING DATASET
DNS.training.aseg.and.DKT.aparc.data <- Reduce(function(...) left_join(..., by=c('ID', 'Scanner', 'eTIV', "FFOCISF.pred.res", "FFOCISF.pred", "GENDER", "AGE","RACE","LATINO","LANGUAGE","GENDER.factor")), list(DNS.MRI.training.data$DNS.aseg.vol.data_filtered, DNS.MRI.training.data$DNS.aparc.DKT.cort.thick.data_filtered, DNS.MRI.training.data$DNS.aparc.DKT.surf.area.data_filtered, DNS.MRI.training.data$DNS.aparc.DKT.vol.data_filtered)) %>%
  select(-c("MeanThick.x", "MeanThick.y", "lhMeanThickness.x", "lhMeanThickness.y", 
            "rhMeanThickness.x", "rhMeanThickness.y"))
DNS.training.aseg.and.DK.aparc.data <- Reduce(function(...) left_join(..., by=c('ID', 'Scanner', 'eTIV',
"FFOCISF.pred.res", "FFOCISF.pred", "GENDER", "AGE","RACE","LATINO","LANGUAGE","GENDER.factor")), list(DNS.MRI.training.data$DNS.aseg.vol.data_filtered, DNS.MRI.training.data$DNS.aparc.DK.cort.thick.data_filtered, DNS.MRI.training.data$DNS.aparc.DK.surf.area.data_filtered, DNS.MRI.training.data$DNS.aparc.DK.vol.data_filtered)) %>%
  select(-c("MeanThick.x", "MeanThick.y", "lhMeanThickness.x", "lhMeanThickness.y", 
            "rhMeanThickness.x", "rhMeanThickness.y"))
### TESTING DATASET
DNS.test.aseg.and.DKT.aparc.data <- Reduce(function(...) left_join(..., by=c('ID', 'Scanner', 'eTIV', "FFOCISF.pred.res", "FFOCISF.pred", "GENDER", "AGE","RACE","LATINO","LANGUAGE","GENDER.factor")), list(DNS.MRI.test.data$DNS.aseg.vol.data_filtered, DNS.MRI.test.data$DNS.aparc.DKT.cort.thick.data_filtered, DNS.MRI.test.data$DNS.aparc.DKT.surf.area.data_filtered, DNS.MRI.test.data$DNS.aparc.DKT.vol.data_filtered)) %>%
  select(-c("MeanThick.x", "MeanThick.y", "lhMeanThickness.x", "lhMeanThickness.y", 
            "rhMeanThickness.x", "rhMeanThickness.y"))
DNS.test.aseg.and.DK.aparc.data <- Reduce(function(...) left_join(..., by=c('ID', 'Scanner', 'eTIV',
"FFOCISF.pred.res", "FFOCISF.pred", "GENDER", "AGE","RACE","LATINO","LANGUAGE","GENDER.factor")), list(DNS.MRI.test.data$DNS.aseg.vol.data_filtered, DNS.MRI.test.data$DNS.aparc.DK.cort.thick.data_filtered, DNS.MRI.test.data$DNS.aparc.DK.surf.area.data_filtered, DNS.MRI.test.data$DNS.aparc.DK.vol.data_filtered)) %>%
  select(-c("MeanThick.x", "MeanThick.y", "lhMeanThickness.x", "lhMeanThickness.y", 
            "rhMeanThickness.x", "rhMeanThickness.y"))

## Add them to the existing lists
DNS.MRI.data_filtered.for.ML <- c(DNS.MRI.data_filtered.for.ML, 
        lst(DNS.aseg.and.DKT.aparc.data, DNS.aseg.and.DK.aparc.data, DNS.aseg.and.Destrieux.aparc.data))
DNS.MRI.training.data <- c(DNS.MRI.training.data, 
        lst(DNS.training.aseg.and.DKT.aparc.data, DNS.training.aseg.and.DK.aparc.data))
DNS.MRI.test.data <- c(DNS.MRI.test.data, 
        lst(DNS.test.aseg.and.DKT.aparc.data, DNS.test.aseg.and.DK.aparc.data))

# Center + scale neuroimaging data so consistent with ML analyses?
DNS.MRI.data_filtered.and.scaled.for.ML <- lapply(DNS.MRI.data_filtered.for.ML, function(df) 
  df %>% mutate(across(-c("ID","FFOCISF.pred.res", "FFOCISF.pred", "GENDER","AGE","RACE","LATINO",
                          "LANGUAGE","GENDER.factor", "Scanner"),
            #   ~ as.vector(scale(df))))) # return as vector instead of matrix
                scale))) #by default, centers and scales (divides by sd)
# this returns matrices named V1. when try to return as vector instead, has problem w/ 
# x not being numeric for colMeans()

## FOR DATA BEING USED IN ML ANALYSES (I.E., DNS.MRI.training.data and DNS.MRI.test.data)
## let caret do the centering and scaling below when run models

#### Additional pre-processing for ML MRI analyses ####

# Check data for nero zero variance predictors, which may want to remove
sapply(DNS.MRI.data_filtered.for.ML, function(x) (nearZeroVar(x, names = TRUE)))
## Outcome: 5th ventricle had near zero variance but not using in analyses. no others

# Check for highly correlated predictor variables (r>0.75)
MRI.correlations <- lapply(DNS.MRI.data_filtered.for.ML, function(x)
                           cor(select(x,-c("ID", "Scanner", "GENDER","AGE","RACE","LATINO",
                          "LANGUAGE","GENDER.factor", ends_with(".res"))), 
                          use = "pairwise.complete.obs"))
# corrplot(MRI.correlations, type = "lower", method = "color")
lapply(MRI.correlations, function(x) (findCorrelation(x, cutoff = 0.75)))
## Outcome: left and right hemispheres are highly correlated, as expected

# Check for missing data
sapply(DNS.MRI.data_filtered.for.ML, function(x) table(colSums(is.na(x))>0))
## Outcome: only language missing data and not using that variable
```

**Prepare data for posthoc tests - Brain structure predicting NEO neuroticism + conscientiousness**
```{r}
sapply(DNS.MRI.data_filtered.for.ML, function(x) table(complete.cases(select(x, starts_with("neo")))))
sapply(DNS.MRI.data_filtered.for.ML, function(x) table(colSums(is.na(select(x, contains("NEON", ignore.case = FALSE))))))

colSums(is.na(select(DNS.MRI.data_filtered.for.ML$DNS.aseg.vol.data_filtered, contains("NEON", ignore.case = FALSE))))
colSums(is.na(select(DNS.MRI.data_filtered.for.ML$DNS.aseg.vol.data_filtered, contains("NEON", ignore.case = FALSE))))


# First, use Section 10 from ML.script.R to process DNS NEO data
# DNS.NEO.raw.data_not.NAs <- calc.facet.means(DNS.NEO.raw.data_not.NAs)
# DNS.NEO.raw.data_not.NAs <- impute.w.NEO.facet.means(DNS.NEO.raw.data_not.NAs)
# DNS.NEO.raw.data_not.NAs <- calc.facet.totals(DNS.NEO.raw.data_not.NAs)

# Second, update summary scores based on imputed raw data and add those to dataframes 
### NOTE - 2/15/23 - pretty sure this is redundant and unnecessary. calc.facet.totals also recalculated domain totals.
#updated.domain.totals <- function(df) {
#    df$NEOA.imputed <- df %>% select(matches("NEOA\\d\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
#    df$NEOE.imputed <- df %>% select(matches("NEOE\\d\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
#    df$NEOC.imputed <- df %>% select(matches("NEOC\\d\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
#    df$NEOO.imputed <- df %>% select(matches("NEOO\\d\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
#    df$NEON.imputed <- df %>% select(matches("NEON\\d\\d$")) %>% rowSums(., na.rm = TRUE) %>% round(., 2)
#    return(df)
#  }
#DNS.NEO.raw.data_not.NAs.NEO.imputed <- updated.domain.totals(DNS.NEO.raw.data_not.NAs)

##### NOTE IF USING NEO ITEMS RESIDUALIZED W/ NEUROIMAGING DATA, NEED TO FIX SO DELETE NEOXX.RES ITEMS WHICH WERE GENERATED FOR N=1360 IN AIM 1,
##### NOT THE CURRENT DATASAMPLE. DATA LEAKAGE. DOMAIN TOTALS IMPUTED ARE FINE B/C THEY WEREN'T RESIDUALIZED IN AIM 1

DNS.MRI.data_filtered.for.ML_w.NEO <- lapply(DNS.MRI.data_filtered.for.ML, function(df){
  df <- left_join(df, DNS.NEO.raw.data_not.NAs.NEO.imputed, by = "ID", suffix=c("", ".y")) %>%
    select(-ends_with(".y"))})

DNS.MRI.training.data <- lapply(DNS.MRI.training.data, function(df){
  df <- left_join(df, DNS.NEO.raw.data_not.NAs.NEO.imputed, by = "ID", suffix=c("", ".y")) %>%
    select(-ends_with(".y"))})
DNS.MRI.test.data <- lapply(DNS.MRI.test.data, function(df){
  df <- left_join(df, DNS.NEO.raw.data_not.NAs.NEO.imputed, by = "ID", suffix=c("", ".y")) %>%
    select(-ends_with(".y"))})

# Finally, residualize for neuroimaging analyses

## only need to residualize neuroticism + conscientiousness for age and gender. neuroimaging data already residualized. 
residualize.NEO.domains.DNS <- function(df){
    X <- df[c("GENDER.factor", "AGE")] # covariates #AGE.x for DNS.MRI.data_filtered.for.ML
    #Y <- select(df, matches("^NEO[A-Z]")) # NEO items + summary scores (included updated sums)
    Y <- select(df, ends_with("_imputed"))
    list_models <- lapply(Y, function(Y) with(X, lm(Y ~ GENDER.factor + AGE, #AGE.x for DNS.MRI.data_filtered.for.ML
                                                    na.action = "na.exclude"))) # Run all models
    list_resid <- lapply(list_models, resid) # List residuals from all models
    df_resid <- do.call(cbind.data.frame, list_resid) # Put residuals in dataframe
    colnames(df_resid) <- paste(colnames(df_resid), "res", sep = ".") # Add ".res" to variable names
    df <- cbind(df, df_resid) # Add residualized variables to df
    return(df) # Make function return the dataframe
}
DNS.MRI.data_filtered.for.ML <- lapply(DNS.MRI.data_filtered.for.ML, residualize.NEO.domains.DNS)

DNS.MRI.training.data <- lapply(DNS.MRI.training.data, residualize.NEO.domains.DNS)
DNS.MRI.test.data <- lapply(DNS.MRI.test.data, residualize.NEO.domains.DNS)
```


## Run analyses
### Specify ROIs

**Hypothesized ROIs:**
Prefrontal cortex
Insula
Posterior cingulate cortex
Precuneus
Caudate
Ventral Striatum

```{r}
DVs <- "FFOCISF.pred.res" 
# A priori ROIs
## Cortical regions
### Desikan-Killiany atlas
cortical.IVs.DK <- c("caudalanteriorcingulate_left", "rostralanteriorcingulate_left",      
    "lateralorbitofrontal_left", "medialorbitofrontal_left", 
    "parsopercularis_left", "parsorbitalis_left", "parstriangularis_left", # inferior frontal
    "caudalmiddlefrontal_left",  "rostralmiddlefrontal_left",  
    "superiorfrontal_left", "frontalpole_left", # frontal pole not in DKT atlas
    "posteriorcingulate_left", "precuneus_left", "insula_left",          
    "caudalanteriorcingulate_right",  "rostralanteriorcingulate_right", 
    "lateralorbitofrontal_right", "medialorbitofrontal_right",        
    "parsopercularis_right", "parsorbitalis_right", "parstriangularis_right",# inferior frontal
    "rostralmiddlefrontal_right", "caudalmiddlefrontal_right",    
    "superiorfrontal_right", "frontalpole_right", # frontal pole not in DKT atlas
    "posteriorcingulate_right", "precuneus_right", "insula_right")
cortical.IVs.DK.res <- paste0(cortical.IVs.DK, ".res")
### Desikan-Killiany-Tourville atlas (doesn't have frontal pole)
cortical.IVs.DKT <- cortical.IVs.DK[! cortical.IVs.DK %in% c("frontalpole_left", "frontalpole_right")]
cortical.IVs.DKT.res <- cortical.IVs.DK.res[! cortical.IVs.DK.res %in% 
                                              c("frontalpole_left.res", "frontalpole_right.res")]

## Subcortical regions
subcortical.IVs <- c("Left.Caudate", "Right.Caudate", 
                     "Left.Accumbens.area", "Right.Accumbens.area")
subcortical.IVs.res <- paste0(subcortical.IVs, ".res")

# Exploratory ROIs
## Cortical regions
# all included regions in cortical atlases, so don't need to specify

## Subcortical regions (not looking at ventricles, vessels, holes, hypointensities, CSF, choroid plexus, optic chiasm, supratentorial vol, brain seg vol, brainstem, eTIV (covariate))
exploratory.subcortical.IVs <- c("Left.Cerebellum.White.Matter" , "Left.Cerebellum.Cortex",            "Left.Thalamus.Proper",             
 "Left.Caudate"                 , "Left.Putamen",                      "Left.Pallidum",                    
 "Left.Hippocampus"             , "Left.Amygdala",                     "Left.Accumbens.area",                  
 "Left.VentralDC",      
 "Right.Cerebellum.White.Matter", "Right.Cerebellum.Cortex",           "Right.Thalamus.Proper",            
 "Right.Caudate"                , "Right.Putamen",                     "Right.Pallidum",                   
 "Right.Hippocampus"            , "Right.Amygdala",                    "Right.Accumbens.area",             
 "Right.VentralDC",               #"Brain.Stem",                 
 "CC_Posterior"                 , "CC_Mid_Posterior",                 
 "CC_Central"                   , "CC_Mid_Anterior",                   "CC_Anterior",                      
# "BrainSegVol"                 ,  "BrainSegVolNotVent",                "BrainSegVolNotVentSurf",           
 "lhCortexVol"                  , "rhCortexVol",                       "CortexVol",                        
 "lhCerebralWhiteMatterVol"     , "rhCerebralWhiteMatterVol",          "CerebralWhiteMatterVol",           
 "SubCortGrayVol"               , "TotalGrayVol")                      #"SupraTentorialVol",                
# "SupraTentorialVolNotVent"          "SupraTentorialVolNotVentVox"       "MaskVol"                          
# "BrainSegVol.to.eTIV"               "MaskVol.to.eTIV"                   "lhSurfaceHoles"                   
# "rhSurfaceHoles"                    "SurfaceHoles"                      "eTIV"       
exploratory.subcortical.IVs.res <- paste0(exploratory.subcortical.IVs, ".res")
```

### MatSpD
A priori Analyses
```{r apriori-correlation-matrices eval=FALSE}
# Create correlation matrix of all a priori neural ROI measures 
# (subcortical volume, cortical thickness, and surface area) to be used in 
# "matrix spectral decomposition" correction for multiple testing

### Extract data for the a priori ROIs
apriori.cortical.ROI.data <- lapply(DNS.MRI.data_filtered.and.scaled.for.ML, function(df){ 
                  select(df, setdiff(starts_with(c(cortical.IVs)), ends_with(".res")))})
apriori.cortical.ROI.data <- as.data.frame(do.call(cbind, apriori.cortical.ROI.data)) %>%
  select(-starts_with(c("DNS.aparc.DKT.vol.data", "DNS.aparc.DK.vol.data")))
apriori.subcortical.ROI.data <- lapply(DNS.MRI.data_filtered.and.scaled.for.ML, function(df){
                  select(df, setdiff(starts_with(c(subcortical.IVs)), ends_with(".res")))})  
apriori.subcortical.ROI.data <- as.data.frame(do.call(cbind, apriori.subcortical.ROI.data))

### Combine into single dataframe for each atlas 
apriori.DK.ROI.data <- bind_cols(apriori.cortical.ROI.data, apriori.subcortical.ROI.data) %>%
                       select(starts_with("DNS.aparc.DK.") | starts_with("DNS.aseg."))
apriori.DKT.ROI.data <- bind_cols(apriori.cortical.ROI.data, apriori.subcortical.ROI.data) %>%
                       select(starts_with("DNS.aparc.DKT.") | starts_with("DNS.aseg."))

## Generate correlation matrix
apriori.DK.ROI.corr.matrix <- data.frame(cor(apriori.DK.ROI.data, 
                                               use = "pairwise.complete.obs"))
apriori.DKT.ROI.corr.matrix <- data.frame(cor(apriori.DKT.ROI.data, 
                                              use = "pairwise.complete.obs"))
write.table(apriori.DK.ROI.corr.matrix, file = "../Results/apriori.DNS.DK.MRI.correlation.matrix_N=1253", 
            row.names = FALSE, col.names = FALSE)
write.table(apriori.DKT.ROI.corr.matrix, file = "../Results/apriori.DNS.DKT.MRI.correlation.matrix_N=1253", 
            row.names = FALSE, col.names = FALSE)

# "corr.matrix" is the input file for the MatSpD.R script 
source("matSpDlite.R")
```
Exploratory Analyses
```{r}
## Extract data for all ROIs
exploratory.cortical.ROI.data <- lapply(DNS.MRI.data_filtered.and.scaled.for.ML, function(df){ 
                  select(df, union(matches("*_area$"), matches("*_thick$")))})
exploratory.cortical.ROI.data <- as.data.frame(do.call(cbind, exploratory.cortical.ROI.data)) %>%
  select(-starts_with(c("DNS.aparc.DKT.vol.data", "DNS.aparc.DK.vol.data", "DNS.aparc.Destrieux.vol.data")))
exploratory.subcortical.ROI.data <- lapply(DNS.MRI.data_filtered.and.scaled.for.ML, function(df){
                  select(df, setdiff(starts_with(c(exploratory.subcortical.IVs)), ends_with(".res")))})  
exploratory.subcortical.ROI.data <- as.data.frame(do.call(cbind, exploratory.subcortical.ROI.data))

## Combine into single dataframe for each atlas 
exploratory.DK.ROI.data <- bind_cols(exploratory.cortical.ROI.data, exploratory.subcortical.ROI.data) %>%
                       select(starts_with("DNS.aparc.DK.") | starts_with("DNS.aseg."))
exploratory.DKT.ROI.data <- bind_cols(exploratory.cortical.ROI.data, exploratory.subcortical.ROI.data) %>%
                       select(starts_with("DNS.aparc.DKT.") | starts_with("DNS.aseg."))
exploratory.Destrieux.ROI.data <- bind_cols(exploratory.cortical.ROI.data, exploratory.subcortical.ROI.data) %>%
                       select(starts_with("DNS.aparc.Destrieux.") | starts_with("DNS.aseg."))

## Generate correlation matrix
exploratory.DK.ROI.corr.matrix <- data.frame(cor(exploratory.DK.ROI.data, 
                                               use = "pairwise.complete.obs"))
exploratory.DKT.ROI.corr.matrix <- data.frame(cor(exploratory.DKT.ROI.data, 
                                              use = "pairwise.complete.obs"))
exploratory.Destrieux.ROI.corr.matrix <- data.frame(cor(exploratory.Destrieux.ROI.data, 
                                              use = "pairwise.complete.obs"))
write.table(exploratory.DK.ROI.corr.matrix, file = "../Results/exploratory.DNS.DK.MRI.correlation.matrix_N=1253",
            row.names = FALSE, col.names = FALSE)
write.table(exploratory.DKT.ROI.corr.matrix, file = "../Results/exploratory.DNS.DKT.MRI.correlation.matrix_N=1253", 
            row.names = FALSE, col.names = FALSE)
write.table(exploratory.Destrieux.ROI.corr.matrix, file = "../Results/exploratory.DNS.Destrieux.MRI.correlation.matrix_N=1253", 
            row.names = FALSE, col.names = FALSE)
# "corr.matrix" is the input file for the MatSpD.R script 
source("matSpDlite.R")
```

### Linear regression
*A priori ROIs*
```{r}
## Volume 
### not residualized (so need to account for scanner, age, gender, and race)
ML.FFOCI_apriori_vol_models = list()
for (i in DVs){
  for (j in subcortical.IVs){
    ML.FFOCI_apriori_vol_models[[paste("DV", i, "vs", "IV", j, "vol", sep = ".")]] <- 
        lm(as.formula(paste(i, "~", j, " + eTIV + Scanner + GENDER.factor + AGE + RACE")), 
             data = DNS.MRI.data_filtered.and.scaled.for.ML$DNS.aseg.vol.data_filtered)
  }
} 
### residualized (already accounted for scanner, age, gender, and race)
# ML.FFOCI_apriori_res.vol_models = list()
# for (i in DVs){
#   for (j in subcortical.IVs.res){
#     ML.FFOCI_apriori_res.vol_models[[paste("DV", i, "vs", "IV", j, "vol.res", sep = ".")]] <- 
#         lm(as.formula(paste(i, "~", j, " + eTIV.res")), 
#              data = DNS.MRI.data_filtered.and.scaled.for.ML$DNS.aseg.vol.data_filtered)
#   }
# } 

## Surface area
### Not residualized (so need to account for scanner)
ML.FFOCI_apriori_area_models = list()
for (i in DVs){
  for (j in cortical.IVs.DKT){
    ML.FFOCI_apriori_area_models[[paste("DV", i, "vs", "IV", j, "area", sep = ".")]] <- 
        lm(as.formula(paste(i, "~", paste0(j, "_area"), " + eTIV + Scanner  + GENDER.factor + AGE + RACE")), 
             data = DNS.MRI.data_filtered.and.scaled.for.ML$DNS.aparc.DKT.surf.area.data_filtered)
  }
} 
### Residualized (already accounted for scanner, age, gender, and race)
# ML.FFOCI_apriori_res.area_models = list()
# for (i in DVs){
#   for (j in cortical.IVs.DKT.res){
#     ML.FFOCI_apriori_res.area_models[[paste("DV", i, "vs", "IV", j, "area.res", sep = ".")]] <- 
#         lm(as.formula(paste(i, "~", paste0(j, "_area.res"), " + eTIV.res")), 
#              data = DNS.MRI.data_filtered.and.scaled.for.ML$DNS.aparc.DKT.surf.area.data_filtered)
#   }
# } 
## Cortical thickness
### Not residualized (so need to account for scanner)
ML.FFOCI_apriori_thickness_models = list()
for (i in DVs){
  for (j in cortical.IVs.DKT){
    ML.FFOCI_apriori_thickness_models[[paste("DV", i, "vs", "IV", j, "thick", sep = ".")]] <- 
        lm(as.formula(paste(i, "~", paste0(j, "_thick"), " + MeanThick  + Scanner + GENDER.factor + AGE + RACE")), 
             data = DNS.MRI.data_filtered.and.scaled.for.ML$DNS.aparc.DKT.cort.thick.data_filtered)
  }
} 
### Residualized (already accounted for scanner, age, gender, and race)
# ML.FFOCI_apriori_res.thickness_models = list()
# for (i in DVs){
#   for (j in cortical.IVs.DKT.res){
#     ML.FFOCI_apriori_res.thickness_models[[paste("DV", i, "vs", "IV", j, "thick.res", sep = ".")]] <- 
#         lm(as.formula(paste(i, "~", paste0(j, "_thick.res"), " + MeanThick.res")), 
#              data = DNS.MRI.data_filtered.and.scaled.for.ML$DNS.aparc.DKT.cort.thick.data_filtered)
#   }
# } 

# Combine lists for volume, surface area, and thickness regressions
ML.FFOCI_apriori_models <- c(ML.FFOCI_apriori_vol_models, ML.FFOCI_apriori_area_models,
                             ML.FFOCI_apriori_thickness_models) 
#                             ML.FFOCI_apriori_res.vol_models, ML.FFOCI_apriori_res.area_models, 
#                             ML.FFOCI_apriori_res.thickness_models)

# Extract results (if want individual variables for each regression result)
# for (i in names(c(ML.FFOCI_apriori_models, ML.FFOCI_apriori_area_models, 
#                   ))){
#     name <- paste(i)
#     assign(name, c(ML.FFOCI_apriori_models, ML.FFOCI_apriori_area_models, 
#                   )[[i]])
# }

# Create spreadsheet of results
results <- lapply(seq_along(ML.FFOCI_apriori_models), function(i) {
    data.frame(
      analysis = names(ML.FFOCI_apriori_models)[i],
      b = summary(ML.FFOCI_apriori_models[[i]])$coefficients[2,1],
      b_95CI.lower = confint(ML.FFOCI_apriori_models[[i]], 2)[[1]],
      b_95CI.upper = confint(ML.FFOCI_apriori_models[[i]], 2)[[2]],
      std.err = summary(ML.FFOCI_apriori_models[[i]])$coefficients[2,2],
      t = summary(ML.FFOCI_apriori_models[[i]])$coefficients[2,3],
      p = summary(ML.FFOCI_apriori_models[[i]])$coefficients[2,4],
      df = df.residual(ML.FFOCI_apriori_models[[i]]),
      model.n = nobs(ML.FFOCI_apriori_models[[i]]),
      model.rsq = summary(ML.FFOCI_apriori_models[[i]])$adj.r.squared,
      stringsAsFactors = FALSE)
})

## NOTE: for 95% CIs, the fifth row of confint.merMod results is for the first IV in model.
##       all stats printed are for the IV of interest.

ML.FFOCI_apriori_DKT.results <- do.call(rbind, results) %>%
  sort_df("p")

write.csv(ML.FFOCI_apriori_results, "../Results/Regression/DNS.Aim2.regression.apriori.DKT.results.csv",
          row.names = FALSE)

# Delta R-sq for significant findings
summary(lm(FFOCISF.pred.res ~ superiorfrontal_right_thick + MeanThick  + Scanner + GENDER.factor + AGE + RACE, 
   data = DNS.MRI.data_filtered.and.scaled.for.ML$DNS.aparc.DKT.cort.thick.data_filtered))$rsquared

# Switching IV and DV for significant findings to see if it makes a difference
summary(lm(superiorfrontal_right_thick ~ FFOCISF.pred.res + MeanThick  + Scanner + GENDER.factor + AGE + RACE, 
   data = DNS.MRI.data_filtered.and.scaled.for.ML$DNS.aparc.DKT.cort.thick.data_filtered))

summary(lmer(FFOCISF.pred.res ~ superiorfrontal_right_thick + MeanThick + GENDER.factor + AGE + RACE + (1 | Scanner), 
   data = DNS.MRI.data_filtered.and.scaled.for.ML$DNS.aparc.DKT.cort.thick.data_filtered))
```

*Exploratory Analyses*
```{r}
## Volume 
### Not residualized (so need to account for scanner, age, gender, and race)
ML.FFOCI_exploratory_vol_models = list()
for (i in DVs){
  for (j in exploratory.subcortical.IVs){
    ML.FFOCI_exploratory_vol_models[[paste("DV", i, "vs", "IV", j, "vol", sep = ".")]] <- 
        lm(as.formula(paste(i, "~", j, " + eTIV + Scanner + GENDER.factor + AGE + RACE")), 
             data = DNS.MRI.data_filtered.and.scaled.for.ML$DNS.aseg.vol.data_filtered)
  }
} 

## Surface area
### Not residualized (so need to account for scanner, age, gender, and race)
ML.FFOCI_exploratory_area_models = list()
for (i in DVs){
  for (j in names(DNS.MRI.data_filtered.and.scaled.for.ML$DNS.aparc.DKT.surf.area.data_filtered) %>% 
            .[matches("*_area$", vars = .)]){
    ML.FFOCI_exploratory_area_models[[paste("DV", i, "vs", "IV", j, "area", sep = ".")]] <- 
        lm(as.formula(paste(i, "~", j, " + eTIV + Scanner  + GENDER.factor + AGE + RACE")), 
             data = DNS.MRI.data_filtered.and.scaled.for.ML$DNS.aparc.DKT.surf.area.data_filtered)
  }
} 

## Cortical thickness
### Not residualized (so need to account for scanner, age, gender, and race)
ML.FFOCI_exploratory_thickness_models = list()
for (i in DVs){
  for (j in names(DNS.MRI.data_filtered.and.scaled.for.ML$DNS.aparc.DKT.cort.thick.data_filtered) %>% 
            .[matches("*_thick$", vars = .)]){
    ML.FFOCI_exploratory_thickness_models[[paste("DV", i, "vs", "IV", j, "thick", sep = ".")]] <- 
        lm(as.formula(paste(i, "~", j, " + MeanThick  + Scanner + GENDER.factor + AGE + RACE")), 
             data = DNS.MRI.data_filtered.and.scaled.for.ML$DNS.aparc.DKT.cort.thick.data_filtered)
  }
} 

# Combine lists for volume, surface area, and thickness regressions
ML.FFOCI_exploratory_models <- c(ML.FFOCI_exploratory_vol_models, ML.FFOCI_exploratory_area_models,
                             ML.FFOCI_exploratory_thickness_models) 

# Extract results (if want individual variables for each regression result)
# for (i in names(c(ML.FFOCI_exploratory_models, ML.FFOCI_exploratory_area_models, 
#                   ))){
#     name <- paste(i)
#     assign(name, c(ML.FFOCI_exploratory_models, ML.FFOCI_exploratory_area_models, 
#                   )[[i]])
# }

# Create spreadsheet of results
results <- lapply(seq_along(ML.FFOCI_exploratory_models), function(i) {
    data.frame(
      analysis = names(ML.FFOCI_exploratory_models)[i],
      b = summary(ML.FFOCI_exploratory_models[[i]])$coefficients[2,1],
      b_95CI.lower = confint(ML.FFOCI_exploratory_models[[i]], 2)[[1]],
      b_95CI.upper = confint(ML.FFOCI_exploratory_models[[i]], 2)[[2]],
      std.err = summary(ML.FFOCI_exploratory_models[[i]])$coefficients[2,2],
      t = summary(ML.FFOCI_exploratory_models[[i]])$coefficients[2,3],
      p = summary(ML.FFOCI_exploratory_models[[i]])$coefficients[2,4],
      df = df.residual(ML.FFOCI_exploratory_models[[i]]),
      model.n = nobs(ML.FFOCI_exploratory_models[[i]]),
      model.rsq = summary(ML.FFOCI_exploratory_models[[i]])$adj.r.squared,
      stringsAsFactors = FALSE)
})

## NOTE: for 95% CIs, the fifth row of confint.merMod results is for the first IV in model.
##       all stats printed are for the IV of interest.

ML.FFOCI_exploratory_DKT.results <- do.call(rbind, results) %>%
  sort_df("p")

write.csv(ML.FFOCI_exploratory_DKT.results,
          "../Results/Aim2.MRI/Regression/DNS.Aim2.regression.exploratory.DKT.results.csv",
          row.names = FALSE)
```

##### Destrieux 
*Exploratory Analyses*
```{r}
## Volume 
### Not residualized (so need to account for scanner, age, gender, and race)
ML.FFOCI_exploratory_vol_models = list()
for (i in DVs){
  for (j in exploratory.subcortical.IVs){
    ML.FFOCI_exploratory_vol_models[[paste("DV", i, "vs", "IV", j, "vol", sep = ".")]] <- 
        lm(as.formula(paste(i, "~", j, " + eTIV + Scanner + GENDER.factor + AGE + RACE")), 
             data = DNS.MRI.data_filtered.and.scaled.for.ML$DNS.aseg.vol.data_filtered)
  }
} 

# Change destrieux variable names to remove dashes. messes up functions
names(DNS.MRI.data_filtered.and.scaled.for.ML$DNS.aparc.Destrieux.cort.thick.data_filtered) <- 
    gsub(x = names(DNS.MRI.data_filtered.and.scaled.for.ML$DNS.aparc.Destrieux.cort.thick.data_filtered), pattern = "\\-", replacement = "_")  
names(DNS.MRI.data_filtered.and.scaled.for.ML$DNS.aparc.Destrieux.surf.area.data_filtered) <- 
    gsub(x = names(DNS.MRI.data_filtered.and.scaled.for.ML$DNS.aparc.Destrieux.surf.area.data_filtered), pattern = "\\-", replacement = "_")
names(DNS.MRI.data_filtered.and.scaled.for.ML$DNS.aparc.Destrieux.vol.data_filtered) <- 
    gsub(x = names(DNS.MRI.data_filtered.and.scaled.for.ML$DNS.aparc.Destrieux.vol.data_filtered), pattern = "\\-", replacement = "_")  

## Surface area
### Not residualized (so need to account for scanner, age, gender, and race)
ML.FFOCI_exploratory_Destrieux_area_models = list()
for (i in DVs){
  for (j in names(DNS.MRI.data_filtered.and.scaled.for.ML$DNS.aparc.Destrieux.surf.area.data_filtered) %>% 
            .[matches("*_area$", vars = .)]){
      ML.FFOCI_exploratory_Destrieux_area_models[[paste("DV", i, "vs", "IV", j, "area", sep = ".")]] <- 
        lm(as.formula(paste(i, "~", j, " + eTIV + Scanner  + GENDER.factor + AGE + RACE")), 
             data = DNS.MRI.data_filtered.and.scaled.for.ML$DNS.aparc.Destrieux.surf.area.data_filtered)
  }
} 

## Cortical thickness
### Not residualized (so need to account for scanner, age, gender, and race)
ML.FFOCI_exploratory_Destrieux_thickness_models = list()
for (i in DVs){
  for (j in names(DNS.MRI.data_filtered.and.scaled.for.ML$DNS.aparc.Destrieux.cort.thick.data_filtered) %>% 
            .[matches("*_thick$", vars = .)]){
    ML.FFOCI_exploratory_Destrieux_thickness_models[[paste("DV", i, "vs", "IV", j, "thick", sep = ".")]] <- 
        lm(as.formula(paste(i, "~", j, " + MeanThick  + Scanner + GENDER.factor + AGE + RACE")), 
             data = DNS.MRI.data_filtered.and.scaled.for.ML$DNS.aparc.Destrieux.cort.thick.data_filtered)
  }
} 

# Combine lists for volume, surface area, and thickness regressions
ML.FFOCI_exploratory_Destrieux_models <- c(ML.FFOCI_exploratory_vol_models, ML.FFOCI_exploratory_Destrieux_area_models,
                             ML.FFOCI_exploratory_Destrieux_thickness_models) 

# Extract results (if want individual variables for each regression result)
# for (i in names(c(ML.FFOCI_exploratory_models, ML.FFOCI_exploratory_area_models, 
#                   ))){
#     name <- paste(i)
#     assign(name, c(ML.FFOCI_exploratory_models, ML.FFOCI_exploratory_area_models, 
#                   )[[i]])
# }

# Create spreadsheet of results
results <- lapply(seq_along(ML.FFOCI_exploratory_Destrieux_models), function(i) {
    data.frame(
      analysis = names(ML.FFOCI_exploratory_Destrieux_models)[i],
      b = summary(ML.FFOCI_exploratory_Destrieux_models[[i]])$coefficients[2,1],
      b_95CI.lower = confint(ML.FFOCI_exploratory_Destrieux_models[[i]], 2)[[1]],
      b_95CI.upper = confint(ML.FFOCI_exploratory_Destrieux_models[[i]], 2)[[2]],
      std.err = summary(ML.FFOCI_exploratory_Destrieux_models[[i]])$coefficients[2,2],
      t = summary(ML.FFOCI_exploratory_Destrieux_models[[i]])$coefficients[2,3],
      p = summary(ML.FFOCI_exploratory_Destrieux_models[[i]])$coefficients[2,4],
      df = df.residual(ML.FFOCI_exploratory_Destrieux_models[[i]]),
      model.n = nobs(ML.FFOCI_exploratory_Destrieux_models[[i]]),
      model.rsq = summary(ML.FFOCI_exploratory_Destrieux_models[[i]])$adj.r.squared,
      stringsAsFactors = FALSE)
})

## NOTE: for 95% CIs, the fifth row of confint.merMod results is for the first IV in model.
##       all stats printed are for the IV of interest.

ML.FFOCI_exploratory_Destrieux.results <- do.call(rbind, results) %>%
  sort_df("p")

write.csv(ML.FFOCI_exploratory_Destrieux.results,
          "../Results/Aim2.MRI/Regression/DNS.Aim2.regression.exploratory.Destrieux.results.csv",
          row.names = FALSE)
```

### Machine Learning
```{r}
results.dir <- paste0(project.dir, "Results/Aim2.MRI/ML/")
  
# Set seed for reproducibility (b/c splitting data + CV randomly assigns rows to test set)
set.seed(44) 

# Start parallel processing
cl <- makePSOCKcluster(5) # specify number of cores to use (my laptop has 8 but diminishing returns for >5)
registerDoParallel(cl)

#### 1) Create reusable objects to customize cross-validation + tuning parameters  ####

# Specify INDEX to use for CV (if don't, results from caretList and models run individually differ b/c use slightly different resampling sets for CV)
set.seed(64) # same seed as used for splitting data into training/val/test
DNStrainCVindices <- createMultiFolds(DNS.MRI.training.data$DNS.aseg.vol.data_filtered$FFOCISF.pred.res, 
                                      k = 5, times = 5)

# Create random SEEDS to use within CV, which are needed for parallel processing
## NOTES: for details see trainControl() help, https://jaehyeon-kim.github.io/2015/05/Setup-Random-Seeds-on-Caret-Package.html,
##        and https://topepo.github.io/caret/model-training-and-tuning.html#repro and 
set.seed(110)
DNS.seeds.5by5.adaptiveCV.tuneLength100 <- vector(mode = "list", length = 26) # length = 5x5+1
for(i in 1:25) {
  DNS.seeds.5by5.adaptiveCV.tuneLength100[[i]] <- sample.int(1000, 100) # 100 is # of combos of tuning parameters trying, 
}                                      # which I'm currently setting to 100 in tuneLength for adaptive CV
## For the last model (run on all training data after caret determines best hyperparameters):
DNS.seeds.5by5.adaptiveCV.tuneLength100[[26]] <- sample.int(1000, 1)

# Specify hyperparameter tuning grids (if using grid search tuning - not used for adaptive resampling) NOTE: these are same grids as used in OCPD Aim 1
glmnetGrid <- expand.grid(alpha = seq(0,1,length=4),
                          lambda = seq(0.0001, 5, length=20))
gbmGrid <- expand.grid(.interaction.depth = (1:5)*2, 
                       .n.trees = (1:10)*25, 
                       .shrinkage = 0.1,
                       .nminobsinnode = 10)
linearsvrGrid <- expand.grid(C = seq(0.25, 8, length = 20))
# radialsvrGrid <- expand.grid(C = seq(0.25, 8, length = 20), 
#                              sigma = ) I don't know what values to try for sigma. prob use random search

# Define trainControl object that specifies cross-validation + tuning parameters
adaptControl.DNS.MRI <- trainControl(
    method = "adaptive_cv", # using adaptive resampling for tuning
    number = 5, # number of folds
    repeats = 5, # repeats entire cross-validating procedure X times 
    verboseIter = TRUE,
    search = "random", # must specify random for adaptive resampling
    index = DNStrainCVindices, # specifies rows to be used in each CV fold for reproducibility + parallel abilities
    seeds = DNS.seeds.5by5.adaptiveCV.tuneLength100,
    adaptive = list(min = 5, # min # of resamples for each tuning parameter (default = 5)
                    alpha = 0.05, # conf level to remove parameter settings
                    method = "gls", # linear model 
                    complete = TRUE)) # whether train should generate full resampling set if finds
                                      # optimal solution before end of resampling. need if want to know estimated performance

#### 2) Run the train function - 1. preprocesses data, 2. does cross-validation,     ####
##                               3. automatically tunes hyperparameters, 4. runs model ##

####################################################
# Run numerous models all at once with caretList() #
####################################################
MRIalgorithmList <- c("glmnet", "gbm", "svmLinear", "svmRadial", "nnet") 

# Algorithm Info
## nnet (from package nnet)
# Type: Classification, Regression
# Tuning parameters:
#    size (#Hidden Units)
#    decay (Weight Decay)
# A model-specific variable importance metric is available.

# A priori ROIs only
## Residualized, adaptive resampling tuning
set.seed(84)
apriori.DNS.MRI.res.adapt.model.list <- caretList(
    as.formula(paste("FFOCISF.pred.res ~ ", paste(c(paste0(cortical.IVs.DKT, "_thick.res"), paste0(cortical.IVs.DKT, "_area.res"), subcortical.IVs.res), collapse = " + "))), 
    data = DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data,
    preProcess = c("center", "scale"), # centers and scales
    trControl = adaptControl.DNS.MRI,
    tuneLength = 100,
    methodList = MRIalgorithmList) # ML algorithms using

## Save model
lapply(seq_along(apriori.DNS.MRI.res.adapt.model.list), function(i) 
  saveRDS(apriori.DNS.MRI.res.adapt.model.list[[i]], 
          file = paste(results.dir, "apriori.DNS.MRI.res.adapt.", 
                      names(apriori.DNS.MRI.res.adapt.model.list)[[i]], ".Rds", sep = "")))

# Exploratory (All ROIs)
## Residualized
set.seed(84)
exploratory.DNS.MRI.res.adapt.model.list <- caretList(
    as.formula(paste("FFOCISF.pred.res ~ ", paste(c(names(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data)[grepl("*_area.res$", colnames(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data))],
        names(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data)[grepl("*_thick.res$", colnames(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data))],
        exploratory.subcortical.IVs.res), collapse = " + "))), 
    data = DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data,
    preProcess = c("center", "scale"), # centers and scales
    trControl = adaptControl.DNS.MRI,
    tuneLength = 100,
    methodList = MRIalgorithmList) # ML algorithms using

## Save model
lapply(seq_along(exploratory.DNS.MRI.res.adapt.model.list), function(i) 
  saveRDS(exploratory.DNS.MRI.res.adapt.model.list[[i]], 
          file = paste(results.dir, "exploratory.DNS.MRI.res.adapt.", 
                      names(exploratory.DNS.MRI.res.adapt.model.list)[[i]], ".Rds", sep = "")))

## NOT Residualized
# residualized model performance was very bad. in sanity check below predicting avg. thick from ROIs' thickness,
# residualized also performed very badly, but not residualized was as expected (R2 ~ 0.9).
# so trying models w/o residualizing

# No covariates in the model
set.seed(84)
exploratory.DNS.MRI.adapt.model.list <- caretList(
    as.formula(paste("FFOCISF.pred.res ~ ", paste(c(names(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data)[grepl("*_area$", colnames(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data))],
        names(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data)[grepl("*_thick$", colnames(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data))],
        exploratory.subcortical.IVs), collapse = " + "))), 
    data = DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data,
    preProcess = c("center", "scale"), # centers and scales
    trControl = adaptControl.DNS.MRI,
    tuneLength = 100,
    methodList = MRIalgorithmList) # ML algorithms using

## Save model
lapply(seq_along(exploratory.DNS.MRI.adapt.model.list), function(i) 
  saveRDS(exploratory.DNS.MRI.adapt.model.list[[i]], 
          file = paste(results.dir, "exploratory.DNS.MRI.adapt.", 
                      names(exploratory.DNS.MRI.adapt.model.list)[[i]], ".Rds", sep = "")))

# Version w/ covariates in the model (ALM ADDED 4/6/23)
set.seed(84)
exploratory.DNS.MRI.adapt.model.list_w.covars <- caretList(
    as.formula(paste("FFOCISF.pred.res ~ ", paste(c(names(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data)[grepl("*_area$", colnames(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data))],
        names(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data)[grepl("*_thick$", colnames(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data))],
        exploratory.subcortical.IVs, "+ eTIV + Scanner + GENDER.factor + AGE + RACE"), collapse = " + "))), 
    data = DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data,
    preProcess = c("center", "scale"), # centers and scales
    trControl = adaptControl.DNS.MRI,
    tuneLength = 100,
    methodList = MRIalgorithmList) # ML algorithms using

## Save model
lapply(seq_along(exploratory.DNS.MRI.adapt.model.list_w.covars), function(i) 
  saveRDS(exploratory.DNS.MRI.adapt.model.list_w.covars[[i]], 
          file = paste(results.dir, "exploratory.DNS.MRI.adapt.", 
                      names(exploratory.DNS.MRI.adapt.model.list_w.covars)[[i]], ".w.covars.Rds", sep = "")))
```

Examine output of ML models
```{r}
# Load saved models (if needed)
rdsfiles <- list.files(path = results.dir, pattern = ".Rds$")
MRIModelList <- lapply(rdsfiles, function(x) readRDS(paste0(results.dir, x)))
names(MRIModelList) <- gsub("\\.Rds*$","", rdsfiles)
#list2env(MRIModelList, envir = environment())
```

```{r }
#### 3) Examine output
# Add apriori and exploratory to list element names 
names(apriori.DNS.MRI.res.adapt.model.list) <- paste0(names(apriori.DNS.MRI.res.adapt.model.list), ".aprioriMRI")
names(exploratory.DNS.MRI.res.adapt.model.list) <- paste0(names(exploratory.DNS.MRI.res.adapt.model.list), ".explorMRI")
# Combine apriori and exploratory models into single list
MRIModelList <- c(apriori.DNS.MRI.res.adapt.model.list, exploratory.DNS.MRI.res.adapt.model.list)
# Remove numbers being adding to col names
names(MRIModelList)<- gsub("*[[:digit:]]*$", "", names(MRIModelList))

# Extract performance from training data CV resampling 
apriori.resamples <- resamples(apriori.DNS.MRI.res.adapt.model.list)
exploratory.resamples <- resamples(exploratory.DNS.MRI.res.adapt.model.list)

# Summarize the CV results for training data
summary(apriori.resamples)
summary(exploratory.resamples)

# View results/compare for training data
bwplot(apriori.resamples, metric = "RMSE") # boxplots of out-of-sample RMSE  
xyplot(apriori.resamples, metric = "RMSE") # scatterplot of model performances on different folds
plotObsVsPred(apriori.resamples)

# Check performance metrics for final models trained on all training data
# (summary(resamples) gives metrics across all CV resamples)
lapply(MRIModelList, function(x) getTrainPerf(x))

# Create spreadsheet of results
# (getTrainPerf() seems to report the mean values from CV resampling that resamples() reports)
TrainPerf.df <- do.call(rbind, lapply(MRIModelList, function(x) as.data.frame(getTrainPerf(x))))

## for some reason the code below only works if a dataframe is already initialized properly, which works if still run getTrainPerf above. 
## it then regenerates those columns in the code below. trying to create an empty dataframe using as.data.frame below doesn't work for some reason.
#TrainPerf.df <- as.data.frame(matrix(ncol = 24, nrow = length(FU12.MAPPOC.adapt.model.list))) 

results.spreadsheet <- function(list, df.name){
df.name <- df.name %>%
  mutate(Model.Name = do.call(rbind, lapply(seq_along(list), function(i) paste(names(list)[i]))),
         Outcome.Measure = do.call(rbind, lapply(list, function(x) all.vars(x$terms)[1])),
         Algorithm = do.call(rbind, lapply(list, function(x) x$method)),
         Tuning.Type = do.call(rbind, lapply(list, function(x) x$control$method)), # says adaptive_cv for adaptive resampling
         tuneLength = do.call(rbind, lapply(list, function(x) print(x$call$tuneLength))),
         CV = do.call(rbind, lapply(list, function(x) print(paste0(x$control$number, "x", x$control$repeats)))),
#        Index.Set = if(x$control$index ==,
#        Seed = , couldn't figure out how to get it to just say whether "given" or "null" or nothing specified in trainControl
#         Parallel = , there is a parallel arg in train() but it's default is TRUE so that doesn't tell you if parallel processing was running
          TrainRMSE = do.call(rbind, lapply(list, function(x) getTrainPerf(x)[[1]])),
          TrainRsquared = do.call(rbind, lapply(list, function(x) getTrainPerf(x)[[2]])),
          TrainMAE = do.call(rbind, lapply(list, function(x) getTrainPerf(x)[[3]])),
          Outcome.SD = do.call(rbind, lapply(list, function(x) print(sd(x$trainingData$.outcome)))),
#         RMSE.to.SD = TrainRMSE/Outcome.SD, don't think mutate can use a variable created in the same call for calculations. must run this separately at end
          Hyperparameter1 = do.call(rbind, lapply(list, function(x) names(x$bestTune)[[1]])),
          Final.Value1 = do.call(rbind, lapply(list, function(x) x$bestTune[[1]])),
          Hyperparameter2 = do.call(rbind, lapply(list, function(x) {if(length(x$bestTune) < 2) {NA} else {names(x$bestTune)[[2]]}})),
          Final.Value2 = do.call(rbind, lapply(list, function(x) {if(length(x$bestTune) < 2) {NA} else {x$bestTune[[2]]}})),
          Hyperparameter3 = do.call(rbind, lapply(list, function(x) {if(length(x$bestTune) < 3) {NA} else {names(x$bestTune)[[3]]}})),
          Final.Value3 = do.call(rbind, lapply(list, function(x) {if(length(x$bestTune) < 3) {NA} else {x$bestTune[[3]]}})),
          Hyperparameter4 = do.call(rbind, lapply(list, function(x) {if(length(x$bestTune) < 4) {NA} else {names(x$bestTune)[[4]]}})),
          Final.Value4 = do.call(rbind, lapply(list, function(x) {if(length(x$bestTune) < 4) {NA} else {x$bestTune[[4]]}})),
          OrigPredictors = do.call(rbind, lapply(list, function(x) length((x$coefnames)))),
          PredictorsKept = do.call(rbind, lapply(list, function(x) length(predictors(x)))),
          N = do.call(rbind, lapply(list, function(x) dim(x$trainingData)[1]))) %>%
  mutate(RMSE.to.SD = TrainRMSE/Outcome.SD)}

TrainPerf.df <- results.spreadsheet(MRIModelList, TrainPerf.df)

write.csv(TrainPerf.df, file = paste0(results.dir, "MRItraining.data.performance.csv"), row.names = F)

## To look at coefficients
# coef(<model.name>$finalModel, <model.name>$bestTune$<one of the tuning parameters>)

# See which predictor variables were kept in the models
## if just want to know how many variables kept, add length() outside of the predictors call
predictors <- lapply(MRIModelList, function(x) predictors(x))
## save to file
# predictors.df <- do.call(cbind, lapply(MRIModelList, function(x) as.data.frame(predictors(x))))
# lapply(X = predictors, function(x) {write(x, append = T, file = "predictors.txt", ncolumns = 56) })
predictors.df <- do.call(cbind, lapply(predictors, function(x) paste(x, collapse = " "))) 
# note this puts all predictors in single cell for each model
# couldn't figure out how to make this better. had to open the file in google sheets and use formula =TRANSPOSE(SPLIT(A2," "))
write.csv(predictors.df, file = paste0(results.dir, "MRIpredictors.csv"))

# Variable Importance
varImpInfo <- lapply(MRIModelList, function(x) varImp(x, scale = FALSE))
## Print to file
varImpInfo.df_apriori <- do.call(cbind, lapply(varImpInfo[1:5], function(x) as.data.frame(x$importance)))
varImpInfo.df_exploratory <- do.call(cbind, lapply(varImpInfo[6:10], function(x) as.data.frame(x$importance)))
names(varImpInfo.df_apriori) <- names(varImpInfo[1:5])
names(varImpInfo.df_exploratory) <- names(varImpInfo[6:10])
write.csv(varImpInfo.df_apriori, file = paste0(results.dir, 'varImpInfo_aprioriMRI.csv'), col.names = TRUE)
write.csv(varImpInfo.df_exploratory, file = paste0(results.dir, 'varImpInfo_exploratoryMRI.csv'), col.names = TRUE)

## Correctly generates plots w/ titles
lapply(seq_along(varImpInfo), function(x) {
  plot(varImpInfo[[x]], top = 20, main = paste(names(varImpInfo)[[x]]))
})

## Figure out how to also save to files
## A not nice manual way using Rstudio temp files (but plots aren't blurry)
dir.create(path = paste0(results.dir, "VarImpPlots")) # (only need to create this dir once)
plots.dir.path <- list.files(tempdir(), pattern="rs-graphics", full.names = TRUE); 
plots.png.paths <- list.files(plots.dir.path, pattern=".png", full.names = TRUE)
file.copy(from=plots.png.paths, to=paste0(results.dir, "VarImpPlots/"))

## Add color coding to graphs
### Individually per model (works)
varImpInfo.df_apriori$varnames <- rownames(varImpInfo.df_apriori) # row names to column
varImpInfo.df_apriori <- varImpInfo.df_apriori %>%
  mutate(var_categ = ifelse(grepl("thick.res", varnames), "Thickness",
                        ifelse(grepl("_area.res", varnames), "Surface Area", "Volume")))

top_n(varImpInfo.df_apriori, n=20, gbm.aprioriMRI) %>%
  ggplot(., aes(x=reorder(varnames, gbm.aprioriMRI), y=gbm.aprioriMRI, color=as.factor(var_categ))) + 
  geom_point() +
  geom_segment(aes(x=varnames,xend=varnames,y=0,yend=gbm.aprioriMRI)) +
  scale_color_discrete(name="Phenotype") +
  ylab("Importance") +
  xlab("Variable Name") +
  coord_flip()

# Brain maps of variable importance (NOT DONE CODING)
## load data (if doing later)
varImpInfo.df_exploratory <- read.csv(paste0(project.dir, "Results/Aim2.MRI/ML/varImpInfo_exploratoryMRI.csv"))

lapply(seq_along(varImpInfo.df_exploratory), function(x) {
  ggseg(mapping=aes(fill=x), atlas = "dkt", position="stacked", color = "black") +
  guides(fill=guide_legend(title="Significant\nFindings")) +
#  scale_fill_discrete(drop=FALSE) + # keeps unused factor levels so color scale same
  ggtitle("")})
  #labs(title = "Cortical")
 #   ggsave("")})

varImpInfo.df_exploratory <- varImpInfo.df_exploratory %>% 
    mutate(hemi = case_when(grepl("left", X) ~ "left", 
                            grepl("right", X) ~ "right"),
           measure = case_when(grepl("_area", X) ~ "Surface Area",
                               grepl("thick", X) ~ "Thickness",
                               TRUE ~ "Volume"),
           region = str_remove(X, "_.*"))
                               #c("\\_left_area.res", "_right_area.res", "_left_thick.res", "_right_thick.res"))) 

# above isn't working. manually create df w/ values to graph
explor.MRI.features.data <- data.frame(hemi=c("left", "left", "left", "right", "left", "right", "right"),
#region = c("left insula", "left thalamus", "left fusiform", "right lateral occipital", "left cerebral white matter", "right superior frontal", "right caudal anterior cingulate"),
region = c("insula", "thalamus proper", "fusiform", "lateral occipital", "cerebral white matter", "superior frontal", "caudal anterior cingulate"),
measure = c("Thickness", "Volume", "Surface area", "Thickness", "Volume", "Thickness", "Thickness"))
#left insula thickness, left thalamus volume, left fusiform gyrus surface area, right lateral occipital cortex thickness, left hemisphere cerebral white matter volume, right superior frontal gyrus thickness, and right caudal anterior cingulate thickness
# Cortical features
ggseg(explor.MRI.features.data,
#ggseg(filter(varImpInfo.df_exploratory, glmnet.explorMRI != 0), 
      mapping=aes(fill=measure), atlas = "dkt", position="stacked", color = "black") +
  guides(fill=guide_legend(title="Features Kept")) +
#  scale_fill_discrete(drop=FALSE) + # keeps unused factor levels so color scale same
  ggtitle("Elastic Net Regression Model")
ggsave("../Figures/final.data/MRI.ML.features.kept.dkt.cortical.png")
# subcortical volume
ggseg(explor.MRI.features.data,
#ggseg(filter(varImpInfo.df_exploratory, glmnet.explorMRI != 0), 
      mapping=aes(fill=measure), atlas = "aseg", position="stacked", color = "black") +
  guides(fill=guide_legend(title="Features Kept")) +
#  scale_fill_discrete(drop=FALSE) + # keeps unused factor levels so color scale same
  ggtitle("Elastic Net Regression Model")
ggsave("../Figures/final.data/MRI.ML.features.kept.aseg.png")


# Predicted values from ML Models (i.e., predicted predicted scores (based on input of predicted DNS FFOCI))
explor.res.col.names <- c(names(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data)[grepl("*_area.res$", colnames(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data))],
        names(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data)[grepl("*_thick.res$", colnames(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data))],
        exploratory.subcortical.IVs.res)

output.predicted.y_glmnet.explor <- predict(MRIModelList$exploratory.DNS.MRI.res.adapt.glmnet)

#output.predicted.y <- predict(MRIModelList)
output.predicted.y.explor <- extractPrediction(MRIModelList[16:20], 
                              testX = DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data[ , explor.res.col.names], 
                              testY = DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data$FFOCISF.pred.res)
plotObsVsPred(output.predicted.y.explor)

#### NOT RESIDUALIZED MODELS ######
# Create spreadsheet of results
# (getTrainPerf() seems to report the mean values from CV resampling that resamples() reports)
NOTResTrainPerf.df <- do.call(rbind, lapply(exploratory.DNS.MRI.adapt.model.list, function(x) as.data.frame(getTrainPerf(x))))

NOTResTrainPerf.df <- results.spreadsheet(exploratory.DNS.MRI.adapt.model.list, NOTResTrainPerf.df)

write.csv(NOTResTrainPerf.df, paste0(results.dir, "MRI.NOT.RES.Training.performance.csv"), row.names = TRUE)

## Version w/ unresidualized MRI data, residualized FFOCI-SF and covariates in models (age, gender, race, scanner, eTIV)
NOTRes.w.covars.TrainPerf.df <- results.spreadsheet(exploratory.DNS.MRI.adapt.model.list_w.covars, TrainPerf.df)
NOTRes.w.covars.TrainPerf.df <- do.call(rbind, lapply(exploratory.DNS.MRI.adapt.model.list_w.covars, function(x) as.data.frame(getTrainPerf(x))))
write.csv(NOTRes.w.covars.TrainPerf.df, file = paste0(results.dir, "MRI.NOT.RES.W.COVARS.training.data.performance.csv"), row.names = F)
```

Evaluate trained model performance in testing dataset
```{r}
####### RESIDUALIZED MODELS ########
# Calculate RMSE for predicted values in test data 
# NOTE: didn't figure out extractPrediction function so using lapply instead
testData.predictions <- lapply(MRIModelList, function(model) predict(model, DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data))

# Create dataframe that output as file
testPerf.df <- as.data.frame(rbind( 
  do.call(rbind, lapply(testData.predictions, function(model) 
    postResample(pred = model, obs = DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data$FFOCISF.pred.res)))))

## Add outcome SD + RMSE/OutcomeSD to the dataframe for reference
testPerf.df <- mutate(testPerf.df, 
    OutcomeSD = sd(DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data$FFOCISF.pred.res))    
testPerf.df <- mutate(testPerf.df, RMSE.to.SD = RMSE/OutcomeSD)

write.csv(testPerf.df, file = paste0(results.dir, "test.data.MRI.performance.csv"), 
          row.names = TRUE)
          
#extractPrediction(FU12.FFOCI.res.adapt.model.list$glmnet, testX = select(testData.FU12, matches("NEO.*\\.res$")), 
#                  testY = testData.FU12$FU12FFOCI_Scaled.Total.res)

#### NOT RESIDUALIZED NEURO DATA MODELS ######
# note: FFOCI-SF still residualized. see post-hoc test section for unresidualized FFOCI + neuro 

# Load saved models (if needed)
rdsfiles <- list.files(path = "/Users/allison/Library/CloudStorage/Box-Box/research/projects/dissertation/Results/Aim2.MRI/ML", pattern = "exploratory.DNS.MRI.adapt.*")
saved.models <- lapply(rdsfiles, function(x) readRDS(paste0("/Users/allison/Library/CloudStorage/Box-Box/research/projects/dissertation/Results/Aim2.MRI/ML/", x)))
names(saved.models) <- gsub("\\.Rds*$","", rdsfiles)
exploratory.DNS.MRI.adapt.model.list <- saved.models

# Create spreadsheet of results
# Calculate RMSE for predicted values in test data 
# NOTE: didn't figure out extractPrediction function so using lapply instead
MRI.notRes.testData.predictions <- lapply(exploratory.DNS.MRI.adapt.model.list, function(model) predict(model, DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data))

# Create dataframe that output as file
testPerf.df <- as.data.frame(rbind( 
  do.call(rbind, lapply(MRI.notRes.testData.predictions, function(model) 
    postResample(pred = model, obs = DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data$FFOCISF.pred.res)))))

## Add outcome SD + RMSE/OutcomeSD to the dataframe for reference
testPerf.df <- mutate(testPerf.df, 
    OutcomeSD = sd(DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data$FFOCISF.pred.res))    
testPerf.df <- mutate(testPerf.df, RMSE.to.SD = RMSE/OutcomeSD)

results.dir <- "/Users/allison/Library/CloudStorage/Box-Box/research/projects/dissertation/Results/Aim2.MRI/ML/"
write.csv(testPerf.df, file = paste0(results.dir, "MRI.NOT.RES.test.data.performance.csv"), 
          row.names = TRUE)

# ADDING COVARIATES TO UNRESIDUALIZED MRI data. FFOCI-SF still residualized (see post-hoc tests below for unresidualized FFOCI + MRI)

# Create spreadsheet of results
# Calculate RMSE for predicted values in test data 
# NOTE: didn't figure out extractPrediction function so using lapply instead
MRI.notRes.w.covars.testData.predictions <- lapply(exploratory.DNS.MRI.adapt.model.list_w.covars, function(model) predict(model, DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data))

# Create dataframe that output as file
testPerf.df <- as.data.frame(rbind( 
  do.call(rbind, lapply(MRI.notRes.w.covars.testData.predictions, function(model) 
    postResample(pred = model, obs = DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data$FFOCISF.pred.res)))))

## Add outcome SD + RMSE/OutcomeSD to the dataframe for reference
testPerf.df <- mutate(testPerf.df, 
    OutcomeSD = sd(DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data$FFOCISF.pred.res))    
testPerf.df <- mutate(testPerf.df, RMSE.to.SD = RMSE/OutcomeSD)

results.dir <- "/Users/allison/Library/CloudStorage/Box-Box/research/projects/dissertation/Results/Aim2.MRI/ML/"
write.csv(testPerf.df, file = paste0(results.dir, "MRI.NOT.RES.W.COVARS.test.data.performance.csv"), 
          row.names = TRUE)

# Stop parallel processing
stopCluster(cl)
```

#### Posthoc Tests
Try predicting neuroticism + conscientiousness from neuroimaging data (as control to check if performance similar to FFOCI models)
```{r}
# Neuroticism - Exploratory (All ROIs)
set.seed(84)
exploratory.DNS.MRI.neuroticism.res.adapt.model.list <- caretList(
    as.formula(paste("NEON.imputed.res ~ ", paste(c(names(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data)[grepl("*_area.res$", colnames(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data))],
        names(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data)[grepl("*_thick.res$", colnames(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data))],
        exploratory.subcortical.IVs.res), collapse = " + "))), 
    data = DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data,
    preProcess = c("center", "scale"), # centers and scales
    trControl = adaptControl.DNS.MRI,
    tuneLength = 100,
    methodList = MRIalgorithmList) # ML algorithms using

## Save model
lapply(seq_along(exploratory.DNS.MRI.neuroticism.res.adapt.model.list), function(i) 
  saveRDS(exploratory.DNS.MRI.neuroticism.res.adapt.model.list[[i]], 
          file = paste(results.dir, "exploratory.DNS.MRI.neuroticism.res.adapt.", 
                      names(exploratory.DNS.MRI.neuroticism.res.adapt.model.list)[[i]], ".Rds", sep = "")))

# Conscientiousness - Exploratory (All ROIs)
set.seed(84)
exploratory.DNS.MRI.conscientiousness.res.adapt.model.list <- caretList(
    as.formula(paste("NEOC.imputed.res ~ ", paste(c(names(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data)[grepl("*_area.res$", colnames(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data))],
        names(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data)[grepl("*_thick.res$", colnames(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data))],
        exploratory.subcortical.IVs.res), collapse = " + "))), 
    data = DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data,
    preProcess = c("center", "scale"), # centers and scales
    trControl = adaptControl.DNS.MRI,
    tuneLength = 100,
    methodList = MRIalgorithmList) # ML algorithms using

## Save model
lapply(seq_along(exploratory.DNS.MRI.conscientiousness.res.adapt.model.list), function(i) 
  saveRDS(exploratory.DNS.MRI.conscientiousness.res.adapt.model.list[[i]], 
          file = paste(results.dir, "exploratory.DNS.MRI.conscientiousness.res.adapt.", 
                      names(exploratory.DNS.MRI.conscientiousness.res.adapt.model.list)[[i]], ".Rds", sep = "")))

# Create spreadsheet of results
# (getTrainPerf() seems to report the mean values from CV resampling that resamples() reports)
## Neuroticism
Neurot.TrainPerf.df <- do.call(rbind, lapply(exploratory.DNS.MRI.neuroticism.res.adapt.model.list, 
                                             function(x) as.data.frame(getTrainPerf(x))))
## for some reason the code below only works if a dataframe is already initialized properly, which works if still run getTrainPerf above. 
## it then regenerates those columns in the code below. trying to create an empty dataframe using as.data.frame below doesn't work for some reason
Neurot.TrainPerf.df <- results.spreadsheet(exploratory.DNS.MRI.neuroticism.res.adapt.model.list, Neurot.TrainPerf.df)

write.csv(Neurot.TrainPerf.df, file = paste0(results.dir, "Neuroticism.MRItraining.data.performance.csv"), row.names = F)

## Conscientiousness
Consc.TrainPerf.df <- do.call(rbind, lapply(exploratory.DNS.MRI.conscientiousness.res.adapt.model.list, 
                                             function(x) as.data.frame(getTrainPerf(x))))
Consc.TrainPerf.df <- results.spreadsheet(exploratory.DNS.MRI.conscientiousness.res.adapt.model.list, Consc.TrainPerf.df)

write.csv(Consc.TrainPerf.df, file = paste0(results.dir, "Conscientiousness.MRItraining.data.performance.csv"), row.names = F)

# Test data performance

## Load saved models (if needed)
rdsfiles <- list.files(path = paste0(results.dir, "personality/"), pattern = ".Rds$")
saved.models <- lapply(rdsfiles, function(x) readRDS(paste0(results.dir, "personality/", x)))
names(saved.models) <- gsub("\\.Rds*$","", rdsfiles)
exploratory.DNS.MRI.conscientiousness.res.adapt.model.list <- saved.models[c(1:5)]
exploratory.DNS.MRI.neuroticism.res.adapt.model.list <- saved.models[c(6:10)]

# #Calculate RMSE for predicted values in test data 
# NOTE: didn't figure out extractPrediction function so using lapply instead
Neurot.testData.predictions <- lapply(exploratory.DNS.MRI.neuroticism.res.adapt.model.list, 
      function(model) predict(model, DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data))

Consc.testData.predictions <- lapply(exploratory.DNS.MRI.conscientiousness.res.adapt.model.list, 
      function(model) predict(model, DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data))

## Create dataframe that output as file
Neurot.testPerf.df <- as.data.frame(rbind( 
  do.call(rbind, lapply(Neurot.testData.predictions, function(model) 
    postResample(pred = model, obs = DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data$NEON_imputed.res)))))

Consc.testPerf.df <- as.data.frame(rbind( 
  do.call(rbind, lapply(Consc.testData.predictions, function(model) 
    postResample(pred = model, obs = DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data$NEOC_imputed.res)))))

## Add outcome SD + RMSE/OutcomeSD to the dataframe for reference
Neurot.testPerf.df <- mutate(Neurot.testPerf.df, 
    OutcomeSD = sd(DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data$NEON_imputed.res))    
Neurot.testPerf.df <- mutate(Neurot.testPerf.df, RMSE.to.SD = RMSE/OutcomeSD)

Consc.testPerf.df <- mutate(Consc.testPerf.df, 
    OutcomeSD = sd(DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data$NEOC_imputed.res))    
Consc.testPerf.df <- mutate(Consc.testPerf.df, RMSE.to.SD = RMSE/OutcomeSD)

write.csv(Neurot.testPerf.df, file = paste0("/Users/allison/Library/CloudStorage/Box-Box/research/projects/dissertation/Results/Aim2.MRI/ML/personality/", "Neuroticism.MRI.test.performance.csv"), 
          row.names = TRUE)

write.csv(Consc.testPerf.df, file = paste0("/Users/allison/Library/CloudStorage/Box-Box/research/projects/dissertation/Results/Aim2.MRI/ML/personality/", "Conscientiousness.MRI.test.performance.csv"), 
          row.names = TRUE)
```

Predict average thickness from regional cortical thickness to see if the ML models 
can accurately predict MRI data in DNS

```{r}
# Residualized
set.seed(84)
ROI.thick.predict.avg.thick.res.model.list <- caretList(
    as.formula(paste("MeanThick.res ~ ", paste(c(
        names(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data)[grepl("*_thick.res$", colnames(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data))]), collapse = " + "))), 
    data = DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data,
    preProcess = c("center", "scale"), # centers and scales
    trControl = adaptControl.DNS.MRI,
    tuneLength = 100,
    methodList = MRIalgorithmList) # ML algorithms using

## Save model
lapply(seq_along(ROI.thick.predict.avg.thick.res.model.list), function(i) 
  saveRDS(ROI.thick.predict.avg.thick.res.model.list[[i]], 
          file = paste(results.dir, "ROI.thick.predict.avg.thick.res.", 
                      names(ROI.thick.predict.avg.thick.res.model.list)[[i]], ".Rds", sep = "")))

# Not residualized
set.seed(84)
ROI.thick.predict.avg.thick.model.list <- caretList(
    as.formula(paste("MeanThick ~ ", paste(c(
        names(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data)[grepl("*_thick$", colnames(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data))]), collapse = " + "))), 
    data = DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data,
    preProcess = c("center", "scale"), # centers and scales
    trControl = adaptControl.DNS.MRI,
    tuneLength = 100,
    methodList = MRIalgorithmList) # ML algorithms using

## Save model
lapply(seq_along(ROI.thick.predict.avg.thick.model.list), function(i) 
  saveRDS(ROI.thick.predict.avg.thick.model.list[[i]], 
          file = paste(results.dir, "ROI.thick.predict.avg.thick.", 
                      names(ROI.thick.predict.avg.thick.model.list)[[i]], ".Rds", sep = "")))

# Create spreadsheet of results
# (getTrainPerf() seems to report the mean values from CV resampling that resamples() reports)
## Residualized
Thick.res.TrainPerf.df <- do.call(rbind, lapply(ROI.thick.predict.avg.thick.res.model.list, 
                                             function(x) as.data.frame(getTrainPerf(x))))
## for some reason the code below only works if a dataframe is already initialized properly, which works if still run getTrainPerf above. 
## it then regenerates those columns in the code below. trying to create an empty dataframe using as.data.frame below doesn't work for some reason
Thick.res.TrainPerf.df <- results.spreadsheet(ROI.thick.predict.avg.thick.res.model.list)

## Not residualized 
Thick.TrainPerf.df <- do.call(rbind, lapply(ROI.thick.predict.avg.thick.model.list, 
                                             function(x) as.data.frame(getTrainPerf(x))))
## for some reason the code below only works if a dataframe is already initialized properly, which works if still run getTrainPerf above. 
## it then regenerates those columns in the code below. trying to create an empty dataframe using as.data.frame below doesn't work for some reason
Thick.TrainPerf.df <- results.spreadsheet(ROI.thick.predict.avg.thick.model.list)

Thick.both.TrainPerf.df <- rbind(Thick.res.TrainPerf.df, Thick.TrainPerf.df)

write.csv(Thick.both.TrainPerf.df, file = paste0(results.dir, "Thickness.MRItraining.data.performance.csv"), row.names = F)

# Test data performance

## Load saved models (if needed)
rdsfiles <- list.files(path = paste0(results.dir, "thickness.sanity.check/"), pattern = ".Rds$")
saved.models <- lapply(rdsfiles, function(x) readRDS(paste0(results.dir, "thickness.sanity.check/", x)))
names(saved.models) <- gsub("\\.Rds*$","", rdsfiles)

ROI.thick.predict.avg.thick.model.list <- saved.models[c(1,2,3,9,10)]
ROI.thick.predict.avg.thick.res.model.list <- saved.models[c(4:8)]

## Calculate RMSE for predicted values in test data 
# NOTE: didn't figure out extractPrediction function so using lapply instead
Thick.testData.predictions <- lapply(ROI.thick.predict.avg.thick.model.list, 
      function(model) predict(model, DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data))
Thick.res.testData.predictions <- lapply(ROI.thick.predict.avg.thick.res.model.list, 
      function(model) predict(model, DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data))

## Create dataframe that output as file
Thick.testPerf.df <- as.data.frame(rbind( 
  do.call(rbind, lapply(Thick.testData.predictions, function(model) 
    postResample(pred = model, obs = DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data$MeanThick)))))

Thick.res.testPerf.df <- as.data.frame(rbind( 
  do.call(rbind, lapply(Thick.res.testData.predictions, function(model) 
    postResample(pred = model, obs = DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data$MeanThick.res)))))

## Add outcome SD + RMSE/OutcomeSD to the dataframe for reference
Thick.testPerf.df <- mutate(Thick.testPerf.df, 
    OutcomeSD = sd(DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data$MeanThick))    
Thick.testPerf.df <- mutate(Thick.testPerf.df, RMSE.to.SD = RMSE/OutcomeSD)

Thick.res.testPerf.df <- mutate(Thick.res.testPerf.df, 
    OutcomeSD = sd(DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data$MeanThick.res))    
Thick.res.testPerf.df <- mutate(Thick.res.testPerf.df, RMSE.to.SD = RMSE/OutcomeSD)

Thick.both.testPerf.df <- rbind(Thick.res.testPerf.df, Thick.testPerf.df)

write.csv(Thick.both.testPerf.df, file = paste0("~/Library/CloudStorage/Box-Box/research/projects/dissertation/Results/Aim2.MRI/ML/thickness.sanity.check/", "Thickness.MRItest.performance.csv"), 
          row.names = TRUE)
```

Use unresidualized predicted FFOCI scores (+ unresidualized neuro data)
```{r}
# Load predicted FFOCI scores (NOT residualized version)
predicted.notRes.FFOCI.DNS <- read.csv("~/Library/CloudStorage/Box-Box/research/projects/dissertation/Results/Aim1.OCPD/ML/OCPD.NAs.filtered.models/from.caretList/parallel/seed.GIVEN/all.unresid.models.run/NEW.all.rerun.fixed.FU12MAPP/predicted.scores/DNS.predicted.FFOCI.Scaled.Total.Not.Res_FU12glmnet.model.csv")
names(predicted.notRes.FFOCI.DNS) <- c("FFOCISF.pred", "ID")

# Add unresidualized predicted FFOCI scores to neuroimaging dataframes
DNS.MRI.data_filtered.for.ML <- lapply(DNS.MRI.data_filtered.for.ML, function(df){
  left_join(df, predicted.notRes.FFOCI.DNS, by = "ID")})
DNS.MRI.training.data <- lapply(DNS.MRI.training.data, function(df){
  left_join(df, predicted.notRes.FFOCI.DNS, by = "ID")})
DNS.MRI.test.data <- lapply(DNS.MRI.test.data, function(df){
  left_join(df, predicted.notRes.FFOCI.DNS, by = "ID")})

# Run exploratory models (All ROIs)
## NOT residualized (features or outputs) 
set.seed(84)
exploratory.DNS.MRI.noRes.adapt.model.list <- caretList(
    as.formula(paste("FFOCISF.pred ~ ", paste(c(names(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data)[grepl("*_area$", colnames(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data))],
        names(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data)[grepl("*_thick$", colnames(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data))],
        exploratory.subcortical.IVs), collapse = " + "))), 
    data = DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data,
    preProcess = c("center", "scale"), # centers and scales
    trControl = adaptControl.DNS.MRI,
    tuneLength = 100,
    methodList = MRIalgorithmList) # ML algorithms using

## Save model
lapply(seq_along(exploratory.DNS.MRI.noRes.adapt.model.list), function(i) 
  saveRDS(exploratory.DNS.MRI.noRes.adapt.model.list[[i]], 
          file = paste(results.dir, "exploratory.DNS.MRI.noRes.adapt.", 
                      names(exploratory.DNS.MRI.noRes.adapt.model.list)[[i]], ".Rds", sep = "")))

# Load saved models (if needed)
rdsfiles <- list.files(path = "/Users/allison/Library/CloudStorage/Box-Box/research/projects/dissertation/Results/Aim2.MRI/ML", pattern = "exploratory.DNS.MRI.noRes.*")
saved.models <- lapply(rdsfiles, function(x) readRDS(paste0("/Users/allison/Library/CloudStorage/Box-Box/research/projects/dissertation/Results/Aim2.MRI/ML/", x)))
names(saved.models) <- gsub("\\.Rds*$","", rdsfiles)
exploratory.DNS.MRI.noRes.adapt.model.list <- saved.models

# Get model performance
## Training data
NotRes.x.and.y.trainPerf.df <- do.call(rbind, lapply(exploratory.DNS.MRI.noRes.adapt.model.list, 
                                             function(x) as.data.frame(getTrainPerf(x))))

NotRes.x.and.y.trainPerf.df <- results.spreadsheet(exploratory.DNS.MRI.noRes.adapt.model.list,
                                                   NotRes.x.and.y.trainPerf.df)
write.csv(NotRes.x.and.y.trainPerf.df, paste0(results.dir, "exploratory.MRI.notRes.x.and.y.training.performance.csv"), row.names = TRUE)

## Test data

# Calculate RMSE for predicted values in test data 
# NOTE: didn't figure out extractPrediction function so using lapply instead
NotRes.x.and.y.testData.predictions <- lapply(exploratory.DNS.MRI.noRes.adapt.model.list, 
      function(model) predict(model, DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data))

# Create dataframe that output as file
NotRes.x.and.y.testPerf.df <- as.data.frame(rbind( 
  do.call(rbind, lapply(NotRes.x.and.y.testData.predictions, function(model) 
    postResample(pred = model, obs = DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data$FFOCISF.pred)))))

## Add outcome SD + RMSE/OutcomeSD to the dataframe for reference
NotRes.x.and.y.testPerf.df <- mutate(NotRes.x.and.y.testPerf.df, 
    OutcomeSD = sd(DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data$FFOCISF.pred))    
NotRes.x.and.y.testPerf.df <- mutate(NotRes.x.and.y.testPerf.df, RMSE.to.SD = RMSE/OutcomeSD)

write.csv(NotRes.x.and.y.testPerf.df, file = paste0("/Users/allison/Library/CloudStorage/Box-Box/research/projects/dissertation/Results/Aim2.MRI/ML/", "exploratory.MRI.notRes.x.and.y.test.performance.csv"), 
          row.names = TRUE)

### Adding covariates to unresidualized  (ALM ADDED 4/6/23)
## NOT residualized (features or outputs) + COVARIATES
set.seed(84)
exploratory.DNS.MRI.noRes.w.covars.adapt.model.list <- caretList(
    as.formula(paste("FFOCISF.pred ~ ", paste(c(names(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data)[grepl("*_area$", colnames(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data))],
        names(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data)[grepl("*_thick$", colnames(DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data))],
        exploratory.subcortical.IVs, "+ eTIV + Scanner + GENDER.factor + AGE + RACE"), collapse = " + "))), 
    data = DNS.MRI.training.data$DNS.training.aseg.and.DKT.aparc.data,
    preProcess = c("center", "scale"), # centers and scales
    trControl = adaptControl.DNS.MRI,
    tuneLength = 100,
    methodList = MRIalgorithmList) # ML algorithms using

## Save model
lapply(seq_along(exploratory.DNS.MRI.noRes.w.covars.adapt.model.list), function(i) 
  saveRDS(exploratory.DNS.MRI.noRes.w.covars.adapt.model.list[[i]], 
          file = paste(results.dir, "exploratory.DNS.MRI.noRes.w.covars.adapt.", 
                      names(exploratory.DNS.MRI.noRes.w.covars.adapt.model.list)[[i]], ".Rds", sep = "")))

# Load saved models (if needed)
# rdsfiles <- list.files(path = "/Users/allison/Library/CloudStorage/Box-Box/research/projects/dissertation/Results/Aim2.MRI/ML", pattern = "exploratory.DNS.MRI.noRes.*")
# saved.models <- lapply(rdsfiles, function(x) readRDS(paste0("/Users/allison/Library/CloudStorage/Box-Box/research/projects/dissertation/Results/Aim2.MRI/ML/", x)))
# names(saved.models) <- gsub("\\.Rds*$","", rdsfiles)
# exploratory.DNS.MRI.noRes.w.covars.adapt.model.list <- saved.models

# Get model performance
## Training data
NotRes.x.and.y.w.covars.trainPerf.df <- do.call(rbind, lapply(exploratory.DNS.MRI.noRes.w.covars.adapt.model.list, 
                                             function(x) as.data.frame(getTrainPerf(x))))
NotRes.x.and.y.w.covars.trainPerf.df <- results.spreadsheet(exploratory.DNS.MRI.noRes.w.covars.adapt.model.list,
                                                   NotRes.x.and.y.w.covars.trainPerf.df)
write.csv(NotRes.x.and.y.w.covars.trainPerf.df, paste0(results.dir, "exploratory.MRI.notRes.x.and.y.w.covars.training.performance.csv"), row.names = TRUE)

## Test data
# Calculate RMSE for predicted values in test data 
# NOTE: didn't figure out extractPrediction function so using lapply instead
NotRes.x.and.y.w.covars.testData.predictions <- lapply(exploratory.DNS.MRI.noRes.w.covars.adapt.model.list, 
      function(model) predict(model, DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data))

# Create dataframe that output as file
NotRes.x.and.y.w.covars.testPerf.df <- as.data.frame(rbind( 
  do.call(rbind, lapply(NotRes.x.and.y.w.covars.testData.predictions, function(model) 
    postResample(pred = model, obs = DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data$FFOCISF.pred)))))

## Add outcome SD + RMSE/OutcomeSD to the dataframe for reference
NotRes.x.and.y.w.covars.testPerf.df <- mutate(NotRes.x.and.y.w.covars.testPerf.df, 
    OutcomeSD = sd(DNS.MRI.test.data$DNS.test.aseg.and.DKT.aparc.data$FFOCISF.pred))    
NotRes.x.and.y.w.covars.testPerf.df <- mutate(NotRes.x.and.y.w.covars.testPerf.df, RMSE.to.SD = RMSE/OutcomeSD)

write.csv(NotRes.x.and.y.w.covars.testPerf.df, file = paste0("/Users/allison/Library/CloudStorage/Box-Box/research/projects/dissertation/Results/Aim2.MRI/ML/", "exploratory.MRI.notRes.x.and.y.w.covars.test.performance.csv"), 
          row.names = TRUE)
```

# Tables
Demographics table
```{r}
# Creating a summary table using the arsenal package and the "tableby" function
library(arsenal)

# Customize the stats to display
my_table_controls <- tableby.control(
  test = F,
  total = T,
  cat.simplify = T,
  numeric.simplify = T,
  numeric.stats = c("meansd"),
  cat.stats = c("countpct"),
  digits = 2)

# Change variable names (FOR SPAN)
my_table_labels <- list(
  PAGE = "Age",
#  PGENDER = "Female",
  PGENDER.factor = "Female",
#  white = "White", 
#  black = "Black", 
#  asian = "East Asian", 
#  aian = "Native American", 
#  nhpi = "Pacific Islander", 
#  other = "Other", 
#  mixed = "Multi-racial", 
  PHispanic = "Hispanic")

# SPAN
# FULL SAMPLE
summary(tableby(~ PAGE + as.factor(PGENDER) + as.factor(PRACE) + as.factor(PHispanic) + as.factor(PEdu) ,                  
    data = SPAN.demo.data,
      control = my_table_controls), labelTranslations = my_table_labels, 
        digits = 2)
# ANALYTIC SAMPLE (BASELINE) * using in table
summary(tableby(~ PAGE + as.factor(PGENDER) + as.factor(PRACE) + as.factor(PHispanic) + as.factor(PEdu) ,                  
    data = dfs.notNAs.filtered$SPAN.bl.NEO.and.OCPD.data.notNAs.filtered,
      control = my_table_controls), labelTranslations = my_table_labels, 
        digits = 2)

# FFOCI Validation STudy
## FULL SAMPLE
summary(tableby(~ Age + as.factor(Gender) + as.factor(Ethnicity) + as.factor(Hispanic),             
    data = Doug.2012paper.data,
      control = my_table_controls), #labelTranslations = my_table_labels, 
        digits = 2)
## ANALYTIC SAMPLE (N=175) *using in table
summary(tableby(~ PFU12Age + as.factor(PFU12Gender) + as.factor(PFU12Ethnicity) + as.factor(PFU12Hispanic),             
    data = Doug.2012paper.data.rescored_complete.FFOCI.scaled,
      control = my_table_controls), #labelTranslations = my_table_labels, 
        digits = 2)
# DNS
## FULL SAMPLE

## ANALYTIC SAMPLE (N=1,253) * using in table
summary(tableby(~ AGE + as.factor(GENDER.factor) + as.factor(RACE) + as.factor(LATINO),             
    data = DNS.MRI.data_filtered.for.ML$DNS.aseg.vol.data_filtered,
      control = my_table_controls), #labelTranslations = my_table_labels, 
        digits = 2)
```


# Figures
Data for figures
##Create final data files
```{r eval=FALSE}
# make sure final N's for data used in figures = 
# SPAN = 1,606 (BASELINE), 1,015 (FU10), 898 (FU12), FFOCI Val=175, DNS=1,253

# SPAN
## NOTE: THIS IS ALL DATA (INCLUDING TRAINING, VALIDATION, TESTING). 
## NOTE: doesn't include residualized data (NEO OR FFOCI). those are in separate dfs for training, val, and testing
SPAN.FINAL.DATA <- dfs.notNAs.EXTRAfiltered.NEO.imputed
#write_xlsx(SPAN.FINAL.DATA, path = paste0(project.dir, "./Data/SPAN.FINAL.DATA.xlsx"))
SPAN.FINAL.BL.DATA <- dfs.notNAs.EXTRAfiltered.NEO.imputed$SPAN.bl.NEO.and.OCPD.data.notNAs.filtered.NEO.imputed
SPAN.FINAL.FU10.DATA <- dfs.notNAs.EXTRAfiltered.NEO.imputed$SPAN.FU10.NEO.and.OCPD.data.notNAs.NEO.imputed
SPAN.FINAL.FU12.DATA <- dfs.notNAs.EXTRAfiltered.NEO.imputed$SPAN.FU12.NEO.and.OCPD.data.notNAs.NEO.imputed

# DOUG'S DATA (FFOCI VALIDATION STUDY)
DOUG.FINAL.DATA <- Doug.2012paper.data.rescored2_complete.FFOCI.scaled 
#write_xlsx(DOUG.FINAL.DATA, path = paste0(project.dir, "./Data/DOUG.FINAL.DATA_n175.xlsx"))

# DNS
## CREATE COMBINED LIST OF DNS NEO AND MRI DATA FOR THE 1,253 PEOPLE IN MRI ANALYSES
### NOTE: THIS IS ALL DATA (INCLUDING TRAINING AND TESTING). 
### NOTE: doesn't include residualized neuro data. those are in separate dfs for training and testing
DNS.FINAL.DATA <- lapply(DNS.MRI.data_filtered.for.ML, function(df) left_join(df, DNS.NEO.raw.data_not.NAs.NEO.imputed, by = "ID"))
DNS.FINAL.DATA <- DNS.FINAL.DATA[- c(1:7)]
#write_xlsx(DNS.FINAL.DATA, path =  paste0(project.dir, "./Data/DNS.FINAL.DATA_n1253.xlsx"))
```
##Load final data files
```{r}
# Define function to load .xlsx files w/ multiple sheets
multiplesheets <- function(fname) {
   
  # getting info about all excel sheets
  sheets <- readxl::excel_sheets(fname)
  tibble <- lapply(sheets, function(x) readxl::read_excel(fname, sheet = x))
  data_frame <- lapply(tibble, as.data.frame)
    
  # assigning names to data frames
  names(data_frame) <- sheets
    
  # print data frame
  return(data_frame)
}
  
# Import xlsx files to lists/dfs
SPAN.FINAL.DATA <- multiplesheets(paste0(project.dir, "./Data/SPAN.FINAL.DATA.xlsx"))
DNS.FINAL.DATA <- multiplesheets(paste0(project.dir, "./Data/DNS.FINAL.DATA_n1253.xlsx"))
DOUG.FINAL.DATA <- read_excel(paste0(project.dir, "./Data/DOUG.FINAL.DATA_n175.xlsx"))
```
Combine data into single dataframe for figures
```{r}
# Create dataframes of just SPAN OCPD data
# OCPD.sum.scores_SPAN.baseline <-  select(SPAN.FINAL.DATA$SPAN.bl.NEO.and.OCPD.data.,
#           c(PARTID, SIDPOC, SIDPOC_scaled, SIDPOC_nomiss, SIDPOCC, SIDPOCD, #SIDP_AnyOCsx, SIDP_2plusOCsx, SIDP_3plusOCsx,
#                                   PMAPPOC, PMAPPOC_scaled, PMAPPOC_nomiss, PMAPPOCC, PMAPPOCD))
# OCPD.sum.scores_SPAN.FU10 <-
#       select(SPAN.FINAL.DATA$SPAN.FU10.NEO.and.OCPD.data,
#           c(PARTID, FU10SIDPOC, FU10SIDPOC_scaled, FU10SIDPOC_nomiss, FU10SIDPOCC, FU10SIDPOCD, #FU10SIDP_AnyOCsx, # FU10SIDP_2plusOCsx, FU10SIDP_3plusOCsx,
#                     PFU10MAPPOC, PFU10MAPPOC_scaled, PFU10MAPPOC_nomiss, PFU10MAPPOCC, PFU10MAPPOCD,
#                   FU10FFOCI_Total, FU10FFOCI_Scaled.Total, FU10FFOCI_NoMiss.Total))
# OCPD.sum.scores_SPAN.FU12 <-  select(SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data,
#           c(PARTID, PFU12MAPPOC, PFU12MAPPOC_scaled, PFU12MAPPOC_nomiss, PFU12MAPPOCC, PFU12MAPPOCD,       
#                   FU12FFOCI_Total, FU12FFOCI_Scaled.Total, FU12FFOCI_NoMiss.Total))
# SPAN.FINAL.OCPD.DATA <- full_join(OCPD.sum.scores_SPAN.baseline, OCPD.sum.scores_SPAN.FU10, by="PARTID")
# SPAN.FINAL.OCPD.DATA <- full_join(SPAN.FINAL.OCPD.DATA, OCPD.sum.scores_SPAN.FU12)


# Long version w/ variable for dataset/timepoint and multiple rows per participants who have multiple TPs
# to generate figures wrapping based on dataset variable
## SPAN
### baseline
OCPD.sum.scores_SPAN.baseline <-  select(SPAN.FINAL.DATA$SPAN.bl.NEO.and.OCPD.data.,
          c(PARTID, SIDPOC, SIDPOC_scaled, SIDPOC_nomiss, SIDPOCC, SIDPOCD, #SIDP_AnyOCsx, SIDP_2plusOCsx, SIDP_3plusOCsx,
                                  PMAPPOC, PMAPPOC_scaled, PMAPPOC_nomiss, PMAPPOCC, PMAPPOCD,
            matches(c("^NEO[A-Z]\\d$", "^NEO[A-Z]$","^NEO[A-Z]\\d_scaled$", "^NEO[A-Z]_scaled$", 
                      "^NEO[A-Z]\\d_imputed$", "^NEO[A-Z]_imputed$")))) %>%
    mutate(Dataset = rep("SPAN.BL", 1606))
### FU10
OCPD.sum.scores_SPAN.FU10 <-
      select(SPAN.FINAL.DATA$SPAN.FU10.NEO.and.OCPD.data,
          c(PARTID, FU10SIDPOC, FU10SIDPOC_scaled, FU10SIDPOC_nomiss, FU10SIDPOCC, FU10SIDPOCD, #FU10SIDP_AnyOCsx, FU10SIDP_2plusOCsx, FU10SIDP_3plusOCsx,
                    PFU10MAPPOC, PFU10MAPPOC_scaled, PFU10MAPPOC_nomiss, PFU10MAPPOCC, PFU10MAPPOCD,
                  FU10FFOCI_Total, FU10FFOCI_Scaled.Total, FU10FFOCI_NoMiss.Total,
            matches(c("NEO[A-Z]\\d$", "NEO[A-Z]$","NEO[A-Z]\\d_scaled$", "NEO[A-Z]_scaled$", 
                      "NEO[A-Z]\\d_imputed$", "NEO[A-Z]_imputed$")))) %>%
    mutate(Dataset = rep("SPAN.FU10", 1015))
colnames(OCPD.sum.scores_SPAN.FU10) <- gsub("FU10", "", colnames(OCPD.sum.scores_SPAN.FU10))
### FU12
OCPD.sum.scores_SPAN.FU12 <-  select(SPAN.FINAL.DATA$SPAN.FU12.NEO.and.OCPD.data,
          c(PARTID, PFU12MAPPOC, PFU12MAPPOC_scaled, PFU12MAPPOC_nomiss, PFU12MAPPOCC, PFU12MAPPOCD,       
                  FU12FFOCI_Total, FU12FFOCI_Scaled.Total, FU12FFOCI_NoMiss.Total, 
            matches(c("NEO[A-Z]\\d$", "NEO[A-Z]$","NEO[A-Z]\\d_scaled$", "NEO[A-Z]_scaled$", 
                      "NEO[A-Z]\\d_imputed$", "NEO[A-Z]_imputed$")))) %>%
 mutate(Dataset = rep("SPAN.FU12", 898))
colnames(OCPD.sum.scores_SPAN.FU12) <- gsub("FU12", "", colnames(OCPD.sum.scores_SPAN.FU12))

## DNS - NO OCPD DATA
## add imputed summary scores to the dataframe
DNS.FINAL.DATA$DNS.aseg.vol.data_filtered <- calc.facet.totals(DNS.FINAL.DATA$DNS.aseg.vol.data_filtered)
NEO.DNS <- select(DNS.FINAL.DATA$DNS.aseg.vol.data_filtered, c(ID, ends_with("_imputed"))) %>%
    mutate(Dataset=rep("DNS", 1253)) %>% rename(PARTID = ID)

## DOUG - FFOCI
OCPD.doug <- select(DOUG.FINAL.DATA, c("PFU12Fake.ID", "PFU12FFOCISF_Total","FU12FFOCI_Scaled.Total",   "PFU12FFOCISF_NoMiss.Total", 
                    ends_with(c("neoneur", "neoextra", "neoopen", "neoagree", "neoconsc")), matches("^PFU12neo[a-z]\\d$"))) %>% 
    rename(PARTID = PFU12Fake.ID, 
        FFOCI_Scaled.Total = FU12FFOCI_Scaled.Total, FFOCI_Total = PFU12FFOCISF_Total, 
        FFOCI_NoMiss.Total = PFU12FFOCISF_NoMiss.Total) %>% 
    mutate(Dataset = rep("Doug.Val", 175))
colnames(OCPD.doug) <- gsub("PFU12", "", colnames(OCPD.doug))
OCPD.doug <- rename(OCPD.doug, NEON_imputed = neoneur, NEOE_imputed = neoextra, 
        NEOO_imputed = neoopen, NEOA_imputed = neoagree, NEOC_imputed = neoconsc)
#colnames(select(OCPD.doug, matches("^neo[a-z]\\d"))) <- paste0(colnames(to_upper(select(OCPD.doug, matches("^neo[a-z]\\d$")))), "_imputed")
OCPD.doug <- OCPD.doug %>% rename_with(~paste0(toupper(.)), matches("^neo[a-z]\\d$"))
OCPD.doug <- OCPD.doug %>% rename_with(~paste0(., "_imputed"), matches("NEO[A-Z]\\d$"))

FINAL.OCPD.DATA.long <- bind_rows(OCPD.sum.scores_SPAN.baseline, OCPD.sum.scores_SPAN.FU10)
FINAL.OCPD.DATA.long <- bind_rows(FINAL.OCPD.DATA.long, OCPD.sum.scores_SPAN.FU12)
FINAL.OCPD.DATA.long <- bind_rows(FINAL.OCPD.DATA.long, OCPD.doug)
FINAL.OCPD.DATA.long$PARTID <- as.character(FINAL.OCPD.DATA.long$PARTID)
FINAL.OCPD.DATA.long <- bind_rows(FINAL.OCPD.DATA.long, NEO.DNS)
```

Resplit MRI data into training vs. test data
- uses file generated during model training that specified the subjids for each
```{r}
DNS.MRI.data.split.info <- read.csv(paste0(project.dir, "./Results/Aim2.MRI/DNS.MRI.data.split.info.csv"))
DNS.training.IDs <- DNS.MRI.data.split.info$MRI.train.ID
DNS.test.IDs <- DNS.MRI.data.split.info$MRI.test.ID

DNS.MRI.training.data <- lapply(DNS.FINAL.DATA, function(x) { 
    x <- filter(x, ID %in% DNS.training.IDs)}) 
DNS.MRI.test.data <- lapply(DNS.FINAL.DATA, function(x) { 
    x <- filter(x, ID %in% DNS.test.IDs)}) 
  
# NOTE: SPREADSHEET TAB NAMES GOT CUT OFF SO SOME LIST NAMES ARE MISSING THE ENDS (I.E. _filtered)

# Add dataframes to list that have all DK or DKT aparc data + aseg data 
# (to run models w/ all data simultaneously)
## Create the dataframes
### FULL DATASET
DNS.aseg.and.DKT.aparc.data <- Reduce(function(...) left_join(..., by=c('ID', 'Scanner', 'eTIV', "FFOCISF.pred.res", "GENDER", "AGE","RACE","LATINO","LANGUAGE","GENDER.factor"), copy = TRUE), list(DNS.FINAL.DATA$DNS.aseg.vol.data_filtered, DNS.FINAL.DATA$DNS.aparc.DKT.cort.thick.data, DNS.FINAL.DATA$DNS.aparc.DKT.surf.area.data_, DNS.FINAL.DATA$DNS.aparc.DKT.vol.data_filter)) %>%
  select(-c("MeanThick.x", "MeanThick.y", "lhMeanThickness.x", "lhMeanThickness.y", 
            "rhMeanThickness.x", "rhMeanThickness.y", 
             "AGE.y","RACE.y","LATINO.y", "GENDER.y", "LANGUAGE.y", "GENDER.factor.y"))
DNS.aseg.and.DK.aparc.data <- Reduce(function(...) left_join(..., by=c('ID', 'Scanner', 'eTIV',
  "FFOCISF.pred.res", "GENDER", "AGE","RACE","LATINO","LANGUAGE","GENDER.factor")), list(DNS.FINAL.DATA$DNS.aseg.vol.data_filtered, DNS.FINAL.DATA$DNS.aparc.DK.cort.thick.data_, DNS.FINAL.DATA$DNS.aparc.DK.surf.area.data, DNS.FINAL.DATA$DNS.aparc.DK.vol.data_filtere)) %>%
  select(-c("MeanThick.x", "MeanThick.y", "lhMeanThickness.x", "lhMeanThickness.y", 
            "rhMeanThickness.x", "rhMeanThickness.y",
            "AGE.y","RACE.y","LATINO.y", "GENDER.y", "LANGUAGE.y", "GENDER.factor.y"))
### TRAINING DATASET
DNS.training.aseg.and.DKT.aparc.data <- Reduce(function(...) left_join(..., by=c('ID', 'Scanner', 'eTIV', "FFOCISF.pred.res", "GENDER", "AGE","RACE","LATINO","LANGUAGE","GENDER.factor")), list(DNS.MRI.training.data$DNS.aseg.vol.data_filtered, DNS.MRI.training.data$DNS.aparc.DKT.cort.thick.data, DNS.MRI.training.data$DNS.aparc.DKT.surf.area.data_, DNS.MRI.training.data$DNS.aparc.DKT.vol.data_filter)) %>%
  select(-c("MeanThick.x", "MeanThick.y", "lhMeanThickness.x", "lhMeanThickness.y", 
            "rhMeanThickness.x", "rhMeanThickness.y",
            "AGE.y","RACE.y","LATINO.y", "GENDER.y", "LANGUAGE.y", "GENDER.factor.y"))
DNS.training.aseg.and.DK.aparc.data <- Reduce(function(...) left_join(..., by=c('ID', 'Scanner', 'eTIV',
"FFOCISF.pred.res", "GENDER", "AGE","RACE","LATINO","LANGUAGE","GENDER.factor")), list(DNS.MRI.training.data$DNS.aseg.vol.data_filtered, DNS.MRI.training.data$DNS.aparc.DK.cort.thick.data_, DNS.MRI.training.data$DNS.aparc.DK.surf.area.data_f, DNS.MRI.training.data$DNS.aparc.DK.vol.data_filtere)) %>%
  select(-c("MeanThick.x", "MeanThick.y", "lhMeanThickness.x", "lhMeanThickness.y", 
            "rhMeanThickness.x", "rhMeanThickness.y",
            "AGE.y","RACE.y","LATINO.y", "GENDER.y", "LANGUAGE.y", "GENDER.factor.y"))
### TESTING DATASET
DNS.test.aseg.and.DKT.aparc.data <- Reduce(function(...) left_join(..., by=c('ID', 'Scanner', 'eTIV', "FFOCISF.pred.res", "GENDER", "AGE","RACE","LATINO","LANGUAGE","GENDER.factor")), list(DNS.MRI.test.data$DNS.aseg.vol.data_filtered, DNS.MRI.test.data$DNS.aparc.DKT.cort.thick.data_filtered, DNS.MRI.test.data$DNS.aparc.DKT.surf.area.data_filtered, DNS.MRI.test.data$DNS.aparc.DKT.vol.data_filtered)) %>%
  select(-c("MeanThick.x", "MeanThick.y", "lhMeanThickness.x", "lhMeanThickness.y", 
            "rhMeanThickness.x", "rhMeanThickness.y",
            "AGE.y","RACE.y","LATINO.y", "GENDER.y", "LANGUAGE.y", "GENDER.factor.y"))
DNS.test.aseg.and.DK.aparc.data <- Reduce(function(...) left_join(..., by=c('ID', 'Scanner', 'eTIV',
"FFOCISF.pred.res", "GENDER", "AGE","RACE","LATINO","LANGUAGE","GENDER.factor")), list(DNS.MRI.test.data$DNS.aseg.vol.data_filtered, DNS.MRI.test.data$DNS.aparc.DK.cort.thick.data_filtered, DNS.MRI.test.data$DNS.aparc.DK.surf.area.data_filtered, DNS.MRI.test.data$DNS.aparc.DK.vol.data_filtered)) %>%
  select(-c("MeanThick.x", "MeanThick.y", "lhMeanThickness.x", "lhMeanThickness.y", 
            "rhMeanThickness.x", "rhMeanThickness.y",
            "AGE.y","RACE.y","LATINO.y", "GENDER.y", "LANGUAGE.y", "GENDER.factor.y"))

## Add them to the existing lists
DNS.MRI.data_filtered.for.ML <- c(DNS.MRI.data_filtered.for.ML, 
        lst(DNS.aseg.and.DKT.aparc.data, DNS.aseg.and.DK.aparc.data))
DNS.MRI.training.data <- c(DNS.MRI.training.data, 
        lst(DNS.training.aseg.and.DKT.aparc.data, DNS.training.aseg.and.DK.aparc.data))
DNS.MRI.test.data <- c(DNS.MRI.test.data, 
        lst(DNS.test.aseg.and.DKT.aparc.data, DNS.test.aseg.and.DK.aparc.data))
```

Set figure formatting parameters
```{r}
FINAL.OCPD.DATA.long$Dataset.factor <- factor(FINAL.OCPD.DATA.long$Dataset, 
                                levels = c("SPAN.BL", "SPAN.FU10", "SPAN.FU12", "Doug.Val", "DNS"),
                                labels=c("SPAN\nBaseline", "SPAN\nFU10", "SPAN\nFU12", "FFOCI\nValidation", "DNS"))

# Specify dataset colors from fishualize color palette so consistent across graphs even when don't have data from everydataset
dataset.colors <- setNames(object = as.character(paletteer_d("fishualize::Antennarius_commerson")), 
                           nm= levels(FINAL.OCPD.DATA.long$Dataset.factor))

boxplot.format <-  list(geom_boxplot(aes(fill=Dataset.factor), notch = TRUE),
    #scale_fill_brewer(type = "qual", palette = "Dark") + 
    #scale_fill_fish_d("Antennarius_commerson"), #also like: clepticus_brasillensis, elagatis_bipinnulata, halichoeres_bivittatus
    scale_fill_manual(values = dataset.colors),
    labs(y="Dataset"),
    scale_y_discrete(limits=c("DNS", "FFOCI\nValidation", "SPAN\nFU12", "SPAN\nFU10","SPAN\nBaseline")), 
    theme_bw(), 
    theme(legend.position="none", axis.text = element_text(color="black"), axis.title = element_text(face = "bold"))) 

NEO.boxplot.format <- append(boxplot.format, list(scale_x_continuous(breaks = c(25,50,75,100,125,150,175,200)),
                                                  xlim(0,200)))
```

## Methods 
```{r}
# FFOCI Scores (SPAN + FFOCI Validation Study)
## histogram - not very useful
# ggplot() + geom_histogram(data = FINAL.OCPD.DATA.long, aes(x=FFOCI_Scaled.Total)) +
#     facet_wrap(vars(Dataset))
## boxplot
FFOCI.boxplot <- ggplot(data = FINAL.OCPD.DATA.long, aes(x=FFOCI_Scaled.Total, y=Dataset.factor)) +
    boxplot.format + labs(x="FFOCI-SF Total Score")

    
# SPAN SIDP OCPD 
## histogram
# ggplot() + geom_histogram(data = FINAL.OCPD.DATA.long, aes(x=SIDPOC_scaled)) +
#     facet_wrap(vars(Dataset))
## boxplot
SIDP.boxplot <- ggplot(data = FINAL.OCPD.DATA.long, aes(x = SIDPOC_scaled, y=Dataset.factor)) +
    boxplot.format + labs(x="SIDP OCPD Total Score")
## violin plot
# ggplot() + geom_violin(data = FINAL.OCPD.DATA.long, aes(x=SIDPOC_scaled, y=Dataset)) + 
#     geom_boxplot(width=0.1)

# SPAN MAPP OCPD
## histogram
# ggplot() + geom_histogram(data = FINAL.OCPD.DATA.long, aes(x=PMAPPOC_scaled)) +
#     facet_wrap(vars(Dataset))
## boxplot
MAPP.boxplot <- ggplot(data = FINAL.OCPD.DATA.long, aes(x = PMAPPOC_scaled, y=Dataset.factor)) +
    boxplot.format + labs(x="MAPP OCPD Total Score")
## violin plot
# ggplot() + geom_violin(data = FINAL.OCPD.DATA.long, aes(x=PMAPPOC_scaled, y=Dataset), alpha = 0.2) + 
#     geom_boxplot(width=0.1)

OCPD.fig <- cowplot::plot_grid(FFOCI.boxplot, SIDP.boxplot, MAPP.boxplot, nrow = 3, ncol = 1)
cowplot::save_plot("../Figures/final.data/OCPD.figure.png", OCPD.fig, ncol = 1, nrow = 3)

# NEO - domain totals from imputed item-level data
NEO.Nfig <- ggplot(data = FINAL.OCPD.DATA.long, aes(x = NEON_imputed, y=Dataset.factor)) + 
    labs(x="Neuroticism") + format
NEO.Cfig <- ggplot(data = FINAL.OCPD.DATA.long, aes(x = NEOC_imputed, y=Dataset.factor)) + 
    labs(x="Conscientiousness") + format
NEO.Efig <- ggplot(data = FINAL.OCPD.DATA.long, aes(x = NEOE_imputed, y=Dataset.factor)) + 
    labs(x="Extraversion") + format
NEO.Ofig <- ggplot(data = FINAL.OCPD.DATA.long, aes(x = NEOO_imputed, y=Dataset.factor)) + 
    labs(x="Openness") + format
NEO.Afig <- ggplot(data = FINAL.OCPD.DATA.long, aes(x = NEOA_imputed, y=Dataset.factor)) + 
    labs(x="Agreeableness") + format

NEO.fig <- cowplot::plot_grid(NEO.Nfig, NEO.Cfig, NEO.Efig, NEO.Ofig, NEO.Afig, nrow = 3, ncol = 2)
cowplot::save_plot("../Figures/final.data/NEO.figure.png", NEO.fig, ncol = 2, nrow = 3)
```

## Results
Aim 1 Figures
```{r}
# NEO Items kept in final model (from SPAN data)
## Load coded data from excel spreadsheet
predictors.kept <- read.xlsx(paste0(results.dir, "predictors.xlsx"), sheet = 2, skipEmptyCols = T)
predictors.graph.data <- predictors.kept[1:30, 6:9]

## Create lollipop chart using ggpubr
ggdotchart(predictors.graph.data, x = "Facet", y = "Items.per.facet-res",
           xlab = "Facets", ylab = "Number of NEO Items Kept",
           color = "Factor",        # Color by groups
           palette = c(rgb(211,87,254, maxColorValue = 255), # purple, conscientiousness
                       rgb(83,212,253, maxColorValue = 255), # blue, openness
                       rgb(150,211,95, maxColorValue = 255), # green, agreeableness
                       rgb(241,234,101, maxColorValue = 255), # yellow, extroversion
                       rgb(230,59,122, maxColorValue = 255)), # pink, neuroticism, 
           sorting = "descending",  # Sort value in descending order
           add = "segments",        # Add segments from y = 0 to dots
           rotate = TRUE,           # Rotate vertically
           group = "Factor",        # Order by groups
           dot.size = 6,            # Large dot size
           label = predictors.graph.data$`Items.per.facet-res`, # Add values as dot labels
           font.label = list(color = "white", size = 9, 
                             vjust = 0.5),               # Adjust label parameters
           ggtheme = theme_pubr()                        # ggplot2 theme
)

# Final Model Performance in SPAN Test Data

## Predicted vs. Actual 
### scatterplot
# 1. Open png file
pdf(file = paste0(results.dir, "figures/test.data_ObsvsPred_FU12FFOCIglmnet.res.pdf"))
# 2. Create the plot
plot(x = testData.final.model.res.FU12.predictions, y = testData.FU12$FU12FFOCI_Scaled.Total.res,
     xlab= "Observed Residualized FFOCI-SF Scaled Total", 
     ylab = "Predicted Residualized FFOCI-SF Scaled Total", 
     xlim = c(-60,60), ylim = c(-60, 60), 
     main = "SPAN Test Data\nObserved vs. Predicted\nFFOCI-SF Scaled Total (Residualized)",
     sub = expression(italic("Elastic Net Regression Model Trained on FU12 FFOCI Residualized Data")),
     asp = 1)
abline(a=0, b=1) # adds x=y line to graph
# 3. Close the file
dev.off()

### histogram
hist(testData.final.model.res.FU12.predictions, col=rgb(0, 1, 0, alpha = 0.3),
     xlab = "FFOCI-SF Scaled Total (Residualized)", main = "SPAN Test Data\nObserved vs. Predicted\nFFOCI-SF Scaled Total (Residualized)",
     sub = expression(italic("Elastic Net Regression Model Trained on FU12 FFOCI Residualized Data")))
hist(testData.FU12$FU12FFOCI_Scaled.Total.res, col = rgb(0, 0, 1, alpha = 0.3), add=T)
legend("topright", legend=c("Predicted", "Actual"), col=c(rgb(0, 1, 0, alpha = 0.3), rgb(0, 0, 1, alpha = 0.3)),
       pt.cex = 2, pch = 15)

ggpubr::gghistogram()

ggplot() +
  geom_histogram(data = testData.final.model.res.FU12.predictions, fill = "green", alpha = 0.3) +
  geom_histogram(data = testData.FU12$FU12FFOCI_Scaled.Total.res, fill = "purple", alpha = 0.3)
```

Aim 2 Figures
```{r} 
# Just the right superior frontal gyrus sig. finding
rhsupfrontggseg<- data.frame(hemi=c("right"),
#region = c("left insula", "left thalamus", "left fusiform", "right lateral occipital", "left cerebral white matter", "right superior frontal", "right caudal anterior cingulate"),
region = c("superior frontal"),
color=c("1"))

ggseg(rhsupfrontggseg,
#ggseg(filter(varImpInfo.df_exploratory, glmnet.explorMRI != 0), 
#      mapping=aes(fill=color, colour="#00B9E3"), atlas = "dkt", position="stacked", color = "black", show.legend=F) +
 mapping=aes(fill=color), atlas = "dkt", position="stacked", color = "black", show.legend=F) +
#  guides(fill=guide_legend(title="Features Kept")) +
  scale_fill_manual(values=c("#00BFC4"))  # keeps unused factor levels so color scale same
ggsave("../Figures/final.data/MRI.regress.results.png")

# All MRI results 
library(scales) #this package includes muted function that allows you to get muted colors

explor.thickness.results <- read.csv("../Figures/final.data/DNS.MRI.thickness.results.for.figure.csv")
#ggseg(explor.thickness.results, atlas="dkt", mapping=aes(fill = t))

explor.thick <- ggplot(explor.thickness.results) +
  geom_brain(atlas = dkt, aes(fill = t)) + 
    scale_fill_gradient2(limits = c(-3.2, 3.2), #set limits so same scale across thickness, area, and subcort vol
        low = muted("blue"), high = muted("red")) +  # flip red + blue color direction
  theme_void() # gets rid of grid and slice numbers

explor.area.results <- read.csv("../Figures/final.data/DNS.MRI.surf.area.results.for.figure.csv")

explor.area <- ggplot(explor.area.results) +
  geom_brain(atlas = dkt, aes(fill = t)) + scale_fill_gradient2(limits = c(-3.2, 3.2),  low = muted("blue"), high = muted("red")) +  # flip red + blue color direction) 
    theme_void()

explor.vol.results <- read.csv("../Figures/final.data/DNS.MRI.vol.results.for.figure.csv")

explor.vol <- ggplot(explor.vol.results) +
  geom_brain(atlas = aseg, side = "coronal", aes(fill = t)) + 
  scale_fill_gradient2(limits = c(-3.2, 3.2),  low = muted("blue"), high = muted("red")) +  # flip red + blue color direction
 theme_void()

# combine plots into single figure
ggarrange(explor.thick, explor.vol,explor.area, common.legend = TRUE, 
          widths = c(2,1), #heights = c(1,2), 
          labels = c("A) Cortical Thickness", "C) Subcortical Volume", "B) Surface Area"),
          hjust = 0, vjust = 0.5)
ggsave(path = "~/Desktop/", "DNS.explor.MRI.results.tiff", width = 7, height = 4)

## trying it a different way
ggarrange(ggarrange(explor.thick, explor.area, nrow = 2, labels = c("A) Cortical Thickness", "B) Surface Area", legend = "none")), 
          explor.vol, 
          ncol = 2, common.legend = TRUE)

```


